{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Optimization for Statistical Learning\" Expirement Notebook\n",
    "## Section 0 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.1 Data Importing and Preprocessing\n",
    "In this section, we include packages we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a8e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages #\n",
    "# !pip install jupyter\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install math\n",
    "# !pip install torch\n",
    "# !pip install xlrd\n",
    "# !pip install pandas\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b59c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import Tensor\n",
    "from torch.optim.optimizer import (Optimizer, required, _use_grad_for_differentiable, _default_to_fused_or_foreach,\n",
    "                        _differentiable_doc, _foreach_doc, _maximize_doc)\n",
    "from typing import List, Optional\n",
    "from torch.autograd import Variable\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load npy files to restore results in the past**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#past_results = np.load('./result.npy', encoding = \"latin1\")\n",
    "#print(past_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0.2 Global Classes, Functions and Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spliting the DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataloader(dataloader, num_piece):\n",
    "    dataset = list(dataloader)\n",
    "    subset_size = len(dataset) // num_piece\n",
    "    remainder = len(dataset) % num_piece\n",
    "    split_subsets = []\n",
    "    start_idx = 0\n",
    "    for i in range(num_piece):\n",
    "        if i < remainder:\n",
    "            end_idx = start_idx + subset_size + 1\n",
    "        else:\n",
    "            end_idx = start_idx + subset_size\n",
    "        subset = dataset[start_idx:end_idx]\n",
    "        split_subsets.append(subset)\n",
    "        start_idx = end_idx\n",
    "    split_dataloaders = []\n",
    "    for subset in split_subsets:\n",
    "        split_dataloader = torch.utils.data.DataLoader(subset, batch_size=dataloader.batch_size, shuffle=True)\n",
    "        split_dataloaders.append(split_dataloader)\n",
    "    return split_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Rate Analaysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test error rate analysis function\n",
    "def calculate_error_rate(X, y, predict):\n",
    "    num_samples = X.shape[0]\n",
    "    error_count = torch.count_nonzero(torch.round(predict) - y)\n",
    "    error_rate = error_count / num_samples\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Optimizer Class of Vanilia Gradient Descent**\n",
    "\n",
    "The name custom_optimizer_SGD is just for consistency with torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_optimizer_SGD(Optimizer):\n",
    "    def __init__(self, params, lr=required, weight_decay=0 ):\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(f\"Invalid weight_decay value: {weight_decay}\")\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "                \n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "                grad = param.grad.data\n",
    "                weight_decay = group['weight_decay']\n",
    "                lr = group['lr']\n",
    "                param.data.add_(-lr, grad)\n",
    "                if weight_decay != 0:\n",
    "                    param.data.add_(-lr * weight_decay, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Client Device Class and Federated Learning Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom class for each client so they can update separately\n",
    "class ClientDevice:\n",
    "    def __init__(self, model, criterion, optimizer, X_train, y_train):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.num_samples = self.X_train.size()[0]\n",
    "        self.num_features = self.X_train.size()[1]\n",
    "\n",
    "    def load_global_weights(self, global_weights):\n",
    "        self.model.load_state_dict(global_weights)\n",
    "\n",
    "    def get_local_weights(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def update_weights_GDVanilia(self, num_epochs):\n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            # Update weight\n",
    "            outputs = self.model(self.X_train.float())\n",
    "            loss = self.criterion(outputs, self.y_train.float())\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def update_weights_GDStochastic(self, num_epochs, batch_size):\n",
    "        self.model.train()\n",
    "        num_batches = self.num_samples // batch_size\n",
    "        for epoch in range(num_epochs):\n",
    "            # Shuffle the data for each epoch\n",
    "            permutation = torch.randperm(self.num_samples)\n",
    "            X_shuffled = self.X_train[permutation]\n",
    "            y_shuffled = self.y_train[permutation]\n",
    "            for batch in range(num_batches):\n",
    "                # Select the current batch\n",
    "                start = batch * batch_size\n",
    "                end = (batch + 1) * batch_size\n",
    "                X_batch = X_shuffled[start:end]\n",
    "                y_batch = y_shuffled[start:end]\n",
    "                # Update weight\n",
    "                outputs = self.model(X_batch.float())\n",
    "                loss = self.criterion(outputs, y_batch.float())\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def update_weights(self, num_epochs, input_shape, iterate_func):\n",
    "        self.model.train()\n",
    "        loss_history, error_history = iterate_func(self.model, self.train_loader, num_epochs, self.optimizer, self.criterion, input_shape, show_history=False, training=True)\n",
    "        return self.model.state_dict(), loss_history, error_history\n",
    "\n",
    "# Establish client devices\n",
    "def establish_client_devices(num_clients, dataset_loader, model_list, optimizer_list, criterion_list):\n",
    "    # Establish client devices\n",
    "    client_device = [None] * num_clients\n",
    "    client_model = [None] * num_clients\n",
    "    client_optimizer = [None] * num_clients\n",
    "    client_criterion = [None] * num_clients\n",
    "    client_weights = [None] * num_clients\n",
    "    for client in range(num_clients):\n",
    "        client_model[client] = model_list[client]\n",
    "        client_optimizer[client] = optimizer_list[client]\n",
    "        client_criterion[client] = criterion_list[client]\n",
    "        client_weights[client] = client_model[client].state_dict()\n",
    "        client_device[client] = ClientDevice(client_model[client], client_optimizer[client], client_criterion[client], dataset_loader)\n",
    "    return client_device\n",
    "    \n",
    "\n",
    "# Define server wise functions\n",
    "def send_client_weights(server_weights, local_weights):\n",
    "    server_weights.append(local_weights)\n",
    "\n",
    "# Total weight processing functions\n",
    "def Federated_Averaging(client_weights_total):\n",
    "    total_clients = len(client_weights_total)\n",
    "    aggregate_weights = {}\n",
    "\n",
    "    # Initialize aggregate_weights with the first client's weights\n",
    "    for layer_name, layer_weights in client_weights_total[0].items():\n",
    "        aggregate_weights[layer_name] = layer_weights / total_clients\n",
    "\n",
    "    # Aggregate weights from the remaining clients\n",
    "    for client_weights in client_weights_total[1:]:\n",
    "        for layer_name, layer_weights in client_weights.items():\n",
    "            aggregate_weights[layer_name] += layer_weights / total_clients\n",
    "\n",
    "    return aggregate_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Linear Training Model\n",
    "In this section, we will focus on the dataset requires no complicated data processing, and mainly linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.0. Data Loading and Preprocessing\n",
    "Here we load the data for the expriements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BMI Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb81ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BMI Dataset\n",
    "\n",
    "# Loading training data\n",
    "dataset = pd.read_csv(\"bmi_train.csv\")\n",
    "dataset.replace({'Gender': {'Female': 0, 'Male': 1}}, inplace=True) #Gender -> boolean\n",
    "dataset = dataset.to_numpy()\n",
    "\n",
    "# Splitting off 80% of data for training, 20% for validation\n",
    "train_split = int(0.8 * len(dataset))\n",
    "X_train = dataset[:train_split, [0,1,2]]\n",
    "y_train = dataset[:train_split, 3]\n",
    "X_test = dataset[train_split:, [0,1,2]]\n",
    "y_test = dataset[train_split:, 3]\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "# Loading prediction data\n",
    "prediction_dataset = pd.read_csv(\"bmi_validation.csv\")\n",
    "prediction_dataset.replace({'Gender': {'Female': 0, 'Male': 1}}, inplace=True) #Gender -> boolean\n",
    "X_prediction = prediction_dataset.to_numpy()\n",
    "\n",
    "# Normalize data set\n",
    "X_train_normalized = (X_train - X_train.min(0)) / (X_train.max(0) - X_train.min(0))\n",
    "X_test_normalized = (X_test - X_test.min(0)) / (X_test.max(0) - X_test.min(0))\n",
    "X_prediction_normalized = (X_prediction - X_prediction.min(0)) / (X_prediction.max(0) - X_prediction.min(0))\n",
    "\n",
    "# Turn data to tensor\n",
    "X_train_tensor = torch.from_numpy(X_train_normalized)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test_normalized)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "X_prediction_tensor = torch.from_numpy(X_prediction_normalized)\n",
    "print(X_train_tensor.size())\n",
    "print(y_train_tensor.size())\n",
    "print(X_test_tensor.size())\n",
    "print(y_test_tensor.size())\n",
    "\n",
    "# Learning Rate and Batch size\n",
    "dataset_name = \"BMI Datset\"\n",
    "learning_rate_preset = 0.01\n",
    "batch_size_preset = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epsilon Pascal Challenge Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d3247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Epsilon Pascal Challenge Dataset\n",
    "\n",
    "# Loading training data\n",
    "dataset = pd.read_csv(\"epsilon_normalized.txt\", sep=' ', header=None, nrows=20000)\n",
    "dataset = dataset.to_numpy()\n",
    "for i in range(1, dataset.shape[1]-1):\n",
    "    dataset[:, i] = [float(value.split(':')[1]) if isinstance(value, str) else value for value in dataset[:, i]]\n",
    "dataset = dataset[:, :-1]\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "for i in range(1, dataset.shape[0]):\n",
    "    if dataset[i - 1, 0] == -1:\n",
    "        dataset[i - 1, 0] = 0\n",
    "\n",
    "# Splitting off data for training and validation\n",
    "train_split = int(0.8 * len(dataset))\n",
    "X_train = dataset[:train_split, 1:].astype(np.float32)\n",
    "y_train = dataset[:train_split, 0].astype(np.float32)\n",
    "X_test = dataset[train_split:, 1:].astype(np.float32)\n",
    "y_test = dataset[train_split:, 0].astype(np.float32)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "\n",
    "# Normalize data set\n",
    "X_train_normalized = X_train\n",
    "X_test_normalized = X_test\n",
    "\n",
    "# Turn data to tensor\n",
    "X_train_tensor = torch.from_numpy(X_train_normalized)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test_normalized)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "print(\"X_train_tensor size: \", X_train_tensor.size())\n",
    "print(\"y_train_tensor size: \", y_train_tensor.size())\n",
    "print(\"X_test_tensor size: \", X_test_tensor.size())\n",
    "print(\"y_test_tensor size: \", y_test_tensor.size())\n",
    "\n",
    "# Preset parameters\n",
    "dataset_name = \"Epsilon Datset\"\n",
    "learning_rate_preset = 0.001\n",
    "batch_size_preset = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gisette Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gisette Dataset\n",
    "#2 class, 6000 data points, ~5000 features\n",
    "\n",
    "# Loading training data\n",
    "dataset = pd.read_csv(\"gisette_scale\", sep=' ', header=None)\n",
    "dataset = dataset.to_numpy()\n",
    "for i in range(1, dataset.shape[1]-1):\n",
    "    dataset[:, i] = [float(value.split(':')[1]) if isinstance(value, str) else value for value in dataset[:, i]]\n",
    "dataset = dataset[:, :-2]\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "for i in range(1, dataset.shape[0]):\n",
    "    if dataset[i - 1, 0] == -1:\n",
    "        dataset[i - 1, 0] = 0\n",
    "\n",
    "#print(dataset)\n",
    "#print(dataset.shape)\n",
    "\n",
    "# Splitting off data for training and validation\n",
    "train_split = int(0.8 * len(dataset))\n",
    "X_train = dataset[:train_split, 1:].astype(np.float32)\n",
    "y_train = dataset[:train_split, 0].astype(np.float32)\n",
    "X_test = dataset[train_split:, 1:].astype(np.float32)\n",
    "y_test = dataset[train_split:, 0].astype(np.float32)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "# Normalize data set\n",
    "denominator = X_train.max(0) - X_train.min(0)\n",
    "X_train_normalized = (X_train - X_train.min(0)) / np.where(denominator != 0, denominator, 1)\n",
    "denominator = X_test.max(0) - X_test.min(0)\n",
    "X_test_normalized = (X_test - X_test.min(0)) / np.where(denominator != 0, denominator, 1)\n",
    "\n",
    "print(\"X_train_normalized: \", X_train_normalized)\n",
    "print(\"X_test_normalized: \", X_test_normalized)\n",
    "\n",
    "# Turn data to tensor\n",
    "X_train_tensor = torch.from_numpy(X_train_normalized)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test_normalized)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "print(X_train_tensor.size())\n",
    "print(y_train_tensor.size())\n",
    "print(X_test_tensor.size())\n",
    "print(y_test_tensor.size())\n",
    "\n",
    "# Learning Rate and Batch size\n",
    "dataset_name = \"Gisette Datset\"\n",
    "learning_rate_preset = 0.005\n",
    "batch_size_preset = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9bae8",
   "metadata": {},
   "source": [
    "### Section 1.1. Vanilia Gradient Descent and Stochastic Gradient Descent\n",
    "\n",
    "Initially test training dataset with custom algorithms and pytorch package. We will verify our result of our algorithms by comparing the pytorch package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Algorithm for Vanilia Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1017f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Vanilia Gradient Descent Algorithms\n",
    "def gradient_descent(X, y, learning_rate, num_epochs):\n",
    "    num_samples, num_features = X.shape\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = np.zeros(num_features)\n",
    "    b = 0\n",
    "\n",
    "    loss_history = []\n",
    "    error_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Calculate predictions\n",
    "        y_pred = np.dot(X, w) + b\n",
    "        \n",
    "        # Calculate the difference between predictions and actual values\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # Calculate the gradient\n",
    "        w_gradient = (1/num_samples) * np.dot(X.T, error)\n",
    "        b_gradient = (1/num_samples) * np.sum(error)\n",
    "        \n",
    "        # Update theta using the learning rate and gradient\n",
    "        w -= learning_rate * w_gradient\n",
    "        b -= learning_rate * b_gradient\n",
    "\n",
    "        # Record the loss\n",
    "        loss = np.mean(np.square(error))\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # Record the error rate\n",
    "        train_error_rate = calculate_error_rate(X_train_normalized,  y_train, torch.from_numpy(y_pred))\n",
    "        error_history.append(train_error_rate)\n",
    "\n",
    "        # Print the loss every specific epochs\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}')\n",
    "    \n",
    "    return w, b, loss_history, error_history\n",
    "\n",
    "# Train the model using gradient descent\n",
    "learning_rate = learning_rate_preset\n",
    "num_iterations = 100\n",
    "w, b, loss_history, error_history = gradient_descent(X_train_normalized, y_train, learning_rate, num_iterations)\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "\n",
    "for i, w_i in enumerate(w):\n",
    "    print(f\"w{i} =\", w_i)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Plot the training loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate history\n",
    "plt.plot(error_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "y_pred = np.dot(X_train_normalized, w) + b\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, torch.from_numpy(y_pred))\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    y_pred = np.dot(X_test_normalized, w) + b\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized,  y_test, torch.from_numpy(y_pred))\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Algorithm for Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Stochastic Gradient Descent Algorithms\n",
    "def stochastic_gradient_descent(X, y, learning_rate, num_epochs, batch_size):\n",
    "    num_samples, num_features = X.shape\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    # Initialize weights and bias\n",
    "    w = np.zeros(num_features)\n",
    "    b = 0\n",
    "    \n",
    "    loss_history = []\n",
    "    error_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data for each epoch\n",
    "        permutation = np.random.permutation(num_samples)\n",
    "        X_shuffled = X[permutation]\n",
    "        y_shuffled = y[permutation]\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            # Select the current batch\n",
    "            start = batch * batch_size\n",
    "            end = (batch + 1) * batch_size\n",
    "            X_batch = X_shuffled[start:end]\n",
    "            y_batch = y_shuffled[start:end]\n",
    "\n",
    "            # Calculate predictions\n",
    "            y_pred = np.dot(X_batch, w) + b\n",
    "\n",
    "            # Calculate the difference between predictions and actual values\n",
    "            error = y_pred - y_batch\n",
    "\n",
    "            # Calculate the gradients\n",
    "            w_gradient = (1 / batch_size) * np.dot(X_batch.T, error)\n",
    "            b_gradient = (1 / batch_size) * np.sum(error)\n",
    "\n",
    "            # Update weights and bias\n",
    "            w -= learning_rate * w_gradient\n",
    "            b -= learning_rate * b_gradient\n",
    "        \n",
    "        # General Output\n",
    "        y_pred = np.dot(X_train_normalized, w) + b\n",
    "        error = y_pred - y_train\n",
    "\n",
    "        # Record the loss\n",
    "        error = y_pred\n",
    "        loss = np.mean(np.square(error))\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # Record the error rate\n",
    "        train_error_rate = calculate_error_rate(X_train_normalized,  y_train, torch.from_numpy(y_pred))\n",
    "        error_history.append(train_error_rate)\n",
    "\n",
    "        # Print the loss every specific epochs\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}')\n",
    "            \n",
    "    return w, b, loss_history, error_history\n",
    "\n",
    "# Train the model using stochastic gradient descent\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 1000\n",
    "batch_size = batch_size_preset\n",
    "w, b, loss_history, error_history = stochastic_gradient_descent(X_train_normalized, y_train, learning_rate, num_epochs, batch_size)\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for i, w_i in enumerate(w):\n",
    "    print(f\"w{i} =\", w_i)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Plot the training loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate history\n",
    "plt.plot(error_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "y_pred = np.dot(X_train_normalized, w) + b\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, torch.from_numpy(y_pred))\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    y_pred = np.dot(X_test_normalized, w) + b\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized,  y_test, torch.from_numpy(y_pred))\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707afbc",
   "metadata": {},
   "source": [
    "**Pytorch Package for Vanilia Gradient Descent**\n",
    "\n",
    "(It is just a Vanilia Gradient Descent... They call it SGD is confusing...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc595f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pytorch Vanilia Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 1000\n",
    "\n",
    "# Define the number of features\n",
    "num_features = X_train_tensor.size()[1]\n",
    "\n",
    "# Define the model parameters (weights and bias)\n",
    "w = torch.zeros(num_features, dtype=torch.float, requires_grad=True)\n",
    "# w = torch.tensor([1., 1., 1.], requires_grad=True)\n",
    "b = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "# b = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "loss_history = []\n",
    "error_history = []\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Vanilla Gradient Descent)\n",
    "optimizer = torch.optim.SGD([w, b], lr=learning_rate, weight_decay=0)\n",
    "\n",
    "# Perform gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = torch.matmul(X_train_tensor.float(), w) + b\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record the loss\n",
    "    loss_history.append(loss.detach().numpy())\n",
    "    \n",
    "    # Record the error rate\n",
    "    train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "    error_history.append(train_error_rate)\n",
    "\n",
    "    # Print the loss every specific epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}')\n",
    "        \n",
    "\n",
    "# Print learned parameters\n",
    "print('Trained weights:', w)\n",
    "print('Trained bias:', b)\n",
    "\n",
    "# Plot the training loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate history\n",
    "plt.plot(error_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "outputs = torch.matmul(X_train_tensor.float(), w) + b\n",
    "train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    outputs = torch.matmul(X_test_tensor.float(), w) + b\n",
    "    test_error_rate = calculate_error_rate(X_test_tensor,  y_test_tensor, outputs)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Package for Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pytorch Stochastic Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs and batch size\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 500\n",
    "batch_size = batch_size_preset\n",
    "\n",
    "# Define the number of samples and features\n",
    "num_samples  = X_train_tensor.size()[0]\n",
    "num_features = X_train_tensor.size()[1]\n",
    "\n",
    "# Define the model parameters (weights and bias)\n",
    "w = torch.zeros(num_features, dtype=torch.float, requires_grad=True)\n",
    "# w = torch.tensor([1., 1., 1.], requires_grad=True)\n",
    "b = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "# b = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "loss_history = []\n",
    "error_history = []\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Vanilla Gradient Descent)\n",
    "optimizer = torch.optim.SGD([w, b], lr=learning_rate, weight_decay=0)\n",
    "\n",
    "# Perform stochastic gradient descent\n",
    "num_batches = num_samples // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the data for each epoch\n",
    "    permutation = torch.randperm(num_samples)\n",
    "    X_shuffled = X_train_tensor[permutation]\n",
    "    y_shuffled = y_train_tensor[permutation]\n",
    "    for batch in range(num_batches):\n",
    "        # Select the current batch\n",
    "        start = batch * batch_size\n",
    "        end = (batch + 1) * batch_size\n",
    "        X_batch = X_shuffled[start:end]\n",
    "        y_batch = y_shuffled[start:end]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = torch.matmul(X_batch.float(), w) + b\n",
    "        loss = criterion(outputs, y_batch.float())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # General Output\n",
    "    outputs = torch.matmul(X_train_tensor.float(), w) + b\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "\n",
    "    # Record the loss\n",
    "    loss_history.append(loss.detach().numpy())\n",
    "    \n",
    "    # Record the error rate\n",
    "    train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "    error_history.append(train_error_rate)\n",
    "\n",
    "    # Print the loss every specific epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}')\n",
    "\n",
    "# Print learned parameters\n",
    "print('Trained weights:', w)\n",
    "print('Trained bias:', b)\n",
    "\n",
    "# Plot the training loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate history\n",
    "plt.plot(error_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "outputs = torch.matmul(X_train_tensor.float(), w) + b\n",
    "train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    outputs = torch.matmul(X_test_tensor.float(), w) + b\n",
    "    test_error_rate = calculate_error_rate(X_test_tensor,  y_test_tensor, outputs)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2. Linear Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa3f70",
   "metadata": {},
   "source": [
    "**Neural Network**\n",
    "\n",
    "This neural network is simply a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom neural network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features=1):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.activation_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.activation_stack(x)\n",
    "        return torch.squeeze(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Neural Network with Vanilia Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16cb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neural Network with Vanilia Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 1000\n",
    "\n",
    "# Define the number of samples and features\n",
    "num_samples  = X_train_tensor.size()[0]\n",
    "num_features = X_train_tensor.size()[1]\n",
    "num_class = len(torch.unique(y_train_tensor))\n",
    "print(num_samples)\n",
    "print(num_features)\n",
    "print(num_class)\n",
    "\n",
    "# Define the model parameters\n",
    "loss_history = []\n",
    "error_history = []\n",
    "\n",
    "# Define neural network model, loss criterion and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "model = NeuralNetwork(num_features)\n",
    "print(model)\n",
    "optimizer = custom_optimizer_SGD(model.parameters(), lr=learning_rate, weight_decay = 0)\n",
    "\n",
    "#for name, param in NeuralNetwork_model.named_parameters():\n",
    "#    print( name )\n",
    "#    values = torch.ones( param.shape )\n",
    "#    param.data = values\n",
    "    \n",
    "# Perform training\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward propagation to obtain the predicted output\n",
    "    outputs = model(X_train_tensor.float())\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "    \n",
    "    # Backward propagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record the loss\n",
    "    loss_history.append(loss.detach().numpy())\n",
    "    \n",
    "    # Record the error rate\n",
    "    train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "    error_history.append(train_error_rate)\n",
    "    \n",
    "    # Print the loss every specific epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}')\n",
    "        \n",
    "# Print learned parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'{name}: {param.data}')\n",
    "        \n",
    "# Plot the training loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate history\n",
    "plt.plot(error_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "outputs = model(X_train_tensor.float())\n",
    "train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    outputs = model(X_test_tensor.float())\n",
    "    test_error_rate = calculate_error_rate(X_test_tensor,  y_test_tensor, outputs)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Neural Network with Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neural Network with Stochastic Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs and batch size\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 1000\n",
    "batch_size = batch_size_preset\n",
    "\n",
    "# Define the number of samples and features\n",
    "num_samples  = X_train_tensor.size()[0]\n",
    "num_features = X_train_tensor.size()[1]\n",
    "\n",
    "# Define the model parameters\n",
    "loss_history = []\n",
    "error_history = []\n",
    "\n",
    "# Define neural network model, loss criterion and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "model = NeuralNetwork(num_features)\n",
    "print(model)\n",
    "optimizer = custom_optimizer_SGD(model.parameters(), lr=learning_rate, weight_decay = 0)\n",
    "\n",
    "#for name, param in NeuralNetwork_model.named_parameters():\n",
    "#    print( name )\n",
    "#    values = torch.ones( param.shape )\n",
    "#    param.data = values\n",
    "    \n",
    "# Perform training\n",
    "model.train()\n",
    "num_batches = num_samples // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the data for each epoch\n",
    "    permutation = torch.randperm(num_samples)\n",
    "    X_shuffled = X_train_tensor[permutation]\n",
    "    y_shuffled = y_train_tensor[permutation]\n",
    "    for batch in range(num_batches):\n",
    "        # Select the current batch\n",
    "        start = batch * batch_size\n",
    "        end = (batch + 1) * batch_size\n",
    "        X_batch = X_shuffled[start:end]\n",
    "        y_batch = y_shuffled[start:end]\n",
    "\n",
    "        # Forward propagation to obtain the predicted output\n",
    "        outputs = model(X_batch.float())\n",
    "    \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, y_batch.float())\n",
    "    \n",
    "        # Backward propagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # General Output\n",
    "    outputs = model(X_train_tensor.float())\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "\n",
    "    # Record the loss\n",
    "    loss_history.append(loss.detach().numpy())\n",
    "    \n",
    "    # Record the error rate\n",
    "    train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "    error_history.append(train_error_rate)\n",
    "\n",
    "    # Print the loss every specific epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}')\n",
    "        \n",
    "# Print learned parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'{name}: {param.data}')\n",
    "        \n",
    "# Plot the training loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate history\n",
    "plt.plot(error_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "outputs = model(X_train_tensor.float())\n",
    "train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    outputs = model(X_test_tensor.float())\n",
    "    test_error_rate = calculate_error_rate(X_test_tensor,  y_test_tensor, outputs)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.3. Fedearted Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1.3.1 Fedearted Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training function for Federated Learning with Vanilia Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Federated Learning Training with vanilia gradient descent method\n",
    "def FedLearnTrainGDVanilia(num_clients, local_update_epochs, loss_cost_history_total, error_cost_history_total, send_cost_history_total):\n",
    "    # Define neural network model, loss criterion and optimizer\n",
    "    model = NeuralNetwork(X_train_tensor.size()[1])\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = custom_optimizer_SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Preprocess the client data\n",
    "    X_train_client = [None] * num_clients\n",
    "    y_train_client = [None] * num_clients\n",
    "    client_row = math.floor( X_train_tensor.size(dim=0) / num_clients )\n",
    "    for client in range(num_clients):\n",
    "        X_train_client[client] = X_train_tensor[(client)*client_row : (client+1)*client_row]\n",
    "        y_train_client[client] = y_train_tensor[(client)*client_row : (client+1)*client_row]\n",
    "\n",
    "    # Establish client devices\n",
    "    client_model = [None] * num_clients\n",
    "    client_optimizer = [None] * num_clients\n",
    "    client_device = [None] * num_clients\n",
    "    client_weights = [None] * num_clients\n",
    "    for client in range(num_clients):\n",
    "        client_model[client] = NeuralNetwork(X_train_client[client].size()[1])\n",
    "        client_optimizer[client] = custom_optimizer_SGD(client_model[client].parameters(), lr=learning_rate)\n",
    "        client_device[client] = ClientDevice(client_model[client], criterion, client_optimizer[client], X_train_client[client], y_train_client[client])\n",
    "\n",
    "    # Cost History\n",
    "    loss_cost_history = []\n",
    "    error_cost_history = []\n",
    "    send_cost_history = []\n",
    "    send_cost = 0\n",
    "\n",
    "    # Perform training\n",
    "    global_weights = model.state_dict()\n",
    "    #print(f'Initial global weights are: {global_weights}')\n",
    "    for epoch in range(num_epochs):\n",
    "        client_weights_total = []\n",
    "\n",
    "        # Clients local update\n",
    "        for client in range(num_clients):\n",
    "            # Transmit the global weight to clients\n",
    "            client_device[client].load_global_weights(global_weights)\n",
    "            client_weights[client] = client_device[client].update_weights_GDVanilia(local_update_epochs)\n",
    "\n",
    "            # Send client weights to the server\n",
    "            send_client_weights(client_weights_total, client_weights[client])\n",
    "            client_weights_size = sum(value.numel() for value in client_weights[client].values())\n",
    "            send_cost = send_cost + client_weights_size\n",
    "\n",
    "        # Aggregate client weights on the server\n",
    "        aggregated_weights = Federated_Averaging(client_weights_total)\n",
    "\n",
    "        # Update global weights with aggregated weights\n",
    "        global_weights.update(aggregated_weights)\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "        # General Output\n",
    "        outputs = model(X_train_tensor.float())\n",
    "        loss = criterion(outputs, y_train_tensor.float())\n",
    "\n",
    "        # Record the loss\n",
    "        loss_cost_history.append(loss.item())\n",
    "\n",
    "        # Record the error rate\n",
    "        train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "        error_cost_history.append(train_error_rate)\n",
    "\n",
    "        # Record the send cost\n",
    "        send_cost_history.append(send_cost)\n",
    "\n",
    "        # Print the loss every specific epochs\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}, Culminative Send Cost: {send_cost}')\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "\n",
    "    # Plot send cost history\n",
    "    plt.plot(send_cost_history)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Send Cost\")\n",
    "    plt.title(\"Send Cost History\")\n",
    "    plt.show()\n",
    "    print(f'Total send cost: {send_cost}')\n",
    "\n",
    "    # Plot the training loss history\n",
    "    plt.plot(loss_cost_history)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss History\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate history\n",
    "    plt.plot(error_cost_history)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate History\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate train error rate\n",
    "    outputs = model(X_train_tensor.float())\n",
    "    train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "    print(\"Train error rate:\", train_error_rate)\n",
    "        \n",
    "    # Calculate test error rate if test data is provided\n",
    "    if X_test is not None and y_test is not None:\n",
    "        outputs = model(X_test_tensor.float())\n",
    "        test_error_rate = calculate_error_rate(X_test_tensor,  y_test_tensor, outputs)\n",
    "        print(\"Test error rate:\", test_error_rate)\n",
    "\n",
    "    # Record the history of loss, error and send_cost\n",
    "    loss_cost_history_total.append(loss_cost_history)\n",
    "    error_cost_history_total.append(error_cost_history)\n",
    "    send_cost_history_total.append(send_cost_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training function for Federated Learning with Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Federated Learning Training with stochastic gradient descent method\n",
    "def FedLearnTrainGDStochastic(num_clients, local_update_epochs, loss_cost_history_total, error_cost_history_total, send_cost_history_total):\n",
    "    # Define neural network model, loss criterion and optimizer\n",
    "    model = NeuralNetwork(X_train_tensor.size()[1])\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = custom_optimizer_SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Preprocess the client data\n",
    "    X_train_client = [None] * num_clients\n",
    "    y_train_client = [None] * num_clients\n",
    "    client_row = math.floor( X_train_tensor.size(dim=0) / num_clients )\n",
    "    for client in range(num_clients):\n",
    "        X_train_client[client] = X_train_tensor[(client)*client_row : (client+1)*client_row]\n",
    "        y_train_client[client] = y_train_tensor[(client)*client_row : (client+1)*client_row]\n",
    "\n",
    "    # Establish client devices\n",
    "    client_model = [None] * num_clients\n",
    "    client_optimizer = [None] * num_clients\n",
    "    client_device = [None] * num_clients\n",
    "    client_weights = [None] * num_clients\n",
    "    for client in range(num_clients):\n",
    "        client_model[client] = NeuralNetwork(X_train_client[client].size()[1])\n",
    "        client_optimizer[client] = custom_optimizer_SGD(client_model[client].parameters(), lr=learning_rate)\n",
    "        client_device[client] = ClientDevice(client_model[client], criterion, client_optimizer[client], X_train_client[client], y_train_client[client])\n",
    "\n",
    "    # Cost History\n",
    "    loss_cost_history = []\n",
    "    error_cost_history = []\n",
    "    send_cost_history = []\n",
    "    send_cost = 0\n",
    "\n",
    "    # Perform training\n",
    "    global_weights = model.state_dict()\n",
    "    #print(f'Initial global weights are: {global_weights}')\n",
    "    for epoch in range(num_epochs):\n",
    "        client_weights_total = []\n",
    "\n",
    "        # Clients local update\n",
    "        for client in range(num_clients):\n",
    "            # Transmit the global weight to clients\n",
    "            client_device[client].load_global_weights(global_weights)\n",
    "            client_weights[client] = client_device[client].update_weights_GDStochastic(local_update_epochs, int(batch_size / num_clients))\n",
    "\n",
    "            # Send client weights to the server\n",
    "            send_client_weights(client_weights_total, client_weights[client])\n",
    "            client_weights_size = sum(value.numel() for value in client_weights[client].values())\n",
    "            send_cost = send_cost + client_weights_size\n",
    "\n",
    "        # Aggregate client weights on the server\n",
    "        aggregated_weights = Federated_Averaging(client_weights_total)\n",
    "\n",
    "        # Update global weights with aggregated weights\n",
    "        global_weights.update(aggregated_weights)\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "        # General Output\n",
    "        outputs = model(X_train_tensor.float())\n",
    "        loss = criterion(outputs, y_train_tensor.float())\n",
    "\n",
    "        # Record the loss\n",
    "        loss_cost_history.append(loss.item())\n",
    "\n",
    "        # Record the error rate\n",
    "        train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "        error_cost_history.append(train_error_rate)\n",
    "\n",
    "        # Record the send cost\n",
    "        send_cost_history.append(send_cost)\n",
    "\n",
    "        # Print the loss every specific epochs\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}, Error: {train_error_rate:.16f}, Culminative Send Cost: {send_cost}')\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "\n",
    "    # Plot send cost history\n",
    "    plt.plot(send_cost_history)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Send Cost\")\n",
    "    plt.title(\"Send Cost History\")\n",
    "    plt.show()\n",
    "    print(f'Total send cost: {send_cost}')\n",
    "\n",
    "    # Plot the training loss history\n",
    "    plt.plot(loss_cost_history)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss History\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate history\n",
    "    plt.plot(error_cost_history)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate History\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate train error rate\n",
    "    outputs = model(X_train_tensor.float())\n",
    "    train_error_rate = calculate_error_rate(X_train_tensor,  y_train_tensor, outputs)\n",
    "    print(\"Train error rate:\", train_error_rate)\n",
    "        \n",
    "    # Calculate test error rate if test data is provided\n",
    "    if X_test is not None and y_test is not None:\n",
    "        outputs = model(X_test_tensor.float())\n",
    "        test_error_rate = calculate_error_rate(X_test_tensor,  y_test_tensor, outputs)\n",
    "        print(\"Test error rate:\", test_error_rate)\n",
    "\n",
    "    # Record the history of loss, error and send_cost\n",
    "    loss_cost_history_total.append(loss_cost_history)\n",
    "    error_cost_history_total.append(error_cost_history)\n",
    "    send_cost_history_total.append(send_cost_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1.3.2 Fedearted Learning Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment with number of clients of Vanilia Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment for num_clients with Vanilia Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 500\n",
    "num_clients_list = [1,5,10,15,20]\n",
    "local_update_epochs_list = [1]\n",
    "\n",
    "# Cost History Total\n",
    "num_clients_list_size = len(num_clients_list)\n",
    "local_update_epochs_list_size = len(local_update_epochs_list)\n",
    "loss_cost_history_total = []\n",
    "error_cost_history_total = []\n",
    "send_cost_history_total = []\n",
    "\n",
    "# Compare the num_clients\n",
    "local_update_epochs = local_update_epochs_list[0]\n",
    "for num_clients in num_clients_list:\n",
    "    print(f'=== The training for num_clients is {num_clients} ===')\n",
    "    FedLearnTrainGDVanilia(num_clients, local_update_epochs, loss_cost_history_total, error_cost_history_total, send_cost_history_total)\n",
    "\n",
    "print(f'=== The Experiment Result ===')\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "print(\"Vanilia Gradient Descent\")\n",
    "\n",
    "# Plot the training loss rate between cost history with clients\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(send_cost_history_total[i], loss_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss Rate vs Send Cost (with different clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'Loss_VS_SendCost_num_clients_{dataset_name}_VGD.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate between cost history with clients\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(send_cost_history_total[i], error_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate vs Send Cost (with different clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'ErrorRate_VS_SendCost_num_clients_{dataset_name}_VGD.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training loss rate between cost history with num_clients per clients\n",
    "min_cost_list = send_cost_history_total[0]\n",
    "for sublist in send_cost_history_total:\n",
    "    if len(sublist) < len(min_cost_list):\n",
    "        min_cost_list = sublist\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(min_cost_list, loss_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost per clients\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss Rate vs Send Cost per clients (with different number of clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'Loss_vs_Send_Cost_num_clients_{dataset_name}_VGD_per_clients.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training loss rate between cost history with num_clients per clients\n",
    "min_cost_list = send_cost_history_total[0]\n",
    "for sublist in send_cost_history_total:\n",
    "    if len(sublist) < len(min_cost_list):\n",
    "        min_cost_list = sublist\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(min_cost_list, error_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost per clients\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate vs Send Cost per clients (with different number of clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'ErrorRate_vs_Send_Cost_num_clients_{dataset_name}_VGD_per_clients.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment with number of clients of Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment for num_clients with Stochastic Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 100\n",
    "batch_size = batch_size_preset\n",
    "num_clients_list = [1,5,10,15,20]\n",
    "local_update_epochs_list = [2]\n",
    "\n",
    "# Cost History Total\n",
    "num_clients_list_size = len(num_clients_list)\n",
    "local_update_epochs_list_size = len(local_update_epochs_list)\n",
    "loss_cost_history_total = []\n",
    "error_cost_history_total = []\n",
    "send_cost_history_total = []\n",
    "\n",
    "# Compare the num_clients\n",
    "local_update_epochs = local_update_epochs_list[0]\n",
    "for num_clients in num_clients_list:\n",
    "    print(f'=== The training for num_clients is {num_clients} ===')\n",
    "    FedLearnTrainGDStochastic(num_clients, local_update_epochs, loss_cost_history_total, error_cost_history_total, send_cost_history_total)\n",
    "\n",
    "print(f'=== The Experiment Result ===')\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "print(\"Stochastic Gradient Descent\")\n",
    "\n",
    "# Plot the training loss rate between cost history with clients\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(send_cost_history_total[i], loss_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss Rate vs Send Cost (with different clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'Loss_VS_SendCost_num_clients_{dataset_name}_SGD.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate between cost history with clients\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(send_cost_history_total[i], error_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate vs Send Cost (with different clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'ErrorRate_VS_SendCost_num_clients_{dataset_name}_SGD.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training loss rate between cost history with num_clients per clients\n",
    "min_cost_list = send_cost_history_total[0]\n",
    "for sublist in send_cost_history_total:\n",
    "    if len(sublist) < len(min_cost_list):\n",
    "        min_cost_list = sublist\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(min_cost_list, loss_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost per clients\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss Rate vs Send Cost per clients (with different number of clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'Loss_vs_Send_Cost_num_clients_{dataset_name}_SGD_per_clients.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training loss rate between cost history with num_clients per clients\n",
    "min_cost_list = send_cost_history_total[0]\n",
    "for sublist in send_cost_history_total:\n",
    "    if len(sublist) < len(min_cost_list):\n",
    "        min_cost_list = sublist\n",
    "for i in range(num_clients_list_size):\n",
    "    plt.plot(min_cost_list, error_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost per clients\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate vs Send Cost per clients (with different number of clients)\")\n",
    "plt.legend(num_clients_list)\n",
    "plt.savefig(f'ErrorRate_vs_Send_Cost_num_clients_{dataset_name}_SGD_per_clients.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment with local update epochs of Vanilia Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment for local_update_epochs with Vanilia Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 1000\n",
    "num_clients_list = [5]\n",
    "local_update_epochs_list = [1,2,3,4,5]\n",
    "\n",
    "# Cost History Total\n",
    "num_clients_list_size = len(num_clients_list)\n",
    "local_update_epochs_list_size = len(local_update_epochs_list)\n",
    "loss_cost_history_total = []\n",
    "error_cost_history_total = []\n",
    "send_cost_history_total = []\n",
    "\n",
    "# Compare the local_update_epochs\n",
    "num_clients = num_clients_list[0]\n",
    "for local_update_epochs in local_update_epochs_list:\n",
    "    print(f'=== The training for local_update_epochs is {local_update_epochs} ===')\n",
    "    FedLearnTrainGDVanilia(num_clients, local_update_epochs, loss_cost_history_total, error_cost_history_total, send_cost_history_total)\n",
    "\n",
    "print(f'=== The Experiment Result ===')\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "print(\"Vanilia Gradient Descent\")\n",
    "\n",
    "# Plot the training loss rate between cost history with local update epochs\n",
    "for i in range(local_update_epochs_list_size):\n",
    "    plt.plot(send_cost_history_total[i], loss_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss Rate vs Send Cost (with different local update epochs)\")\n",
    "plt.legend(local_update_epochs_list)\n",
    "plt.savefig(f'Loss_VS_SendCost_local_update_epochs_{dataset_name}_VGD.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate between cost history with local update epochs\n",
    "for i in range(local_update_epochs_list_size):\n",
    "    plt.plot(send_cost_history_total[i], error_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate vs Send Cost (with different local update epochs)\")\n",
    "plt.legend(local_update_epochs_list)\n",
    "plt.savefig(f'ErrorRate_VS_SendCost_local_update_epochs_{dataset_name}_VGD.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment with local update epochs of Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment for local_update_epochs with Stochastic Gradient Descent\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 500\n",
    "batch_size = batch_size_preset\n",
    "num_clients_list = [2]\n",
    "local_update_epochs_list = [1,2,3,4,5]\n",
    "\n",
    "# Cost History Total\n",
    "num_clients_list_size = len(num_clients_list)\n",
    "local_update_epochs_list_size = len(local_update_epochs_list)\n",
    "loss_cost_history_total = []\n",
    "error_cost_history_total = []\n",
    "send_cost_history_total = []\n",
    "\n",
    "# Compare the local_update_epochs\n",
    "num_clients = num_clients_list[0]\n",
    "for local_update_epochs in local_update_epochs_list:\n",
    "    print(f'=== The training for local_update_epochs is {local_update_epochs} ===')\n",
    "    FedLearnTrainGDStochastic(num_clients, local_update_epochs, loss_cost_history_total, error_cost_history_total, send_cost_history_total)\n",
    "\n",
    "print(f'=== The Experiment Result ===')\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "print(\"Stochastic Gradient Descent\")\n",
    "\n",
    "# Plot the training loss rate between cost history with local update epochs\n",
    "for i in range(local_update_epochs_list_size):\n",
    "    plt.plot(send_cost_history_total[i], loss_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Training Loss Rate\")\n",
    "plt.title(\"Training Loss Rate vs Send Cost (with different local update epochs)\")\n",
    "plt.legend(local_update_epochs_list)\n",
    "plt.savefig(f'Loss_VS_SendCost_local_update_epochs_{dataset_name}_SGD.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the error rate between cost history with local update epochs\n",
    "for i in range(local_update_epochs_list_size):\n",
    "    plt.plot(send_cost_history_total[i], error_cost_history_total[i])\n",
    "plt.xlabel(\"Send Cost\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate vs Send Cost (with different local update epochs)\")\n",
    "plt.legend(local_update_epochs_list)\n",
    "plt.savefig(f'ErrorRate_VS_SendCost_local_update_epochs_{dataset_name}_SGD.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Non-Linear Training Model\n",
    "Here we focus on dataset requires mainly non-linear training algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.0 Data Loading and Preprocessing\n",
    "\n",
    "Here we load the data for the expriements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNIST Dataset\n",
    "\n",
    "# Loading training data\n",
    "dataset = pd.read_csv(\"mnist_train.csv\")\n",
    "dataset = dataset.to_numpy()\n",
    "X_train = dataset[:2000, 1:].astype(np.int32)\n",
    "y_train = dataset[:2000, 0].astype(np.int32)\n",
    "\n",
    "# Loading testing data\n",
    "dataset = pd.read_csv(\"mnist_test.csv\")\n",
    "dataset = dataset.to_numpy()\n",
    "X_test = dataset[:1000, 1:].astype(np.int32)\n",
    "y_test = dataset[:1000, 0].astype(np.int32)\n",
    "\n",
    "# Translation of data  \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "y_train = y_train.astype('float32') \n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "y_test = y_test.astype('float32') \n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "# Normalize data set\n",
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0\n",
    "\n",
    "# Turn data to tensor\n",
    "X_train_tensor = torch.from_numpy(X_train_normalized)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test_normalized)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "print(X_train_tensor)\n",
    "print(y_train_tensor)\n",
    "print(X_test_tensor)\n",
    "print(y_test_tensor)\n",
    "print(X_train_tensor.size())\n",
    "print(y_train_tensor.size())\n",
    "print(X_test_tensor.size())\n",
    "print(y_test_tensor.size())\n",
    "\n",
    "# Learning Rate and Batch size\n",
    "dataset_name = \"MNIST Dataset\"\n",
    "learning_rate_preset = 0.01\n",
    "batch_size_preset = 100\n",
    "CNN_input_shape_preset = (-1, 1, 28, 28)\n",
    "\n",
    "# Number of samples, features, and classes\n",
    "num_samples_preset  = X_train_tensor.size()[0]\n",
    "num_features_preset = X_train_tensor.size()[1]\n",
    "num_classes_preset = len(torch.unique(y_train_tensor))\n",
    "\n",
    "# Translate the tensor to dataset\n",
    "MINST_train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "MINST_test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Translate to DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(MINST_train_dataset, batch_size = batch_size_preset, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(MINST_test_dataset, batch_size = batch_size_preset, shuffle = True)\n",
    "\n",
    "# Visualize the first 10 images\n",
    "for i in range(10):\n",
    "    plt.imshow(X_train_tensor[i], cmap='gray')\n",
    "    plt.show()\n",
    "    print(y_train_tensor[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR-10 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59.  62.  63.]\n",
      "   [ 43.  46.  45.]\n",
      "   [ 50.  48.  43.]\n",
      "   ...\n",
      "   [158. 132. 108.]\n",
      "   [152. 125. 102.]\n",
      "   [148. 124. 103.]]\n",
      "\n",
      "  [[ 16.  20.  20.]\n",
      "   [  0.   0.   0.]\n",
      "   [ 18.   8.   0.]\n",
      "   ...\n",
      "   [123.  88.  55.]\n",
      "   [119.  83.  50.]\n",
      "   [122.  87.  57.]]\n",
      "\n",
      "  [[ 25.  24.  21.]\n",
      "   [ 16.   7.   0.]\n",
      "   [ 49.  27.   8.]\n",
      "   ...\n",
      "   [118.  84.  50.]\n",
      "   [120.  84.  50.]\n",
      "   [109.  73.  42.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[208. 170.  96.]\n",
      "   [201. 153.  34.]\n",
      "   [198. 161.  26.]\n",
      "   ...\n",
      "   [160. 133.  70.]\n",
      "   [ 56.  31.   7.]\n",
      "   [ 53.  34.  20.]]\n",
      "\n",
      "  [[180. 139.  96.]\n",
      "   [173. 123.  42.]\n",
      "   [186. 144.  30.]\n",
      "   ...\n",
      "   [184. 148.  94.]\n",
      "   [ 97.  62.  34.]\n",
      "   [ 83.  53.  34.]]\n",
      "\n",
      "  [[177. 144. 116.]\n",
      "   [168. 129.  94.]\n",
      "   [179. 142.  87.]\n",
      "   ...\n",
      "   [216. 184. 140.]\n",
      "   [151. 118.  84.]\n",
      "   [123.  92.  72.]]]\n",
      "\n",
      "\n",
      " [[[154. 177. 187.]\n",
      "   [126. 137. 136.]\n",
      "   [105. 104.  95.]\n",
      "   ...\n",
      "   [ 91.  95.  71.]\n",
      "   [ 87.  90.  71.]\n",
      "   [ 79.  81.  70.]]\n",
      "\n",
      "  [[140. 160. 169.]\n",
      "   [145. 153. 154.]\n",
      "   [125. 125. 118.]\n",
      "   ...\n",
      "   [ 96.  99.  78.]\n",
      "   [ 77.  80.  62.]\n",
      "   [ 71.  73.  61.]]\n",
      "\n",
      "  [[140. 155. 164.]\n",
      "   [139. 146. 149.]\n",
      "   [115. 115. 112.]\n",
      "   ...\n",
      "   [ 79.  82.  64.]\n",
      "   [ 68.  70.  55.]\n",
      "   [ 67.  69.  55.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[175. 167. 166.]\n",
      "   [156. 154. 160.]\n",
      "   [154. 160. 170.]\n",
      "   ...\n",
      "   [ 42.  34.  36.]\n",
      "   [ 61.  53.  57.]\n",
      "   [ 93.  83.  91.]]\n",
      "\n",
      "  [[165. 154. 128.]\n",
      "   [156. 152. 130.]\n",
      "   [159. 161. 142.]\n",
      "   ...\n",
      "   [103.  93.  96.]\n",
      "   [123. 114. 120.]\n",
      "   [131. 121. 131.]]\n",
      "\n",
      "  [[163. 148. 120.]\n",
      "   [158. 148. 122.]\n",
      "   [163. 156. 133.]\n",
      "   ...\n",
      "   [143. 133. 139.]\n",
      "   [143. 134. 142.]\n",
      "   [143. 133. 144.]]]\n",
      "\n",
      "\n",
      " [[[255. 255. 255.]\n",
      "   [253. 253. 253.]\n",
      "   [253. 253. 253.]\n",
      "   ...\n",
      "   [253. 253. 253.]\n",
      "   [253. 253. 253.]\n",
      "   [253. 253. 253.]]\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   ...\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]]\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   ...\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113. 120. 112.]\n",
      "   [111. 118. 111.]\n",
      "   [105. 112. 106.]\n",
      "   ...\n",
      "   [ 72.  81.  80.]\n",
      "   [ 72.  80.  79.]\n",
      "   [ 72.  80.  79.]]\n",
      "\n",
      "  [[111. 118. 110.]\n",
      "   [104. 111. 104.]\n",
      "   [ 99. 106.  98.]\n",
      "   ...\n",
      "   [ 68.  75.  73.]\n",
      "   [ 70.  76.  75.]\n",
      "   [ 78.  84.  82.]]\n",
      "\n",
      "  [[106. 113. 105.]\n",
      "   [ 99. 106.  98.]\n",
      "   [ 95. 102.  94.]\n",
      "   ...\n",
      "   [ 78.  85.  83.]\n",
      "   [ 79.  85.  83.]\n",
      "   [ 80.  86.  84.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 35. 178. 235.]\n",
      "   [ 40. 176. 239.]\n",
      "   [ 42. 176. 241.]\n",
      "   ...\n",
      "   [ 99. 177. 219.]\n",
      "   [ 79. 147. 197.]\n",
      "   [ 89. 148. 189.]]\n",
      "\n",
      "  [[ 57. 182. 234.]\n",
      "   [ 44. 184. 250.]\n",
      "   [ 50. 183. 240.]\n",
      "   ...\n",
      "   [156. 182. 200.]\n",
      "   [141. 177. 206.]\n",
      "   [116. 149. 175.]]\n",
      "\n",
      "  [[ 98. 197. 237.]\n",
      "   [ 64. 189. 252.]\n",
      "   [ 69. 192. 245.]\n",
      "   ...\n",
      "   [188. 195. 206.]\n",
      "   [119. 135. 147.]\n",
      "   [ 61.  79.  90.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73.  79.  77.]\n",
      "   [ 53.  63.  68.]\n",
      "   [ 54.  68.  80.]\n",
      "   ...\n",
      "   [ 17.  40.  64.]\n",
      "   [ 21.  36.  51.]\n",
      "   [ 33.  48.  49.]]\n",
      "\n",
      "  [[ 61.  68.  75.]\n",
      "   [ 55.  70.  86.]\n",
      "   [ 57.  79. 103.]\n",
      "   ...\n",
      "   [ 24.  48.  72.]\n",
      "   [ 17.  35.  53.]\n",
      "   [  7.  23.  32.]]\n",
      "\n",
      "  [[ 44.  56.  73.]\n",
      "   [ 46.  66.  88.]\n",
      "   [ 49.  77. 105.]\n",
      "   ...\n",
      "   [ 27.  52.  77.]\n",
      "   [ 21.  43.  66.]\n",
      "   [ 12.  31.  50.]]]\n",
      "\n",
      "\n",
      " [[[189. 211. 240.]\n",
      "   [186. 208. 236.]\n",
      "   [185. 207. 235.]\n",
      "   ...\n",
      "   [175. 195. 224.]\n",
      "   [172. 194. 222.]\n",
      "   [169. 194. 220.]]\n",
      "\n",
      "  [[194. 210. 239.]\n",
      "   [191. 207. 236.]\n",
      "   [190. 206. 235.]\n",
      "   ...\n",
      "   [173. 192. 220.]\n",
      "   [171. 191. 218.]\n",
      "   [167. 190. 216.]]\n",
      "\n",
      "  [[208. 219. 244.]\n",
      "   [205. 216. 240.]\n",
      "   [204. 215. 239.]\n",
      "   ...\n",
      "   [175. 191. 217.]\n",
      "   [172. 190. 216.]\n",
      "   [169. 191. 215.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[207. 199. 181.]\n",
      "   [203. 195. 175.]\n",
      "   [203. 196. 173.]\n",
      "   ...\n",
      "   [135. 132. 127.]\n",
      "   [162. 158. 150.]\n",
      "   [168. 163. 151.]]\n",
      "\n",
      "  [[198. 190. 170.]\n",
      "   [189. 181. 159.]\n",
      "   [180. 172. 147.]\n",
      "   ...\n",
      "   [178. 171. 160.]\n",
      "   [175. 169. 156.]\n",
      "   [175. 169. 154.]]\n",
      "\n",
      "  [[198. 189. 173.]\n",
      "   [189. 181. 162.]\n",
      "   [178. 170. 149.]\n",
      "   ...\n",
      "   [195. 184. 169.]\n",
      "   [196. 189. 171.]\n",
      "   [195. 190. 171.]]]\n",
      "\n",
      "\n",
      " [[[229. 229. 239.]\n",
      "   [236. 237. 247.]\n",
      "   [234. 236. 247.]\n",
      "   ...\n",
      "   [217. 219. 233.]\n",
      "   [221. 223. 234.]\n",
      "   [222. 223. 233.]]\n",
      "\n",
      "  [[222. 221. 229.]\n",
      "   [239. 239. 249.]\n",
      "   [233. 234. 246.]\n",
      "   ...\n",
      "   [223. 223. 236.]\n",
      "   [227. 228. 238.]\n",
      "   [210. 211. 220.]]\n",
      "\n",
      "  [[213. 206. 211.]\n",
      "   [234. 232. 239.]\n",
      "   [231. 233. 244.]\n",
      "   ...\n",
      "   [220. 220. 232.]\n",
      "   [220. 219. 232.]\n",
      "   [202. 203. 215.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[150. 143. 135.]\n",
      "   [140. 135. 127.]\n",
      "   [132. 127. 120.]\n",
      "   ...\n",
      "   [224. 222. 218.]\n",
      "   [230. 228. 225.]\n",
      "   [241. 241. 238.]]\n",
      "\n",
      "  [[137. 132. 126.]\n",
      "   [130. 127. 120.]\n",
      "   [125. 121. 115.]\n",
      "   ...\n",
      "   [181. 180. 178.]\n",
      "   [202. 201. 198.]\n",
      "   [212. 211. 207.]]\n",
      "\n",
      "  [[122. 119. 114.]\n",
      "   [118. 116. 110.]\n",
      "   [120. 116. 111.]\n",
      "   ...\n",
      "   [179. 177. 173.]\n",
      "   [164. 164. 162.]\n",
      "   [163. 163. 161.]]]]\n",
      "[6. 9. 9. ... 9. 1. 1.]\n",
      "tensor([[[[0.2314, 0.2431, 0.2471],\n",
      "          [0.1686, 0.1804, 0.1765],\n",
      "          [0.1961, 0.1882, 0.1686],\n",
      "          ...,\n",
      "          [0.6196, 0.5176, 0.4235],\n",
      "          [0.5961, 0.4902, 0.4000],\n",
      "          [0.5804, 0.4863, 0.4039]],\n",
      "\n",
      "         [[0.0627, 0.0784, 0.0784],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0706, 0.0314, 0.0000],\n",
      "          ...,\n",
      "          [0.4824, 0.3451, 0.2157],\n",
      "          [0.4667, 0.3255, 0.1961],\n",
      "          [0.4784, 0.3412, 0.2235]],\n",
      "\n",
      "         [[0.0980, 0.0941, 0.0824],\n",
      "          [0.0627, 0.0275, 0.0000],\n",
      "          [0.1922, 0.1059, 0.0314],\n",
      "          ...,\n",
      "          [0.4627, 0.3294, 0.1961],\n",
      "          [0.4706, 0.3294, 0.1961],\n",
      "          [0.4275, 0.2863, 0.1647]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.8157, 0.6667, 0.3765],\n",
      "          [0.7882, 0.6000, 0.1333],\n",
      "          [0.7765, 0.6314, 0.1020],\n",
      "          ...,\n",
      "          [0.6275, 0.5216, 0.2745],\n",
      "          [0.2196, 0.1216, 0.0275],\n",
      "          [0.2078, 0.1333, 0.0784]],\n",
      "\n",
      "         [[0.7059, 0.5451, 0.3765],\n",
      "          [0.6784, 0.4824, 0.1647],\n",
      "          [0.7294, 0.5647, 0.1176],\n",
      "          ...,\n",
      "          [0.7216, 0.5804, 0.3686],\n",
      "          [0.3804, 0.2431, 0.1333],\n",
      "          [0.3255, 0.2078, 0.1333]],\n",
      "\n",
      "         [[0.6941, 0.5647, 0.4549],\n",
      "          [0.6588, 0.5059, 0.3686],\n",
      "          [0.7020, 0.5569, 0.3412],\n",
      "          ...,\n",
      "          [0.8471, 0.7216, 0.5490],\n",
      "          [0.5922, 0.4627, 0.3294],\n",
      "          [0.4824, 0.3608, 0.2824]]],\n",
      "\n",
      "\n",
      "        [[[0.6039, 0.6941, 0.7333],\n",
      "          [0.4941, 0.5373, 0.5333],\n",
      "          [0.4118, 0.4078, 0.3725],\n",
      "          ...,\n",
      "          [0.3569, 0.3725, 0.2784],\n",
      "          [0.3412, 0.3529, 0.2784],\n",
      "          [0.3098, 0.3176, 0.2745]],\n",
      "\n",
      "         [[0.5490, 0.6275, 0.6627],\n",
      "          [0.5686, 0.6000, 0.6039],\n",
      "          [0.4902, 0.4902, 0.4627],\n",
      "          ...,\n",
      "          [0.3765, 0.3882, 0.3059],\n",
      "          [0.3020, 0.3137, 0.2431],\n",
      "          [0.2784, 0.2863, 0.2392]],\n",
      "\n",
      "         [[0.5490, 0.6078, 0.6431],\n",
      "          [0.5451, 0.5725, 0.5843],\n",
      "          [0.4510, 0.4510, 0.4392],\n",
      "          ...,\n",
      "          [0.3098, 0.3216, 0.2510],\n",
      "          [0.2667, 0.2745, 0.2157],\n",
      "          [0.2627, 0.2706, 0.2157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.6863, 0.6549, 0.6510],\n",
      "          [0.6118, 0.6039, 0.6275],\n",
      "          [0.6039, 0.6275, 0.6667],\n",
      "          ...,\n",
      "          [0.1647, 0.1333, 0.1412],\n",
      "          [0.2392, 0.2078, 0.2235],\n",
      "          [0.3647, 0.3255, 0.3569]],\n",
      "\n",
      "         [[0.6471, 0.6039, 0.5020],\n",
      "          [0.6118, 0.5961, 0.5098],\n",
      "          [0.6235, 0.6314, 0.5569],\n",
      "          ...,\n",
      "          [0.4039, 0.3647, 0.3765],\n",
      "          [0.4824, 0.4471, 0.4706],\n",
      "          [0.5137, 0.4745, 0.5137]],\n",
      "\n",
      "         [[0.6392, 0.5804, 0.4706],\n",
      "          [0.6196, 0.5804, 0.4784],\n",
      "          [0.6392, 0.6118, 0.5216],\n",
      "          ...,\n",
      "          [0.5608, 0.5216, 0.5451],\n",
      "          [0.5608, 0.5255, 0.5569],\n",
      "          [0.5608, 0.5216, 0.5647]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000],\n",
      "          [0.9922, 0.9922, 0.9922],\n",
      "          [0.9922, 0.9922, 0.9922],\n",
      "          ...,\n",
      "          [0.9922, 0.9922, 0.9922],\n",
      "          [0.9922, 0.9922, 0.9922],\n",
      "          [0.9922, 0.9922, 0.9922]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          ...,\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.4431, 0.4706, 0.4392],\n",
      "          [0.4353, 0.4627, 0.4353],\n",
      "          [0.4118, 0.4392, 0.4157],\n",
      "          ...,\n",
      "          [0.2824, 0.3176, 0.3137],\n",
      "          [0.2824, 0.3137, 0.3098],\n",
      "          [0.2824, 0.3137, 0.3098]],\n",
      "\n",
      "         [[0.4353, 0.4627, 0.4314],\n",
      "          [0.4078, 0.4353, 0.4078],\n",
      "          [0.3882, 0.4157, 0.3843],\n",
      "          ...,\n",
      "          [0.2667, 0.2941, 0.2863],\n",
      "          [0.2745, 0.2980, 0.2941],\n",
      "          [0.3059, 0.3294, 0.3216]],\n",
      "\n",
      "         [[0.4157, 0.4431, 0.4118],\n",
      "          [0.3882, 0.4157, 0.3843],\n",
      "          [0.3725, 0.4000, 0.3686],\n",
      "          ...,\n",
      "          [0.3059, 0.3333, 0.3255],\n",
      "          [0.3098, 0.3333, 0.3255],\n",
      "          [0.3137, 0.3373, 0.3294]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.5686, 0.5804, 0.6157],\n",
      "          [0.5137, 0.5255, 0.5686],\n",
      "          [0.4510, 0.4667, 0.4863],\n",
      "          ...,\n",
      "          [0.4941, 0.4118, 0.4078],\n",
      "          [0.4941, 0.4118, 0.4078],\n",
      "          [0.4902, 0.4078, 0.4039]],\n",
      "\n",
      "         [[0.5059, 0.5176, 0.5529],\n",
      "          [0.4863, 0.4980, 0.5412],\n",
      "          [0.4039, 0.4196, 0.4392],\n",
      "          ...,\n",
      "          [0.4941, 0.4118, 0.4078],\n",
      "          [0.4941, 0.4118, 0.4078],\n",
      "          [0.4902, 0.4078, 0.4039]],\n",
      "\n",
      "         [[0.4549, 0.4667, 0.5020],\n",
      "          [0.4588, 0.4667, 0.5098],\n",
      "          [0.3961, 0.4118, 0.4314],\n",
      "          ...,\n",
      "          [0.4941, 0.4118, 0.4078],\n",
      "          [0.4902, 0.4078, 0.4039],\n",
      "          [0.4863, 0.4039, 0.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.4902, 0.6431, 0.2980],\n",
      "          [0.3569, 0.4902, 0.2392],\n",
      "          [0.1804, 0.3020, 0.1216],\n",
      "          ...,\n",
      "          [0.4824, 0.6314, 0.4078],\n",
      "          [0.4510, 0.6000, 0.3412],\n",
      "          [0.4784, 0.6235, 0.3412]],\n",
      "\n",
      "         [[0.4902, 0.6471, 0.2627],\n",
      "          [0.4941, 0.6431, 0.3176],\n",
      "          [0.4078, 0.5451, 0.2980],\n",
      "          ...,\n",
      "          [0.5059, 0.6549, 0.4157],\n",
      "          [0.4627, 0.6118, 0.3569],\n",
      "          [0.4980, 0.6314, 0.3647]],\n",
      "\n",
      "         [[0.4980, 0.6510, 0.2980],\n",
      "          [0.4980, 0.6471, 0.3137],\n",
      "          [0.5059, 0.6510, 0.3569],\n",
      "          ...,\n",
      "          [0.5020, 0.6627, 0.3490],\n",
      "          [0.4863, 0.6431, 0.3451],\n",
      "          [0.4941, 0.6275, 0.3569]]],\n",
      "\n",
      "\n",
      "        [[[0.5725, 0.5725, 0.5725],\n",
      "          [0.7255, 0.7255, 0.7255],\n",
      "          [0.9725, 0.9725, 0.9725],\n",
      "          ...,\n",
      "          [0.9922, 0.9922, 0.9922],\n",
      "          [0.9922, 0.9922, 0.9922],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.5608, 0.5608, 0.5608],\n",
      "          [0.3412, 0.3373, 0.3373],\n",
      "          [0.6902, 0.6863, 0.6863],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.7608, 0.7490, 0.7529],\n",
      "          [0.3294, 0.3137, 0.3176],\n",
      "          [0.2627, 0.2471, 0.2510],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9804, 0.9804, 0.9765],\n",
      "          [0.5255, 0.5176, 0.4980],\n",
      "          [0.2824, 0.2667, 0.2275],\n",
      "          ...,\n",
      "          [0.2157, 0.2157, 0.2157],\n",
      "          [0.7569, 0.7569, 0.7569],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.7804, 0.7765, 0.7608],\n",
      "          [0.6000, 0.5922, 0.5647],\n",
      "          ...,\n",
      "          [0.1451, 0.1451, 0.1451],\n",
      "          [0.4863, 0.4863, 0.4863],\n",
      "          [0.9686, 0.9686, 0.9686]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.9765, 0.9765, 0.9725],\n",
      "          [0.9529, 0.9529, 0.9490],\n",
      "          ...,\n",
      "          [0.5725, 0.5725, 0.5725],\n",
      "          [0.6510, 0.6510, 0.6510],\n",
      "          [0.9333, 0.9333, 0.9333]]],\n",
      "\n",
      "\n",
      "        [[[0.7961, 0.8078, 0.8157],\n",
      "          [0.7882, 0.7922, 0.7922],\n",
      "          [0.8157, 0.8196, 0.8196],\n",
      "          ...,\n",
      "          [0.7333, 0.7608, 0.7608],\n",
      "          [0.7412, 0.7569, 0.7569],\n",
      "          [0.7412, 0.7569, 0.7608]],\n",
      "\n",
      "         [[0.7529, 0.7569, 0.7608],\n",
      "          [0.7451, 0.7490, 0.7569],\n",
      "          [0.7882, 0.7961, 0.8000],\n",
      "          ...,\n",
      "          [0.7098, 0.7412, 0.7412],\n",
      "          [0.7137, 0.7412, 0.7490],\n",
      "          [0.7333, 0.7529, 0.7529]],\n",
      "\n",
      "         [[0.7412, 0.7569, 0.7725],\n",
      "          [0.7569, 0.7725, 0.7882],\n",
      "          [0.7882, 0.8039, 0.8157],\n",
      "          ...,\n",
      "          [0.7098, 0.7373, 0.7451],\n",
      "          [0.7333, 0.7529, 0.7529],\n",
      "          [0.7451, 0.7569, 0.7569]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.6549, 0.6627, 0.6706],\n",
      "          [0.6471, 0.6627, 0.6667],\n",
      "          [0.6549, 0.6706, 0.6745],\n",
      "          ...,\n",
      "          [0.3961, 0.4314, 0.4275],\n",
      "          [0.4706, 0.4824, 0.4667],\n",
      "          [0.4824, 0.4941, 0.4784]],\n",
      "\n",
      "         [[0.5961, 0.6314, 0.6431],\n",
      "          [0.6824, 0.6824, 0.6784],\n",
      "          [0.6627, 0.6667, 0.6706],\n",
      "          ...,\n",
      "          [0.4235, 0.4549, 0.4510],\n",
      "          [0.4471, 0.4706, 0.4588],\n",
      "          [0.4784, 0.4902, 0.4745]],\n",
      "\n",
      "         [[0.6627, 0.6667, 0.6588],\n",
      "          [0.6824, 0.6784, 0.6667],\n",
      "          [0.6471, 0.6588, 0.6588],\n",
      "          ...,\n",
      "          [0.4039, 0.4431, 0.4471],\n",
      "          [0.4667, 0.4784, 0.4706],\n",
      "          [0.5176, 0.5137, 0.4941]]]])\n",
      "tensor([6., 9., 9., 4., 1., 1., 2., 7., 8., 3., 4., 7., 7., 2., 9., 9., 9., 3.,\n",
      "        2., 6., 4., 3., 6., 6., 2., 6., 3., 5., 4., 0., 0., 9., 1., 3., 4., 0.,\n",
      "        3., 7., 3., 3., 5., 2., 2., 7., 1., 1., 1., 2., 2., 0., 9., 5., 7., 9.,\n",
      "        2., 2., 5., 2., 4., 3., 1., 1., 8., 2., 1., 1., 4., 9., 7., 8., 5., 9.,\n",
      "        6., 7., 3., 1., 9., 0., 3., 1., 3., 5., 4., 5., 7., 7., 4., 7., 9., 4.,\n",
      "        2., 3., 8., 0., 1., 6., 1., 1., 4., 1., 8., 3., 9., 6., 6., 1., 8., 5.,\n",
      "        2., 9., 9., 8., 1., 7., 7., 0., 0., 6., 9., 1., 2., 2., 9., 2., 6., 6.,\n",
      "        1., 9., 5., 0., 4., 7., 6., 7., 1., 8., 1., 1., 2., 8., 1., 3., 3., 6.,\n",
      "        2., 4., 9., 9., 5., 4., 3., 6., 7., 4., 6., 8., 5., 5., 4., 3., 1., 8.,\n",
      "        4., 7., 6., 0., 9., 5., 1., 3., 8., 2., 7., 5., 3., 4., 1., 5., 7., 0.,\n",
      "        4., 7., 5., 5., 1., 0., 9., 6., 9., 0., 8., 7., 8., 8., 2., 5., 2., 3.,\n",
      "        5., 0., 6., 1., 9., 3., 6., 9., 1., 3., 9., 6., 6., 7., 1., 0., 9., 5.,\n",
      "        8., 5., 2., 9., 0., 8., 8., 0., 6., 9., 1., 1., 6., 3., 7., 6., 6., 0.,\n",
      "        6., 6., 1., 7., 1., 5., 8., 3., 6., 6., 8., 6., 8., 4., 6., 6., 1., 3.,\n",
      "        8., 3., 4., 1., 7., 1., 3., 8., 5., 1., 1., 4., 0., 9., 3., 7., 4., 9.,\n",
      "        9., 2., 4., 9., 9., 1., 0., 5., 9., 0., 8., 2., 1., 2., 0., 5., 6., 3.,\n",
      "        2., 7., 8., 8., 6., 0., 7., 9., 4., 5., 6., 4., 2., 1., 1., 2., 1., 5.,\n",
      "        9., 9., 0., 8., 4., 1., 1., 6., 3., 3., 9., 0., 7., 9., 7., 7., 9., 1.,\n",
      "        5., 1., 6., 6., 8., 7., 1., 3., 0., 3., 3., 2., 4., 5., 7., 5., 9., 0.,\n",
      "        3., 4., 0., 4., 4., 6., 0., 0., 6., 6., 0., 8., 1., 6., 2., 9., 2., 5.,\n",
      "        9., 6., 7., 4., 1., 8., 7., 3., 6., 9., 3., 0., 4., 0., 5., 1., 0., 3.,\n",
      "        4., 8., 5., 4., 7., 2., 3., 9., 7., 6., 7., 1., 4., 7., 0., 1., 7., 3.,\n",
      "        1., 8., 4., 4., 2., 0., 2., 2., 0., 0., 9., 0., 9., 6., 8., 2., 7., 7.,\n",
      "        4., 0., 3., 0., 8., 9., 4., 2., 7., 2., 5., 2., 5., 1., 9., 4., 8., 5.,\n",
      "        1., 7., 4., 4., 0., 6., 9., 0., 7., 8., 8., 9., 9., 3., 3., 4., 0., 4.,\n",
      "        5., 6., 6., 0., 1., 0., 8., 0., 4., 8., 8., 1., 5., 2., 6., 8., 1., 0.,\n",
      "        0., 7., 7., 5., 9., 6., 2., 8., 3., 4., 7., 3., 9., 0., 1., 2., 4., 8.,\n",
      "        1., 8., 6., 4., 4., 5., 7., 1., 3., 9., 8., 0., 1., 7., 5., 8., 2., 8.,\n",
      "        0., 4., 1., 8., 9., 8., 2., 9., 9., 2., 7., 5., 7., 3., 8., 8., 4., 4.,\n",
      "        2., 7., 1., 6., 4., 0., 4., 6., 9., 7., 6., 2., 5., 5., 1., 7., 2., 2.,\n",
      "        2., 9., 5., 4., 2., 7., 8., 1., 3., 4., 3., 7., 6., 9., 8., 0., 6., 0.,\n",
      "        2., 2., 2., 1., 8., 4., 0., 1., 8., 8., 1., 5., 7., 6., 4., 5., 8., 7.,\n",
      "        1., 9., 1., 9., 8., 4., 7., 3., 8., 8., 2., 6., 6., 7., 1., 6., 8., 1.,\n",
      "        9., 7., 8., 3., 0., 1., 0., 8., 8., 3., 0., 0., 1., 5., 0., 8., 8., 7.,\n",
      "        9., 9., 0., 9., 4., 1., 3., 6., 6., 4., 4., 7., 5., 6., 0., 8., 0., 3.,\n",
      "        2., 8., 4., 6., 9., 9., 7., 0., 3., 3., 6., 7., 4., 9., 1., 6., 2., 7.,\n",
      "        2., 2., 0., 6., 7., 5., 7., 6., 8., 9., 0., 9., 4., 4., 7., 0., 9., 4.,\n",
      "        9., 6., 9., 4., 5., 7., 9., 2., 4., 5., 1., 4., 3., 9., 6., 5., 6., 9.,\n",
      "        3., 3., 5., 0., 7., 2., 1., 3., 6., 4., 0., 0., 2., 5., 0., 1., 0., 2.,\n",
      "        3., 9., 8., 4., 9., 8., 0., 2., 6., 4., 4., 0., 1., 8., 8., 3., 6., 9.,\n",
      "        6., 6., 7., 8., 2., 4., 5., 7., 6., 5., 3., 0., 5., 0., 5., 0., 8., 2.,\n",
      "        6., 7., 3., 8., 2., 1., 7., 6., 7., 1., 0., 9., 5., 5., 0., 1., 7., 6.,\n",
      "        9., 0., 4., 7., 7., 1., 5., 9., 4., 0., 8., 5., 9., 9., 6., 7., 1., 8.,\n",
      "        3., 2., 3., 8., 2., 2., 4., 6., 0., 0., 5., 3., 8., 2., 3., 7., 2., 9.,\n",
      "        3., 8., 7., 8., 2., 7., 9., 0., 2., 3., 2., 2., 2., 3., 3., 6., 2., 3.,\n",
      "        2., 8., 0., 5., 5., 1., 4., 5., 6., 6., 2., 7., 0., 1., 7., 7., 8., 2.,\n",
      "        9., 2., 2., 4., 2., 1., 1., 1., 6., 6., 6., 5., 1., 1., 7., 0., 4., 3.,\n",
      "        3., 7., 1., 2., 3., 5., 5., 5., 6., 1., 4., 3., 7., 8., 8., 3., 6., 6.,\n",
      "        2., 3., 0., 9., 4., 3., 8., 0., 0., 1., 1., 5., 4., 9., 3., 1., 8., 9.,\n",
      "        3., 9., 9., 2., 9., 4., 8., 2., 9., 8., 8., 1., 5., 3., 6., 8., 7., 6.,\n",
      "        9., 8., 0., 6., 4., 0., 0., 2., 5., 8., 2., 0., 2., 7., 6., 9., 7., 1.,\n",
      "        5., 5., 6., 6., 3., 6., 2., 4., 7., 0., 5., 6., 4., 6., 5., 2., 4., 6.,\n",
      "        1., 6., 0., 4., 0., 3., 1., 8., 5., 4., 4., 1., 7., 3., 9., 4., 7., 9.,\n",
      "        7., 3., 7., 2., 8., 4., 6., 6., 1., 2., 9., 0., 4., 8., 7., 3., 9., 8.,\n",
      "        7., 7., 0., 2., 4., 1., 1., 4., 1., 5., 4., 0., 5., 6., 2., 8., 5., 0.,\n",
      "        2., 1., 3., 5., 7., 3., 5., 1., 3., 5.])\n",
      "tensor([[[[0.6196, 0.4392, 0.1922],\n",
      "          [0.6235, 0.4353, 0.1843],\n",
      "          [0.6471, 0.4549, 0.2000],\n",
      "          ...,\n",
      "          [0.5373, 0.3725, 0.1412],\n",
      "          [0.4941, 0.3569, 0.1412],\n",
      "          [0.4549, 0.3333, 0.1294]],\n",
      "\n",
      "         [[0.5961, 0.4392, 0.2000],\n",
      "          [0.5922, 0.4314, 0.1569],\n",
      "          [0.6235, 0.4471, 0.1765],\n",
      "          ...,\n",
      "          [0.5333, 0.3725, 0.1216],\n",
      "          [0.4902, 0.3569, 0.1255],\n",
      "          [0.4667, 0.3451, 0.1333]],\n",
      "\n",
      "         [[0.5922, 0.4314, 0.1843],\n",
      "          [0.5922, 0.4275, 0.1294],\n",
      "          [0.6196, 0.4353, 0.1412],\n",
      "          ...,\n",
      "          [0.5451, 0.3843, 0.1333],\n",
      "          [0.5098, 0.3725, 0.1333],\n",
      "          [0.4706, 0.3490, 0.1294]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2667, 0.4863, 0.6941],\n",
      "          [0.1647, 0.3922, 0.5804],\n",
      "          [0.1216, 0.3451, 0.5373],\n",
      "          ...,\n",
      "          [0.1490, 0.3804, 0.5725],\n",
      "          [0.0510, 0.2510, 0.4235],\n",
      "          [0.1569, 0.3333, 0.4980]],\n",
      "\n",
      "         [[0.2392, 0.4549, 0.6588],\n",
      "          [0.1922, 0.4000, 0.5804],\n",
      "          [0.1373, 0.3333, 0.5176],\n",
      "          ...,\n",
      "          [0.1020, 0.3216, 0.5098],\n",
      "          [0.1137, 0.3216, 0.4941],\n",
      "          [0.0784, 0.2510, 0.4196]],\n",
      "\n",
      "         [[0.2118, 0.4196, 0.6275],\n",
      "          [0.2196, 0.4118, 0.5843],\n",
      "          [0.1765, 0.3490, 0.5176],\n",
      "          ...,\n",
      "          [0.0941, 0.3020, 0.4863],\n",
      "          [0.1333, 0.3294, 0.5059],\n",
      "          [0.0824, 0.2627, 0.4314]]],\n",
      "\n",
      "\n",
      "        [[[0.9216, 0.9216, 0.9216],\n",
      "          [0.9059, 0.9059, 0.9059],\n",
      "          [0.9098, 0.9098, 0.9098],\n",
      "          ...,\n",
      "          [0.9137, 0.9137, 0.9137],\n",
      "          [0.9137, 0.9137, 0.9137],\n",
      "          [0.9098, 0.9098, 0.9098]],\n",
      "\n",
      "         [[0.9333, 0.9333, 0.9333],\n",
      "          [0.9216, 0.9216, 0.9216],\n",
      "          [0.9216, 0.9216, 0.9216],\n",
      "          ...,\n",
      "          [0.9255, 0.9255, 0.9255],\n",
      "          [0.9255, 0.9255, 0.9255],\n",
      "          [0.9216, 0.9216, 0.9216]],\n",
      "\n",
      "         [[0.9294, 0.9294, 0.9294],\n",
      "          [0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176],\n",
      "          ...,\n",
      "          [0.9216, 0.9216, 0.9216],\n",
      "          [0.9216, 0.9216, 0.9216],\n",
      "          [0.9176, 0.9176, 0.9176]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.3412, 0.3882, 0.3490],\n",
      "          [0.1686, 0.2000, 0.1451],\n",
      "          [0.0745, 0.0902, 0.0431],\n",
      "          ...,\n",
      "          [0.6627, 0.7216, 0.7020],\n",
      "          [0.7137, 0.7725, 0.7569],\n",
      "          [0.7373, 0.7922, 0.7882]],\n",
      "\n",
      "         [[0.3216, 0.3765, 0.3216],\n",
      "          [0.1804, 0.2235, 0.1412],\n",
      "          [0.1412, 0.1725, 0.0863],\n",
      "          ...,\n",
      "          [0.6824, 0.7412, 0.7176],\n",
      "          [0.7255, 0.7843, 0.7686],\n",
      "          [0.7333, 0.7922, 0.7843]],\n",
      "\n",
      "         [[0.3333, 0.3961, 0.3255],\n",
      "          [0.2431, 0.2941, 0.1882],\n",
      "          [0.2275, 0.2627, 0.1490],\n",
      "          ...,\n",
      "          [0.6588, 0.7176, 0.6980],\n",
      "          [0.7059, 0.7647, 0.7490],\n",
      "          [0.7294, 0.7843, 0.7804]]],\n",
      "\n",
      "\n",
      "        [[[0.6196, 0.7451, 0.8706],\n",
      "          [0.6196, 0.7333, 0.8549],\n",
      "          [0.5451, 0.6510, 0.7608],\n",
      "          ...,\n",
      "          [0.8941, 0.9059, 0.9176],\n",
      "          [0.9294, 0.9373, 0.9529],\n",
      "          [0.9333, 0.9451, 0.9647]],\n",
      "\n",
      "         [[0.6667, 0.7843, 0.8980],\n",
      "          [0.6745, 0.7804, 0.8863],\n",
      "          [0.5922, 0.6902, 0.7882],\n",
      "          ...,\n",
      "          [0.9098, 0.9098, 0.9255],\n",
      "          [0.9647, 0.9647, 0.9804],\n",
      "          [0.9647, 0.9686, 0.9843]],\n",
      "\n",
      "         [[0.6824, 0.7882, 0.8824],\n",
      "          [0.6902, 0.7843, 0.8706],\n",
      "          [0.6157, 0.7020, 0.7804],\n",
      "          ...,\n",
      "          [0.9020, 0.8980, 0.9098],\n",
      "          [0.9804, 0.9765, 0.9843],\n",
      "          [0.9608, 0.9569, 0.9686]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1216, 0.1569, 0.1765],\n",
      "          [0.1176, 0.1529, 0.1725],\n",
      "          [0.1020, 0.1373, 0.1569],\n",
      "          ...,\n",
      "          [0.1451, 0.1569, 0.1804],\n",
      "          [0.0353, 0.0510, 0.0549],\n",
      "          [0.0157, 0.0275, 0.0196]],\n",
      "\n",
      "         [[0.0902, 0.1333, 0.1529],\n",
      "          [0.1059, 0.1490, 0.1686],\n",
      "          [0.0980, 0.1412, 0.1608],\n",
      "          ...,\n",
      "          [0.0745, 0.0784, 0.0941],\n",
      "          [0.0157, 0.0235, 0.0118],\n",
      "          [0.0196, 0.0275, 0.0118]],\n",
      "\n",
      "         [[0.1098, 0.1608, 0.1843],\n",
      "          [0.1176, 0.1686, 0.1961],\n",
      "          [0.1255, 0.1765, 0.2039],\n",
      "          ...,\n",
      "          [0.0196, 0.0235, 0.0314],\n",
      "          [0.0157, 0.0196, 0.0118],\n",
      "          [0.0275, 0.0314, 0.0275]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.5176, 0.5294, 0.5843],\n",
      "          [0.5216, 0.5373, 0.5882],\n",
      "          [0.5294, 0.5451, 0.5922],\n",
      "          ...,\n",
      "          [0.5098, 0.5412, 0.5922],\n",
      "          [0.5098, 0.5373, 0.5961],\n",
      "          [0.5098, 0.5373, 0.5961]],\n",
      "\n",
      "         [[0.5412, 0.5490, 0.5961],\n",
      "          [0.5451, 0.5529, 0.6000],\n",
      "          [0.5451, 0.5529, 0.6000],\n",
      "          ...,\n",
      "          [0.5216, 0.5490, 0.6000],\n",
      "          [0.5176, 0.5451, 0.6000],\n",
      "          [0.5137, 0.5412, 0.6000]],\n",
      "\n",
      "         [[0.5451, 0.5490, 0.5922],\n",
      "          [0.5451, 0.5490, 0.5922],\n",
      "          [0.5529, 0.5529, 0.6000],\n",
      "          ...,\n",
      "          [0.5176, 0.5451, 0.5922],\n",
      "          [0.5137, 0.5412, 0.5922],\n",
      "          [0.5137, 0.5373, 0.5922]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0902, 0.1490, 0.0667],\n",
      "          [0.0745, 0.1294, 0.0392],\n",
      "          [0.0980, 0.1490, 0.0706],\n",
      "          ...,\n",
      "          [0.5294, 0.5373, 0.5686],\n",
      "          [0.5294, 0.5412, 0.5686],\n",
      "          [0.5294, 0.5373, 0.5686]],\n",
      "\n",
      "         [[0.0667, 0.1176, 0.0510],\n",
      "          [0.0549, 0.1020, 0.0431],\n",
      "          [0.0667, 0.1176, 0.0471],\n",
      "          ...,\n",
      "          [0.5373, 0.5412, 0.5725],\n",
      "          [0.5373, 0.5412, 0.5725],\n",
      "          [0.5373, 0.5412, 0.5725]],\n",
      "\n",
      "         [[0.0510, 0.0941, 0.0314],\n",
      "          [0.0510, 0.0941, 0.0392],\n",
      "          [0.0549, 0.0980, 0.0392],\n",
      "          ...,\n",
      "          [0.5255, 0.5333, 0.5647],\n",
      "          [0.5255, 0.5333, 0.5608],\n",
      "          [0.5255, 0.5333, 0.5608]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          ...,\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000],\n",
      "          [0.9961, 0.9961, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.9176, 0.9137, 0.9333],\n",
      "          [0.9333, 0.9294, 0.9451],\n",
      "          [0.9373, 0.9333, 0.9490],\n",
      "          ...,\n",
      "          [0.9647, 0.9569, 0.9686],\n",
      "          [0.9725, 0.9647, 0.9765],\n",
      "          [0.9765, 0.9725, 0.9843]],\n",
      "\n",
      "         [[0.8980, 0.8941, 0.9137],\n",
      "          [0.9098, 0.9059, 0.9255],\n",
      "          [0.9137, 0.9098, 0.9294],\n",
      "          ...,\n",
      "          [0.9569, 0.9490, 0.9608],\n",
      "          [0.9647, 0.9569, 0.9686],\n",
      "          [0.9725, 0.9647, 0.9725]],\n",
      "\n",
      "         [[0.9059, 0.9020, 0.9255],\n",
      "          [0.9137, 0.9098, 0.9333],\n",
      "          [0.9137, 0.9098, 0.9333],\n",
      "          ...,\n",
      "          [0.9804, 0.9725, 0.9804],\n",
      "          [0.9843, 0.9765, 0.9843],\n",
      "          [0.9882, 0.9843, 0.9882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.4510, 0.2941, 0.2157],\n",
      "          [0.4196, 0.2824, 0.2157],\n",
      "          [0.4157, 0.2784, 0.2196],\n",
      "          ...,\n",
      "          [0.8863, 0.7765, 0.5922],\n",
      "          [0.8314, 0.6902, 0.5020],\n",
      "          [0.8510, 0.7098, 0.5137]],\n",
      "\n",
      "         [[0.4431, 0.2902, 0.2157],\n",
      "          [0.4039, 0.2745, 0.2157],\n",
      "          [0.3882, 0.2706, 0.2157],\n",
      "          ...,\n",
      "          [0.8431, 0.7490, 0.5412],\n",
      "          [0.8078, 0.7137, 0.5020],\n",
      "          [0.8118, 0.6941, 0.5059]],\n",
      "\n",
      "         [[0.4157, 0.2784, 0.2118],\n",
      "          [0.4118, 0.2824, 0.2235],\n",
      "          [0.4039, 0.2824, 0.2196],\n",
      "          ...,\n",
      "          [0.7961, 0.6980, 0.4902],\n",
      "          [0.8353, 0.7569, 0.5373],\n",
      "          [0.7804, 0.6980, 0.4980]]]])\n",
      "tensor([3., 8., 8., 0., 6., 6., 1., 6., 3., 1., 0., 9., 5., 7., 9., 8., 5., 7.,\n",
      "        8., 6., 7., 0., 4., 9., 5., 2., 4., 0., 9., 6., 6., 5., 4., 5., 9., 2.,\n",
      "        4., 1., 9., 5., 4., 6., 5., 6., 0., 9., 3., 9., 7., 6., 9., 8., 0., 3.,\n",
      "        8., 8., 7., 7., 4., 6., 7., 3., 6., 3., 6., 2., 1., 2., 3., 7., 2., 6.,\n",
      "        8., 8., 0., 2., 9., 3., 3., 8., 8., 1., 1., 7., 2., 5., 2., 7., 8., 9.,\n",
      "        0., 3., 8., 6., 4., 6., 6., 0., 0., 7.])\n",
      "torch.Size([1000, 32, 32, 3])\n",
      "torch.Size([1000])\n",
      "torch.Size([100, 32, 32, 3])\n",
      "torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_cifar10_data(directory):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    \n",
    "    # Load data batches\n",
    "    for i in range(1, 6):\n",
    "        train_batch_file = os.path.join(directory, 'data_batch_{}'.format(i))\n",
    "        train_data_dict = unpickle(train_batch_file)\n",
    "        train_batch_images = train_data_dict[b'data']\n",
    "        train_batch_labels = train_data_dict[b'labels']\n",
    "        \n",
    "        # Reshape the image data\n",
    "        train_batch_images = train_batch_images.reshape((-1, 3, 32, 32)).transpose((0, 2, 3, 1))\n",
    "        \n",
    "        train_images.append(train_batch_images)\n",
    "        train_labels.extend(train_batch_labels)\n",
    "    \n",
    "    # Load test batch\n",
    "    test_batch_file = os.path.join(directory, 'test_batch')\n",
    "    test_data_dict = unpickle(test_batch_file)\n",
    "    test_batch_images = test_data_dict[b'data']\n",
    "    test_batch_labels = test_data_dict[b'labels']\n",
    "    \n",
    "    # Reshape the test image data\n",
    "    test_batch_images = test_batch_images.reshape((-1, 3, 32, 32)).transpose((0, 2, 3, 1))\n",
    "\n",
    "    test_images.append(test_batch_images)\n",
    "    test_labels.extend(test_batch_labels)\n",
    "    \n",
    "    train_images = np.concatenate(train_images, axis=0)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.concatenate(test_images, axis=0)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Specify the path to the 'cifar-10-batches-py' directory\n",
    "data_directory = 'cifar-10-batches-py'\n",
    "\n",
    "# Load CIFAR-10 data\n",
    "train_images, train_labels, test_images, test_labels = load_cifar10_data(data_directory)\n",
    "\n",
    "# Input to X and y\n",
    "X_train = train_images.astype(np.int32)\n",
    "y_train = train_labels.astype(np.int32)\n",
    "X_test = test_images.astype(np.int32)\n",
    "y_test = test_labels.astype(np.int32)\n",
    "\n",
    "# Translation of data\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32') \n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "# Normalize data set\n",
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0\n",
    "\n",
    "# Turn data to tensor\n",
    "X_train_tensor = torch.from_numpy(X_train_normalized[:1000])\n",
    "y_train_tensor = torch.from_numpy(y_train[:1000])\n",
    "X_test_tensor = torch.from_numpy(X_test_normalized[:100])\n",
    "y_test_tensor = torch.from_numpy(y_test[:100])\n",
    "print(X_train_tensor)\n",
    "print(y_train_tensor)\n",
    "print(X_test_tensor)\n",
    "print(y_test_tensor)\n",
    "print(X_train_tensor.size())\n",
    "print(y_train_tensor.size())\n",
    "print(X_test_tensor.size())\n",
    "print(y_test_tensor.size())\n",
    "\n",
    "# Learning Rate and Batch size\n",
    "dataset_name = \"CIFAR-10 Datset\"\n",
    "learning_rate_preset = 0.01\n",
    "batch_size_preset = 100\n",
    "CNN_input_shape_preset = (-1, 3, 32, 32)\n",
    "\n",
    "# Number of samples, features, and classes\n",
    "num_samples_preset  = X_train_tensor.size()[0]\n",
    "num_features_preset = X_train_tensor.size()[1]\n",
    "num_classes_preset = len(torch.unique(y_train_tensor))\n",
    "\n",
    "# Translate the tensor to dataset\n",
    "CIFAR_10_train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "CIFAR_10_test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Translate to DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(CIFAR_10_train_dataset, batch_size = batch_size_preset, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(CIFAR_10_test_dataset, batch_size = batch_size_preset, shuffle = True)\n",
    "\n",
    "# Visualize the first 10 images\n",
    "for i in range(10):\n",
    "    plt.imshow(X_train_tensor[i])\n",
    "    plt.show()\n",
    "    print(y_train_tensor[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1 Non-Linear Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network (CNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "class ConvolutionalNeuralNetwork_CIFAR10(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.activation_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation_stack(x)\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Client Device for CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom class for each client so they can update separately\n",
    "class ClientDevice:\n",
    "    def __init__(self, model, optimizer, criterion, train_dataloader, test_dataloader=None):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "\n",
    "    def load_global_weights(self, global_weights):\n",
    "        self.model.load_state_dict(global_weights)\n",
    "\n",
    "    def get_local_weights(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def update_weights(self, num_epochs, iterate_func):\n",
    "        self.model.train()\n",
    "        loss_history, error_history = iterate_func(self.model, self.train_dataloader, num_epochs, self.optimizer, self.criterion, show_history=False, training=True)\n",
    "        return self.model.state_dict(), loss_history, error_history\n",
    "\n",
    "# Establish client devices\n",
    "def establish_client_devices(num_clients, train_dataloader_list, test_dataloader_list, model_list, optimizer_list, criterion_list):\n",
    "    # Establish client devices\n",
    "    client_device = [None] * num_clients\n",
    "    client_model = [None] * num_clients\n",
    "    client_optimizer = [None] * num_clients\n",
    "    client_criterion = [None] * num_clients\n",
    "    client_weights = [None] * num_clients\n",
    "    for client in range(num_clients):\n",
    "        client_model[client] = model_list[client]\n",
    "        client_optimizer[client] = optimizer_list[client]\n",
    "        client_criterion[client] = criterion_list[client]\n",
    "        client_weights[client] = client_model[client].state_dict()\n",
    "        client_device[client] = ClientDevice(client_model[client], client_optimizer[client], client_criterion[client], train_dataloader_list[client], test_dataloader_list[client])\n",
    "    return client_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Training and Testing Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_CNN_model(model, dataset_loader, num_epochs, optimizer, criterion, show_history=True, training=True):\n",
    "    loss_history = []\n",
    "    error_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        single_iteration_count = 0.00\n",
    "        batch_iteration_count = 0.00\n",
    "        loss_count = 0.00\n",
    "        error_count = 0.00\n",
    "        for i, (images, labels) in enumerate(dataset_loader):\n",
    "            # Define variables\n",
    "            X_batch = Variable(images.view(CNN_input_shape))\n",
    "            y_batch = Variable(labels)\n",
    "\n",
    "            # Forward propagation to obtain the predicted output\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, y_batch.long())\n",
    "            \n",
    "            # Backward propagation and optimization\n",
    "            if training is True:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Record the iteration used\n",
    "            single_iteration_count += 1\n",
    "            batch_iteration_count += len(y_batch)\n",
    "\n",
    "            # Record the loss\n",
    "            loss_count += loss.data.detach().numpy()\n",
    "\n",
    "            # Record the error rate\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            error_count += (predicted != y_batch).float().sum()\n",
    "        \n",
    "        # Summarize the loss rate\n",
    "        loss_rate = loss_count / float(single_iteration_count)\n",
    "        loss_history.append(loss_rate)\n",
    "\n",
    "        # Summarize the error rate\n",
    "        train_error_rate = error_count / float(batch_iteration_count)\n",
    "        error_history.append(train_error_rate)\n",
    "\n",
    "        # Print the summarized loss and error every specific epochs\n",
    "        if show_history is True and ((epoch + 1) % 10 == 0 or epoch == 0):\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_rate.item():.8f}, Average Error: {train_error_rate:.16f}')\n",
    "\n",
    "    return loss_history, error_history\n",
    "\n",
    "def fit_CNN_model(model, train_loader, test_loader, num_epochs, optimizer, criterion, show_history=True):\n",
    "    # Model becomes \"Train Mode\"\n",
    "    model.train()\n",
    "    if test_loader is not None:\n",
    "       print(\"!-- Training Session --!\")\n",
    "    train_loss_history, train_error_history = iterate_CNN_model(model, train_loader, num_epochs, optimizer, criterion, show_history=show_history, training=True)\n",
    "    \n",
    "    if test_loader is not None:\n",
    "        # Model becomes \"Eval Mode\"\n",
    "        model.eval()\n",
    "        print(\"!-- Testing Session --!\")\n",
    "        test_loss_history, test_error_history = iterate_CNN_model(model, test_loader, num_epochs, optimizer, criterion, show_history=show_history, training=True)\n",
    "    \n",
    "    # Experiment Result\n",
    "    print(\"!-- CNN Model Result --!\")\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "            \n",
    "    # Plot the training and testing loss history\n",
    "    if test_loader is not None:\n",
    "        plt.plot(train_loss_history, label='Training Loss')\n",
    "        plt.plot(test_loss_history, label='Testing Loss')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.plot(train_loss_history)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Training Loss Rate\")\n",
    "    plt.title(\"Average Training Loss History\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate history\n",
    "    if test_loader is not None:\n",
    "        plt.plot(train_error_history, label='Training Error Rate')\n",
    "        plt.plot(test_error_history, label='Testing Error Rate')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.plot(train_error_history)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Error Rate\")\n",
    "    plt.title(\"Average Error Rate History\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the CNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 10\n",
    "\n",
    "# Define neural network model, loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if dataset_name == \"CIFAR-10 Datset\":\n",
    "    model = ConvolutionalNeuralNetwork_CIFAR10(num_classes_preset)\n",
    "else:\n",
    "    model = ConvolutionalNeuralNetwork(num_classes_preset)\n",
    "CNN_input_shape = CNN_input_shape_preset\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0)\n",
    "print(model)\n",
    "\n",
    "# Perform training\n",
    "start = timeit.default_timer()\n",
    "fit_CNN_model(model, train_loader, None, num_epochs, optimizer, criterion, show_history=True)\n",
    "stop = timeit.default_timer()\n",
    "train_time = stop - start\n",
    "print(\"Time: \", train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2 Federated Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Federated Learning Training with stochastic gradient descent method\n",
    "def iterate_FedLearn_model(model, dataset_loader, num_epochs, optimizer, criterion, num_clients, local_update_epochs, client_device, iterate_func=iterate_CNN_model, aggregate_func=Federated_Averaging, show_history=True, training = True):\n",
    "    # Initialize cost history for recording\n",
    "    loss_cost_history = []\n",
    "    error_cost_history = []\n",
    "    send_cost_history = []\n",
    "    time_history = []\n",
    "    send_cost = 0\n",
    "\n",
    "    # Initialize global weights\n",
    "    client_weights = [None] * num_clients\n",
    "    global_weights = model.state_dict()\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    # Iteration\n",
    "    for epoch in range(num_epochs):\n",
    "        client_weights_total = []\n",
    "        loss_count = 0.00\n",
    "        error_count = 0.00\n",
    "\n",
    "        # Clients local update\n",
    "        for client in range(num_clients):\n",
    "            # Transmit the global weight to clients\n",
    "            client_device[client].load_global_weights(global_weights)\n",
    "\n",
    "            # Local update\n",
    "            client_weights[client], local_loss_history, local_error_history = client_device[client].update_weights(local_update_epochs, iterate_func)\n",
    "            local_loss = sum(local_loss_history) / len(local_loss_history)\n",
    "            local_error = sum(local_error_history) / len(local_error_history)\n",
    "\n",
    "            # Send client weights to the server\n",
    "            send_client_weights(client_weights_total, client_weights[client])\n",
    "            client_weights_size = sum(value.numel() for value in client_weights[client].values())\n",
    "            send_cost = send_cost + client_weights_size\n",
    "\n",
    "            # Send client loss and error to the server (we ignore the cost involved here)\n",
    "            loss_count += local_loss\n",
    "            error_count += local_error\n",
    "\n",
    "        # Aggregate client weights on the server\n",
    "        aggregated_weights = aggregate_func(client_weights_total)\n",
    "\n",
    "        # Update global weights with aggregated weights\n",
    "        global_weights.update(aggregated_weights)\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "        # Summarize loss and error\n",
    "        loss_average = loss_count / num_clients\n",
    "        train_error_rate_average = error_count / num_clients\n",
    "\n",
    "        # Record the loss\n",
    "        loss_cost_history.append(loss_average.item())\n",
    "\n",
    "        # Record the error rate\n",
    "        error_cost_history.append(train_error_rate_average)\n",
    "\n",
    "        # Record the send cost\n",
    "        send_cost_history.append(send_cost)\n",
    "\n",
    "        # Record the time history\n",
    "        current_time = timeit.default_timer()\n",
    "        time_history.append(current_time - start_time)\n",
    "\n",
    "        # Print the loss every specific epochs\n",
    "        if show_history is True and ((epoch + 1) % 1 == 0 or epoch == 0):\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average.item():.8f}, Average Error: {train_error_rate_average:.16f}, Culminative Send Cost: {send_cost}')\n",
    "    stop_time = timeit.default_timer()\n",
    "    used_time = stop_time - start_time\n",
    "    print(\"Time for all iteration: \", used_time)\n",
    "    return loss_cost_history, error_cost_history, send_cost_history, time_history\n",
    "\n",
    "def fit_FedLearn_model(model, train_loader, test_loader, num_epochs, num_clients, client_setup_func, local_update_epochs, optimizer, criterion, iterate_func, aggregate_func, show_history=True):\n",
    "    # Preprocess the client data\n",
    "    #client_dataloader_list = split_dataloader(train_loader, num_clients)\n",
    "\n",
    "    # This is the alternative for preprocessing, will be changed in the future\n",
    "\n",
    "    ### Alternative ###\n",
    "    client_dataloader_list = [] * num_clients\n",
    "    X_train_client = [None] * num_clients\n",
    "    y_train_client = [None] * num_clients\n",
    "    client_row = math.floor( num_samples_preset / num_clients )\n",
    "    for client in range(num_clients):\n",
    "        X_train_client[client] = X_train_tensor[(client)*client_row : (client+1)*client_row]\n",
    "        y_train_client[client] = y_train_tensor[(client)*client_row : (client+1)*client_row]\n",
    "        \n",
    "        # Translate the tensor to dataset\n",
    "        client_train_dataset = torch.utils.data.TensorDataset(X_train_client[client], y_train_client[client])\n",
    "\n",
    "        # Translate to DataLoader\n",
    "        client_loader = torch.utils.data.DataLoader(client_train_dataset, batch_size = batch_size_preset, shuffle = True)\n",
    "        client_dataloader_list.append(client_loader)\n",
    "    ### Alternative End ###\n",
    "\n",
    "    ### MINST Split ###\n",
    "    #client_dataloader_list = [] * num_clients\n",
    "    #X_train_client = [[]] * num_clients\n",
    "    #y_train_client = [[]] * num_clients\n",
    "    #client_row = math.floor( num_samples_preset / num_clients )\n",
    "    #for client in range(num_clients):\n",
    "    #    client_labels = torch.where(y_train_tensor == client)[0]\n",
    "    #    X_train_client[client] = X_train_tensor[client_labels]\n",
    "    #    y_train_client[client] = y_train_tensor[client_labels]\n",
    "\n",
    "        # Translate the tensor to dataset\n",
    "    #    client_train_dataset = torch.utils.data.TensorDataset(X_train_client[client], y_train_client[client])\n",
    "\n",
    "        # Translate to DataLoader\n",
    "    #    client_loader = torch.utils.data.DataLoader(client_train_dataset, batch_size = batch_size_preset, shuffle = True)\n",
    "    #    client_dataloader_list.append(client_loader)\n",
    "\n",
    "        # Size\n",
    "        #print(X_train_client[client])\n",
    "        #print(y_train_client[client])\n",
    "        #print(X_train_client[client].size())\n",
    "        #print(y_train_client[client].size())\n",
    "    ### MINST Split End ###\n",
    "\n",
    "    # Define the client model, criterion, optimizer, its dataset\n",
    "    client_model_list = [None] * num_clients\n",
    "    client_optimizer_list = [None] * num_clients\n",
    "    client_criterion_list = [None] * num_clients\n",
    "    client_setup_func(num_clients, client_model_list, client_optimizer_list, client_criterion_list, client_dataloader_list)\n",
    "    \n",
    "    # Establish client devices\n",
    "    client_device = establish_client_devices(num_clients=num_clients, \n",
    "                                             train_dataloader_list=client_dataloader_list, \n",
    "                                             test_dataloader_list= [None] * num_clients,\n",
    "                                             model_list=client_model_list, \n",
    "                                             optimizer_list=client_optimizer_list,\n",
    "                                             criterion_list=client_criterion_list)\n",
    "\n",
    "    # Perform iteration\n",
    "    train_loss_history = []\n",
    "    train_error_history = []\n",
    "    train_send_cost_history = []\n",
    "    train_time_history = []\n",
    "    test_loss_history = []\n",
    "    test_error_history = []\n",
    "    test_send_cost_history = []\n",
    "    test_time_history = []\n",
    "\n",
    "    # Variance Anaylsis\n",
    "    train_loss_var_history = [None] * num_clients\n",
    "    train_error_var_history = [None] * num_clients\n",
    "    test_loss_var_history = [None] * num_clients\n",
    "    test_error_var_history = [None] * num_clients\n",
    "    train_loss_var_history_uphalf = [None] * num_clients\n",
    "    train_error_var_history_uphalf = [None] * num_clients\n",
    "    test_loss_var_history_uphalf = [None] * num_clients\n",
    "    test_error_var_history_uphalf = [None] * num_clients\n",
    "    \n",
    "    # Model becomes \"Train Mode\"\n",
    "    model.train()\n",
    "    if test_loader is not None:\n",
    "        print(\"!-- Training Session --!\")\n",
    "    train_loss_history, train_error_history, train_send_cost_history, train_time_history = iterate_FedLearn_model(model=model, dataset_loader=train_loader, \n",
    "                                                                                         num_epochs=num_epochs, optimizer=optimizer, criterion=criterion, \n",
    "                                                                                         num_clients=num_clients, local_update_epochs=local_update_epochs, client_device=client_device,\n",
    "                                                                                         iterate_func=iterate_func, aggregate_func=aggregate_func,\n",
    "                                                                                         show_history=show_history, training = True)\n",
    "\n",
    "    if test_loader is not None:\n",
    "        # Model becomes \"Eval Mode\"\n",
    "        model.eval()\n",
    "        print(\"!-- Testing Session --!\")\n",
    "        test_loss_history, test_error_history, test_send_cost_history, test_time_history = iterate_FedLearn_model(model=model, dataset_loader=test_loader, \n",
    "                                                                                         num_epochs=num_epochs, optimizer=optimizer, criterion=criterion, \n",
    "                                                                                         num_clients=num_clients, local_update_epochs=local_update_epochs, client_device=client_device,\n",
    "                                                                                         iterate_func=iterate_func, aggregate_func=aggregate_func,\n",
    "                                                                                         show_history=show_history, training = False)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Plot send cost history\n",
    "    if test_loader is not None:\n",
    "        print(f'Total send cost in training: {sum(train_send_cost_history)}')\n",
    "        print(f'Total send cost in testing: {sum(test_send_cost_history)}')\n",
    "        plt.plot(train_send_cost_history, label='Training Send Cost')\n",
    "        plt.plot(test_send_cost_history, label='Testing Send Cost')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        print(f'Total send cost in training: {sum(train_send_cost_history)}')\n",
    "        plt.plot(train_send_cost_history)\n",
    "    plt.plot(train_send_cost_history)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Send Cost\")\n",
    "    plt.title(\"Send Cost History\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the training and testing loss history\n",
    "    if test_loader is not None:\n",
    "        plt.plot(train_loss_history, label='Training Loss')\n",
    "        plt.plot(test_loss_history, label='Testing Loss')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.plot(train_loss_history)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Training Loss Rate\")\n",
    "    plt.title(\"Average Training Loss History\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate history\n",
    "    if test_loader is not None:\n",
    "        plt.plot(train_error_history, label='Training Error Rate')\n",
    "        plt.plot(test_error_history, label='Testing Error Rate')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.plot(train_error_history)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Average Error Rate\")\n",
    "    plt.title(\"Average Error Rate History\")\n",
    "    plt.show()\n",
    "\n",
    "    # Variance Anaylsis\n",
    "    train_loss_var_history[client] = np.var(train_loss_history)\n",
    "    print(f'Train Loss Variance: {train_loss_var_history[client]}')\n",
    "    test_loss_var_history[client] = np.var(test_loss_history)\n",
    "    print(f'Test Loss Variance: {test_loss_var_history[client]}')\n",
    "\n",
    "    train_loss_var_history_uphalf[client] = np.var(train_loss_history[int(len(train_loss_history) / 2):])\n",
    "    print(f'Train Loss Variance For Half: {train_loss_var_history_uphalf[client]}')\n",
    "    test_loss_var_history_uphalf[client] = np.var(test_loss_history[int(len(test_loss_history) / 2):])\n",
    "    print(f'Test Loss Variance For Half: {test_loss_var_history_uphalf[client]}')\n",
    "\n",
    "    train_error_var_history[client] = np.var(train_error_history)\n",
    "    print(f'Train error Variance: {train_error_var_history[client]}')\n",
    "    test_error_var_history[client] = np.var(test_error_history)\n",
    "    print(f'Test error Variance: {test_error_var_history[client]}')\n",
    "\n",
    "    train_error_var_history_uphalf[client] = np.var(train_error_history[int(len(train_error_history) / 2):])\n",
    "    print(f'Train error Variance For Half: {train_loss_var_history_uphalf[client]}')\n",
    "    test_error_var_history_uphalf[client] = np.var(test_error_history[int(len(test_error_history) / 2):])\n",
    "    print(f'Test error Variance For Half: {test_loss_var_history_uphalf[client]}')\n",
    "\n",
    "    # Plot the train time history\n",
    "    if test_loader is not None:\n",
    "        plt.plot(train_time_history, label='Training Time History')\n",
    "        plt.plot(test_time_history, label='Testing Time History')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.plot(train_time_history)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Time used\")\n",
    "    plt.title(\"Iteration Time History\")\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss_history, train_error_history, train_send_cost_history, train_time_history, test_loss_history, test_error_history, test_send_cost_history, test_time_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Federated Learning Expriment Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_FedLearn_model(global_model_class_setup_func, train_loader, test_loader, num_epochs_list, num_clients_list, local_update_epochs_list, client_setup_func, iterate_func, aggregate_func, compareClients=False):\n",
    "    # Cost History Total\n",
    "    num_clients_list_size = len(num_clients_list)\n",
    "    local_update_epochs_list_size = len(local_update_epochs_list)\n",
    "    train_loss_history_total = []\n",
    "    train_error_history_total = []\n",
    "    train_send_cost_history_total = []\n",
    "    train_time_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_error_history_total = []\n",
    "    test_send_cost_history_total = []\n",
    "    test_time_history_total = []\n",
    "    experiment_type = \"test\"\n",
    "\n",
    "    if compareClients is True:\n",
    "        iteration_list = num_clients_list\n",
    "        experiment_type = \"num_clients\"\n",
    "    else:\n",
    "        iteration_list = local_update_epochs_list\n",
    "        experiment_type = \"local_update_epochs\"\n",
    "\n",
    "    for n in range(len(iteration_list)):\n",
    "        if compareClients is True:\n",
    "            print(f'=== The training for num_clients is {num_clients_list[n]} ===')\n",
    "            num_epochs = num_epochs_list[n]\n",
    "            num_clients = num_clients_list[n]\n",
    "            local_update_epochs = local_update_epochs_list[0]\n",
    "        else:\n",
    "            print(f'=== The training for local_update_epochs is {local_update_epochs_list[n]} ===')\n",
    "            num_epochs = num_epochs_list[n]\n",
    "            num_clients = num_clients_list[0]\n",
    "            local_update_epochs = local_update_epochs_list[n]\n",
    "\n",
    "        # Define global neural network model, loss criterion and optimizer\n",
    "        model, criterion, optimizer = global_model_class_setup_func()\n",
    "        print(model)\n",
    "\n",
    "        # Perform training\n",
    "        train_loss_history, train_error_history, train_send_cost_history, train_time_history, test_loss_history, test_error_history, test_send_cost_history, test_time_history = fit_FedLearn_model(model, train_loader, test_loader, num_epochs, num_clients, client_setup_func, local_update_epochs, optimizer, criterion, iterate_func, aggregate_func, show_history=True)\n",
    "\n",
    "        # Record the history of loss, error and send_cost\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        train_send_cost_history_total.append(train_send_cost_history)\n",
    "        train_time_history_total.append(train_time_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "        test_send_cost_history_total.append(test_send_cost_history)\n",
    "        test_time_history_total.append(test_time_history)\n",
    "\n",
    "        filename = \"homogeneous_{}{}{}{}epoch_result\".format(dataset_name, iteration_list[n], experiment_type, num_epochs)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, train_loss = train_loss_history, train_error = train_error_history, train_send_cost = train_send_cost_history, train_time = train_time_history, test_loss = test_loss_history, test_error = test_error_history, test_send_cost = test_send_cost_history, test_time = test_time_history)\n",
    "\n",
    "\n",
    "        # Save the npy result for client (train_loss, train_send_cost, train_time, test_error)\n",
    "        #filename = \"{}_{}_{}_{}epoch_result\".format(dataset_name, experiment_type, iteration_list[n-1], num_epochs)\n",
    "        #with open('filename', 'wb') as f:\n",
    "        #    np.save(f, train_loss_history)\n",
    "        #    np.save(f, train_error_history)\n",
    "        #    np.save(f, train_send_cost_history)\n",
    "        #    np.save(f, train_time_history)\n",
    "        #    np.save(f, test_loss_history)\n",
    "        #    np.save(f, test_error_history)\n",
    "        #    np.save(f, test_send_cost_history)\n",
    "        #    np.save(f, test_time_history)\n",
    "    \n",
    "        # Save the npy result (train_loss_history_total)\n",
    "        #total_filename = \"{}_{}_{}epoch_result\".format(dataset_name, experiment_type, n)\n",
    "        #with open(total_filename, 'wb') as f:\n",
    "        #np.savez(total_filename, train_loss = train_loss_history_total, train_error = train_error_history_total, train_send_cost = train_send_cost_history_total, train_time = train_time_history_total, test_loss = test_loss_history_total, test_error = test_error_history_total, test_send_cost = test_send_cost_history, test_time = test_time_history_total)\n",
    "            #np.save(f, )\n",
    "            #np.save(f, )\n",
    "            #np.save(f, )\n",
    "            #np.save(f, )\n",
    "            #np.save(f, )\n",
    "            #np.save(f, )\n",
    "            #np.save(f, )\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    # Show Dataset Name\n",
    "    print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "    # Training Result\n",
    "    print(f'!-- Training Result --!')\n",
    "    if compareClients is True:\n",
    "        # Plot the training loss rate between cost history with num_clients\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(train_send_cost_history_total[i], train_loss_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Training Loss Rate\")\n",
    "        plt.title(\"Training Loss Rate vs Send Cost (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(train_send_cost_history_total[i], train_error_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate vs Send Cost (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the training loss rate between cost history with num_clients per clients\n",
    "        min_cost_list = train_send_cost_history_total[0]\n",
    "        for sublist in train_send_cost_history_total:\n",
    "            if len(sublist) < len(min_cost_list):\n",
    "                min_cost_list = sublist\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(min_cost_list, train_loss_history_total[i])\n",
    "        plt.xlabel(\"Send Cost per clients\")\n",
    "        plt.ylabel(\"Training Loss Rate\")\n",
    "        plt.title(\"Training Loss Rate vs Send Cost per clients (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_per_clients_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the training loss rate between cost history with num_clients per clients\n",
    "        min_cost_list = train_send_cost_history_total[0]\n",
    "        for sublist in train_send_cost_history_total:\n",
    "            if len(sublist) < len(min_cost_list):\n",
    "                min_cost_list = sublist\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(min_cost_list, train_error_history_total[i])\n",
    "        plt.xlabel(\"Send Cost per clients\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate vs Send Cost per clients (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_per_clients_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        print(f'!-- x-axis as global epochs --!')\n",
    "        # Plot the training loss rate between cost history with num_clients\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(train_loss_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Training Loss Rate\")\n",
    "        plt.title(\"Training Loss Rate (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'Loss_{dataset_name}_num_clients_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(train_error_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'ErrorRate_{dataset_name}_num_clients_training.png')\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        # Plot the training loss rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(train_send_cost_history_total[i], train_loss_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Training Loss Rate\")\n",
    "        plt.title(\"Training Loss Rate vs Send Cost (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_local_update_epochs_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(train_send_cost_history_total[i], train_error_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate vs Send Cost (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_local_update_epochs_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        print(f'!-- x-axis as global epochs --!')\n",
    "        # Plot the training loss rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(train_loss_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Training Loss Rate\")\n",
    "        plt.title(\"Training Loss Rate (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'Loss_epochs_{dataset_name}_local_update_epochs_training.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(train_error_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'ErrorRate_epochs_{dataset_name}_local_update_epochs_training.png')\n",
    "        plt.show()\n",
    "\n",
    "    # Testing Result\n",
    "    print(f'!-- Testing Result --!')\n",
    "    if compareClients is True:\n",
    "        # Plot the training loss rate between cost history with num_clients\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(test_send_cost_history_total[i], test_loss_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Testing Loss Rate\")\n",
    "        plt.title(\"Testing Loss Rate vs Send Cost (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(test_send_cost_history_total[i], test_error_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate vs Send Cost (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the training loss rate between cost history with num_clients per clients\n",
    "        min_cost_list = test_send_cost_history_total[0]\n",
    "        for sublist in test_send_cost_history_total:\n",
    "            if len(sublist) < len(min_cost_list):\n",
    "                min_cost_list = sublist\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(min_cost_list, test_loss_history_total[i])\n",
    "        plt.xlabel(\"Send Cost per clients\")\n",
    "        plt.ylabel(\"Testing Loss Rate\")\n",
    "        plt.title(\"Testing Loss Rate vs Send Cost per clients (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_per_clients_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the training loss rate between cost history with num_clients per clients\n",
    "        min_cost_list = test_send_cost_history_total[0]\n",
    "        for sublist in test_send_cost_history_total:\n",
    "            if len(sublist) < len(min_cost_list):\n",
    "                min_cost_list = sublist\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(min_cost_list, test_error_history_total[i])\n",
    "        plt.xlabel(\"Send Cost per clients\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate vs Send Cost per clients (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_per_clients_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        print(f'!-- x-axis as global epochs --!')\n",
    "        # Plot the training loss rate between cost history with num_clients\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(test_loss_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Testing Loss Rate\")\n",
    "        plt.title(\"Testing Loss Rate (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'Loss_{dataset_name}_num_clients_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(num_clients_list_size):\n",
    "            plt.plot(test_error_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate (with different number of clients)\")\n",
    "        plt.legend(num_clients_list)\n",
    "        plt.savefig(f'ErrorRate_{dataset_name}_num_clients_testing.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Plot the training loss rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(test_send_cost_history_total[i], test_loss_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Training Loss Rate\")\n",
    "        plt.title(\"Training Loss Rate vs Send Cost (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_local_update_epochs_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(test_send_cost_history_total[i], test_error_history_total[i])\n",
    "        plt.xlabel(\"Send Cost\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate vs Send Cost (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_local_update_epochs_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        print(f'!-- x-axis as global epochs --!')\n",
    "        # Plot the training loss rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(test_loss_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Training Loss Rate\")\n",
    "        plt.title(\"Training Loss Rate (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'Loss_epochs_{dataset_name}_local_update_epochs_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the error rate between cost history with local_update_epochs\n",
    "        for i in range(local_update_epochs_list_size):\n",
    "            plt.plot(test_error_history_total[i])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error Rate\")\n",
    "        plt.title(\"Error Rate (with different local update epochs)\")\n",
    "        plt.legend(local_update_epochs_list)\n",
    "        plt.savefig(f'ErrorRate_epochs_{dataset_name}_local_update_epochs_testing.png')\n",
    "        plt.show()\n",
    "\n",
    "    # Compare training and testing result\n",
    "    \n",
    "\n",
    "    # Save the training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_global_model_func_CNN():\n",
    "    if dataset_name == \"CIFAR-10 Datset\":\n",
    "        model = ConvolutionalNeuralNetwork_CIFAR10(num_classes_preset)\n",
    "    else:\n",
    "        model = ConvolutionalNeuralNetwork(num_classes_preset)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "def simple_client_setup_func_CNN(num_clients, client_model_list, client_optimizer_list, client_criterion_list, client_dataloader_list):\n",
    "    for client in range(num_clients):\n",
    "        if dataset_name == \"CIFAR-10 Datset\":\n",
    "            client_model_list[client] = ConvolutionalNeuralNetwork_CIFAR10(num_classes_preset)\n",
    "        else:\n",
    "            client_model_list[client] = ConvolutionalNeuralNetwork(num_classes_preset)\n",
    "        client_criterion_list[client] = nn.CrossEntropyLoss()\n",
    "        client_optimizer_list[client] = torch.optim.SGD(client_model_list[client].parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment for num_clients with CNN model\n",
    "\n",
    "# Define the model parameters\n",
    "learning_rate = learning_rate_preset\n",
    "num_epochs = 5\n",
    "batch_size = batch_size_preset\n",
    "\n",
    "num_epochs_list = [50, 5]\n",
    "num_clients_list = [1,2,5]\n",
    "local_update_epochs_list = [2]\n",
    "\n",
    "CNN_input_shape = CNN_input_shape_preset\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "experiment_type = \"num_clients\"\n",
    "total_filename = \"{}_{}_{}epoch_result\".format(dataset_name, experiment_type, num_epochs)\n",
    "\n",
    "# Experiment\n",
    "experiment_FedLearn_model(simple_global_model_func_CNN, train_loader, test_loader, num_epochs_list, num_clients_list, local_update_epochs_list, simple_client_setup_func_CNN, iterate_CNN_model, Federated_Averaging, compareClients=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expirement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Dataset: CIFAR-10 Datset\n",
      "=== The training for local_update_epochs is 1 ===\n",
      "ConvolutionalNeuralNetwork_CIFAR10(\n",
      "  (activation_stack): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "    (19): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (20): ReLU()\n",
      "    (21): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (22): ReLU()\n",
      "    (23): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "!-- Training Session --!\n",
      "Epoch [1/200], Average Loss: 2.30633025, Average Error: 0.9069999456405640, Culminative Send Cost: 58531330\n",
      "Epoch [2/200], Average Loss: 2.18515327, Average Error: 0.6909999847412109, Culminative Send Cost: 117062660\n",
      "Epoch [3/200], Average Loss: 2.10994499, Average Error: 0.6959999799728394, Culminative Send Cost: 175593990\n",
      "Epoch [4/200], Average Loss: 2.02539656, Average Error: 0.6639999747276306, Culminative Send Cost: 234125320\n",
      "Epoch [5/200], Average Loss: 2.00944207, Average Error: 0.6840000152587891, Culminative Send Cost: 292656650\n",
      "Epoch [6/200], Average Loss: 2.31130626, Average Error: 0.8379999995231628, Culminative Send Cost: 351187980\n",
      "Epoch [7/200], Average Loss: 2.25889239, Average Error: 0.8390000462532043, Culminative Send Cost: 409719310\n",
      "Epoch [8/200], Average Loss: 2.04337673, Average Error: 0.6930000185966492, Culminative Send Cost: 468250640\n",
      "Epoch [9/200], Average Loss: 1.93592349, Average Error: 0.6480000019073486, Culminative Send Cost: 526781970\n",
      "Epoch [10/200], Average Loss: 1.84738572, Average Error: 0.6190000176429749, Culminative Send Cost: 585313300\n",
      "Epoch [11/200], Average Loss: 1.86360134, Average Error: 0.6330000162124634, Culminative Send Cost: 643844630\n",
      "Epoch [12/200], Average Loss: 1.95429167, Average Error: 0.6970000267028809, Culminative Send Cost: 702375960\n",
      "Epoch [13/200], Average Loss: 1.91801770, Average Error: 0.6880000233650208, Culminative Send Cost: 760907290\n",
      "Epoch [14/200], Average Loss: 1.81722385, Average Error: 0.6179999709129333, Culminative Send Cost: 819438620\n",
      "Epoch [15/200], Average Loss: 1.80860925, Average Error: 0.6140000224113464, Culminative Send Cost: 877969950\n",
      "Epoch [16/200], Average Loss: 1.84210768, Average Error: 0.6430000066757202, Culminative Send Cost: 936501280\n",
      "Epoch [17/200], Average Loss: 1.94224988, Average Error: 0.6729999780654907, Culminative Send Cost: 995032610\n",
      "Epoch [18/200], Average Loss: 1.87599733, Average Error: 0.6389999985694885, Culminative Send Cost: 1053563940\n",
      "Epoch [19/200], Average Loss: 1.85987318, Average Error: 0.6790000200271606, Culminative Send Cost: 1112095270\n",
      "Epoch [20/200], Average Loss: 1.71152407, Average Error: 0.5839999914169312, Culminative Send Cost: 1170626600\n",
      "Epoch [21/200], Average Loss: 1.66772224, Average Error: 0.6019999980926514, Culminative Send Cost: 1229157930\n",
      "Epoch [22/200], Average Loss: 1.74506243, Average Error: 0.6149999499320984, Culminative Send Cost: 1287689260\n",
      "Epoch [23/200], Average Loss: 1.79832205, Average Error: 0.6209999918937683, Culminative Send Cost: 1346220590\n",
      "Epoch [24/200], Average Loss: 1.65885350, Average Error: 0.5379999876022339, Culminative Send Cost: 1404751920\n",
      "Epoch [25/200], Average Loss: 1.63194010, Average Error: 0.5659999847412109, Culminative Send Cost: 1463283250\n",
      "Epoch [26/200], Average Loss: 1.64449055, Average Error: 0.5630000233650208, Culminative Send Cost: 1521814580\n",
      "Epoch [27/200], Average Loss: 1.78052111, Average Error: 0.6169999837875366, Culminative Send Cost: 1580345910\n",
      "Epoch [28/200], Average Loss: 1.72173250, Average Error: 0.5730000734329224, Culminative Send Cost: 1638877240\n",
      "Epoch [29/200], Average Loss: 1.54203142, Average Error: 0.5470000505447388, Culminative Send Cost: 1697408570\n",
      "Epoch [30/200], Average Loss: 1.34081538, Average Error: 0.4299999773502350, Culminative Send Cost: 1755939900\n",
      "Epoch [31/200], Average Loss: 1.42191496, Average Error: 0.4970000386238098, Culminative Send Cost: 1814471230\n",
      "Epoch [32/200], Average Loss: 1.57178305, Average Error: 0.5540000200271606, Culminative Send Cost: 1873002560\n",
      "Epoch [33/200], Average Loss: 1.66744405, Average Error: 0.5299999713897705, Culminative Send Cost: 1931533890\n",
      "Epoch [34/200], Average Loss: 1.78839356, Average Error: 0.5699999928474426, Culminative Send Cost: 1990065220\n",
      "Epoch [35/200], Average Loss: 1.56385937, Average Error: 0.4679999947547913, Culminative Send Cost: 2048596550\n",
      "Epoch [36/200], Average Loss: 1.32333845, Average Error: 0.4120000302791595, Culminative Send Cost: 2107127880\n",
      "Epoch [37/200], Average Loss: 1.20420241, Average Error: 0.3899999856948853, Culminative Send Cost: 2165659210\n",
      "Epoch [38/200], Average Loss: 1.19979596, Average Error: 0.4039999842643738, Culminative Send Cost: 2224190540\n",
      "Epoch [39/200], Average Loss: 1.34437180, Average Error: 0.4670000076293945, Culminative Send Cost: 2282721870\n",
      "Epoch [40/200], Average Loss: 1.66518962, Average Error: 0.5740000009536743, Culminative Send Cost: 2341253200\n",
      "Epoch [41/200], Average Loss: 1.67999924, Average Error: 0.5400000810623169, Culminative Send Cost: 2399784530\n",
      "Epoch [42/200], Average Loss: 1.36923982, Average Error: 0.4639999866485596, Culminative Send Cost: 2458315860\n",
      "Epoch [43/200], Average Loss: 1.00306628, Average Error: 0.2959999740123749, Culminative Send Cost: 2516847190\n",
      "Epoch [44/200], Average Loss: 0.87896337, Average Error: 0.2639999985694885, Culminative Send Cost: 2575378520\n",
      "Epoch [45/200], Average Loss: 1.16957204, Average Error: 0.3230000138282776, Culminative Send Cost: 2633909850\n",
      "Epoch [46/200], Average Loss: 1.16322409, Average Error: 0.3789999783039093, Culminative Send Cost: 2692441180\n",
      "Epoch [47/200], Average Loss: 1.27424103, Average Error: 0.3980000317096710, Culminative Send Cost: 2750972510\n",
      "Epoch [48/200], Average Loss: 0.96098128, Average Error: 0.2820000052452087, Culminative Send Cost: 2809503840\n",
      "Epoch [49/200], Average Loss: 0.66136510, Average Error: 0.1669999808073044, Culminative Send Cost: 2868035170\n",
      "Epoch [50/200], Average Loss: 0.47189597, Average Error: 0.1129999980330467, Culminative Send Cost: 2926566500\n",
      "Epoch [51/200], Average Loss: 0.44768146, Average Error: 0.1409999877214432, Culminative Send Cost: 2985097830\n",
      "Epoch [52/200], Average Loss: 0.68091463, Average Error: 0.2130000144243240, Culminative Send Cost: 3043629160\n",
      "Epoch [53/200], Average Loss: 0.74237396, Average Error: 0.1920000016689301, Culminative Send Cost: 3102160490\n",
      "Epoch [54/200], Average Loss: 0.48751058, Average Error: 0.1200000047683716, Culminative Send Cost: 3160691820\n",
      "Epoch [55/200], Average Loss: 0.39813536, Average Error: 0.1140000075101852, Culminative Send Cost: 3219223150\n",
      "Epoch [56/200], Average Loss: 0.36994497, Average Error: 0.0960000008344650, Culminative Send Cost: 3277754480\n",
      "Epoch [57/200], Average Loss: 0.38026708, Average Error: 0.1080000028014183, Culminative Send Cost: 3336285810\n",
      "Epoch [58/200], Average Loss: 0.18910752, Average Error: 0.0289999991655350, Culminative Send Cost: 3394817140\n",
      "Epoch [59/200], Average Loss: 0.07587975, Average Error: 0.0079999994486570, Culminative Send Cost: 3453348470\n",
      "Epoch [60/200], Average Loss: 0.03951203, Average Error: 0.0009999999310821, Culminative Send Cost: 3511879800\n",
      "Epoch [61/200], Average Loss: 0.02779549, Average Error: 0.0000000000000000, Culminative Send Cost: 3570411130\n",
      "Epoch [62/200], Average Loss: 0.02197047, Average Error: 0.0000000000000000, Culminative Send Cost: 3628942460\n",
      "Epoch [63/200], Average Loss: 0.01824912, Average Error: 0.0000000000000000, Culminative Send Cost: 3687473790\n",
      "Epoch [64/200], Average Loss: 0.01561913, Average Error: 0.0000000000000000, Culminative Send Cost: 3746005120\n",
      "Epoch [65/200], Average Loss: 0.01366102, Average Error: 0.0000000000000000, Culminative Send Cost: 3804536450\n",
      "Epoch [66/200], Average Loss: 0.01213510, Average Error: 0.0000000000000000, Culminative Send Cost: 3863067780\n",
      "Epoch [67/200], Average Loss: 0.01091111, Average Error: 0.0000000000000000, Culminative Send Cost: 3921599110\n",
      "Epoch [68/200], Average Loss: 0.00990838, Average Error: 0.0000000000000000, Culminative Send Cost: 3980130440\n",
      "Epoch [69/200], Average Loss: 0.00907142, Average Error: 0.0000000000000000, Culminative Send Cost: 4038661770\n",
      "Epoch [70/200], Average Loss: 0.00836178, Average Error: 0.0000000000000000, Culminative Send Cost: 4097193100\n",
      "Epoch [71/200], Average Loss: 0.00775242, Average Error: 0.0000000000000000, Culminative Send Cost: 4155724430\n",
      "Epoch [72/200], Average Loss: 0.00722325, Average Error: 0.0000000000000000, Culminative Send Cost: 4214255760\n",
      "Epoch [73/200], Average Loss: 0.00675941, Average Error: 0.0000000000000000, Culminative Send Cost: 4272787090\n",
      "Epoch [74/200], Average Loss: 0.00634980, Average Error: 0.0000000000000000, Culminative Send Cost: 4331318420\n",
      "Epoch [75/200], Average Loss: 0.00598509, Average Error: 0.0000000000000000, Culminative Send Cost: 4389849750\n",
      "Epoch [76/200], Average Loss: 0.00565885, Average Error: 0.0000000000000000, Culminative Send Cost: 4448381080\n",
      "Epoch [77/200], Average Loss: 0.00536536, Average Error: 0.0000000000000000, Culminative Send Cost: 4506912410\n",
      "Epoch [78/200], Average Loss: 0.00509970, Average Error: 0.0000000000000000, Culminative Send Cost: 4565443740\n",
      "Epoch [79/200], Average Loss: 0.00485788, Average Error: 0.0000000000000000, Culminative Send Cost: 4623975070\n",
      "Epoch [80/200], Average Loss: 0.00463683, Average Error: 0.0000000000000000, Culminative Send Cost: 4682506400\n",
      "Epoch [81/200], Average Loss: 0.00443417, Average Error: 0.0000000000000000, Culminative Send Cost: 4741037730\n",
      "Epoch [82/200], Average Loss: 0.00424774, Average Error: 0.0000000000000000, Culminative Send Cost: 4799569060\n",
      "Epoch [83/200], Average Loss: 0.00407568, Average Error: 0.0000000000000000, Culminative Send Cost: 4858100390\n",
      "Epoch [84/200], Average Loss: 0.00391636, Average Error: 0.0000000000000000, Culminative Send Cost: 4916631720\n",
      "Epoch [85/200], Average Loss: 0.00376827, Average Error: 0.0000000000000000, Culminative Send Cost: 4975163050\n",
      "Epoch [86/200], Average Loss: 0.00363032, Average Error: 0.0000000000000000, Culminative Send Cost: 5033694380\n",
      "Epoch [87/200], Average Loss: 0.00350159, Average Error: 0.0000000000000000, Culminative Send Cost: 5092225710\n",
      "Epoch [88/200], Average Loss: 0.00338122, Average Error: 0.0000000000000000, Culminative Send Cost: 5150757040\n",
      "Epoch [89/200], Average Loss: 0.00326849, Average Error: 0.0000000000000000, Culminative Send Cost: 5209288370\n",
      "Epoch [90/200], Average Loss: 0.00316274, Average Error: 0.0000000000000000, Culminative Send Cost: 5267819700\n",
      "Epoch [91/200], Average Loss: 0.00306327, Average Error: 0.0000000000000000, Culminative Send Cost: 5326351030\n",
      "Epoch [92/200], Average Loss: 0.00296954, Average Error: 0.0000000000000000, Culminative Send Cost: 5384882360\n",
      "Epoch [93/200], Average Loss: 0.00288107, Average Error: 0.0000000000000000, Culminative Send Cost: 5443413690\n",
      "Epoch [94/200], Average Loss: 0.00279745, Average Error: 0.0000000000000000, Culminative Send Cost: 5501945020\n",
      "Epoch [95/200], Average Loss: 0.00271833, Average Error: 0.0000000000000000, Culminative Send Cost: 5560476350\n",
      "Epoch [96/200], Average Loss: 0.00264331, Average Error: 0.0000000000000000, Culminative Send Cost: 5619007680\n",
      "Epoch [97/200], Average Loss: 0.00257206, Average Error: 0.0000000000000000, Culminative Send Cost: 5677539010\n",
      "Epoch [98/200], Average Loss: 0.00250433, Average Error: 0.0000000000000000, Culminative Send Cost: 5736070340\n",
      "Epoch [99/200], Average Loss: 0.00243987, Average Error: 0.0000000000000000, Culminative Send Cost: 5794601670\n",
      "Epoch [100/200], Average Loss: 0.00237845, Average Error: 0.0000000000000000, Culminative Send Cost: 5853133000\n",
      "Epoch [101/200], Average Loss: 0.00231986, Average Error: 0.0000000000000000, Culminative Send Cost: 5911664330\n",
      "Epoch [102/200], Average Loss: 0.00226394, Average Error: 0.0000000000000000, Culminative Send Cost: 5970195660\n",
      "Epoch [103/200], Average Loss: 0.00221046, Average Error: 0.0000000000000000, Culminative Send Cost: 6028726990\n",
      "Epoch [104/200], Average Loss: 0.00215934, Average Error: 0.0000000000000000, Culminative Send Cost: 6087258320\n",
      "Epoch [105/200], Average Loss: 0.00211040, Average Error: 0.0000000000000000, Culminative Send Cost: 6145789650\n",
      "Epoch [106/200], Average Loss: 0.00206351, Average Error: 0.0000000000000000, Culminative Send Cost: 6204320980\n",
      "Epoch [107/200], Average Loss: 0.00201856, Average Error: 0.0000000000000000, Culminative Send Cost: 6262852310\n",
      "Epoch [108/200], Average Loss: 0.00197542, Average Error: 0.0000000000000000, Culminative Send Cost: 6321383640\n",
      "Epoch [109/200], Average Loss: 0.00193398, Average Error: 0.0000000000000000, Culminative Send Cost: 6379914970\n",
      "Epoch [110/200], Average Loss: 0.00189414, Average Error: 0.0000000000000000, Culminative Send Cost: 6438446300\n",
      "Epoch [111/200], Average Loss: 0.00185583, Average Error: 0.0000000000000000, Culminative Send Cost: 6496977630\n",
      "Epoch [112/200], Average Loss: 0.00181897, Average Error: 0.0000000000000000, Culminative Send Cost: 6555508960\n",
      "Epoch [113/200], Average Loss: 0.00178346, Average Error: 0.0000000000000000, Culminative Send Cost: 6614040290\n",
      "Epoch [114/200], Average Loss: 0.00174923, Average Error: 0.0000000000000000, Culminative Send Cost: 6672571620\n",
      "Epoch [115/200], Average Loss: 0.00171621, Average Error: 0.0000000000000000, Culminative Send Cost: 6731102950\n",
      "Epoch [116/200], Average Loss: 0.00168437, Average Error: 0.0000000000000000, Culminative Send Cost: 6789634280\n",
      "Epoch [117/200], Average Loss: 0.00165361, Average Error: 0.0000000000000000, Culminative Send Cost: 6848165610\n",
      "Epoch [118/200], Average Loss: 0.00162390, Average Error: 0.0000000000000000, Culminative Send Cost: 6906696940\n",
      "Epoch [119/200], Average Loss: 0.00159518, Average Error: 0.0000000000000000, Culminative Send Cost: 6965228270\n",
      "Epoch [120/200], Average Loss: 0.00156739, Average Error: 0.0000000000000000, Culminative Send Cost: 7023759600\n",
      "Epoch [121/200], Average Loss: 0.00154049, Average Error: 0.0000000000000000, Culminative Send Cost: 7082290930\n",
      "Epoch [122/200], Average Loss: 0.00151446, Average Error: 0.0000000000000000, Culminative Send Cost: 7140822260\n",
      "Epoch [123/200], Average Loss: 0.00148922, Average Error: 0.0000000000000000, Culminative Send Cost: 7199353590\n",
      "Epoch [124/200], Average Loss: 0.00146478, Average Error: 0.0000000000000000, Culminative Send Cost: 7257884920\n",
      "Epoch [125/200], Average Loss: 0.00144109, Average Error: 0.0000000000000000, Culminative Send Cost: 7316416250\n",
      "Epoch [126/200], Average Loss: 0.00141811, Average Error: 0.0000000000000000, Culminative Send Cost: 7374947580\n",
      "Epoch [127/200], Average Loss: 0.00139580, Average Error: 0.0000000000000000, Culminative Send Cost: 7433478910\n",
      "Epoch [128/200], Average Loss: 0.00137415, Average Error: 0.0000000000000000, Culminative Send Cost: 7492010240\n",
      "Epoch [129/200], Average Loss: 0.00135309, Average Error: 0.0000000000000000, Culminative Send Cost: 7550541570\n",
      "Epoch [130/200], Average Loss: 0.00133266, Average Error: 0.0000000000000000, Culminative Send Cost: 7609072900\n",
      "Epoch [131/200], Average Loss: 0.00131279, Average Error: 0.0000000000000000, Culminative Send Cost: 7667604230\n",
      "Epoch [132/200], Average Loss: 0.00129347, Average Error: 0.0000000000000000, Culminative Send Cost: 7726135560\n",
      "Epoch [133/200], Average Loss: 0.00127468, Average Error: 0.0000000000000000, Culminative Send Cost: 7784666890\n",
      "Epoch [134/200], Average Loss: 0.00125639, Average Error: 0.0000000000000000, Culminative Send Cost: 7843198220\n",
      "Epoch [135/200], Average Loss: 0.00123859, Average Error: 0.0000000000000000, Culminative Send Cost: 7901729550\n",
      "Epoch [136/200], Average Loss: 0.00122127, Average Error: 0.0000000000000000, Culminative Send Cost: 7960260880\n",
      "Epoch [137/200], Average Loss: 0.00120440, Average Error: 0.0000000000000000, Culminative Send Cost: 8018792210\n",
      "Epoch [138/200], Average Loss: 0.00118797, Average Error: 0.0000000000000000, Culminative Send Cost: 8077323540\n",
      "Epoch [139/200], Average Loss: 0.00117196, Average Error: 0.0000000000000000, Culminative Send Cost: 8135854870\n",
      "Epoch [140/200], Average Loss: 0.00115634, Average Error: 0.0000000000000000, Culminative Send Cost: 8194386200\n",
      "Epoch [141/200], Average Loss: 0.00114111, Average Error: 0.0000000000000000, Culminative Send Cost: 8252917530\n",
      "Epoch [142/200], Average Loss: 0.00112626, Average Error: 0.0000000000000000, Culminative Send Cost: 8311448860\n",
      "Epoch [143/200], Average Loss: 0.00111175, Average Error: 0.0000000000000000, Culminative Send Cost: 8369980190\n",
      "Epoch [144/200], Average Loss: 0.00109760, Average Error: 0.0000000000000000, Culminative Send Cost: 8428511520\n",
      "Epoch [145/200], Average Loss: 0.00108377, Average Error: 0.0000000000000000, Culminative Send Cost: 8487042850\n",
      "Epoch [146/200], Average Loss: 0.00107028, Average Error: 0.0000000000000000, Culminative Send Cost: 8545574180\n",
      "Epoch [147/200], Average Loss: 0.00105710, Average Error: 0.0000000000000000, Culminative Send Cost: 8604105510\n",
      "Epoch [148/200], Average Loss: 0.00104421, Average Error: 0.0000000000000000, Culminative Send Cost: 8662636840\n",
      "Epoch [149/200], Average Loss: 0.00103163, Average Error: 0.0000000000000000, Culminative Send Cost: 8721168170\n",
      "Epoch [150/200], Average Loss: 0.00101933, Average Error: 0.0000000000000000, Culminative Send Cost: 8779699500\n",
      "Epoch [151/200], Average Loss: 0.00100730, Average Error: 0.0000000000000000, Culminative Send Cost: 8838230830\n",
      "Epoch [152/200], Average Loss: 0.00099553, Average Error: 0.0000000000000000, Culminative Send Cost: 8896762160\n",
      "Epoch [153/200], Average Loss: 0.00098402, Average Error: 0.0000000000000000, Culminative Send Cost: 8955293490\n",
      "Epoch [154/200], Average Loss: 0.00097276, Average Error: 0.0000000000000000, Culminative Send Cost: 9013824820\n",
      "Epoch [155/200], Average Loss: 0.00096173, Average Error: 0.0000000000000000, Culminative Send Cost: 9072356150\n",
      "Epoch [156/200], Average Loss: 0.00095093, Average Error: 0.0000000000000000, Culminative Send Cost: 9130887480\n",
      "Epoch [157/200], Average Loss: 0.00094036, Average Error: 0.0000000000000000, Culminative Send Cost: 9189418810\n",
      "Epoch [158/200], Average Loss: 0.00093002, Average Error: 0.0000000000000000, Culminative Send Cost: 9247950140\n",
      "Epoch [159/200], Average Loss: 0.00091988, Average Error: 0.0000000000000000, Culminative Send Cost: 9306481470\n",
      "Epoch [160/200], Average Loss: 0.00090996, Average Error: 0.0000000000000000, Culminative Send Cost: 9365012800\n",
      "Epoch [161/200], Average Loss: 0.00090022, Average Error: 0.0000000000000000, Culminative Send Cost: 9423544130\n",
      "Epoch [162/200], Average Loss: 0.00089069, Average Error: 0.0000000000000000, Culminative Send Cost: 9482075460\n",
      "Epoch [163/200], Average Loss: 0.00088134, Average Error: 0.0000000000000000, Culminative Send Cost: 9540606790\n",
      "Epoch [164/200], Average Loss: 0.00087218, Average Error: 0.0000000000000000, Culminative Send Cost: 9599138120\n",
      "Epoch [165/200], Average Loss: 0.00086319, Average Error: 0.0000000000000000, Culminative Send Cost: 9657669450\n",
      "Epoch [166/200], Average Loss: 0.00085438, Average Error: 0.0000000000000000, Culminative Send Cost: 9716200780\n",
      "Epoch [167/200], Average Loss: 0.00084573, Average Error: 0.0000000000000000, Culminative Send Cost: 9774732110\n",
      "Epoch [168/200], Average Loss: 0.00083724, Average Error: 0.0000000000000000, Culminative Send Cost: 9833263440\n",
      "Epoch [169/200], Average Loss: 0.00082893, Average Error: 0.0000000000000000, Culminative Send Cost: 9891794770\n",
      "Epoch [170/200], Average Loss: 0.00082075, Average Error: 0.0000000000000000, Culminative Send Cost: 9950326100\n",
      "Epoch [171/200], Average Loss: 0.00081273, Average Error: 0.0000000000000000, Culminative Send Cost: 10008857430\n",
      "Epoch [172/200], Average Loss: 0.00080485, Average Error: 0.0000000000000000, Culminative Send Cost: 10067388760\n",
      "Epoch [173/200], Average Loss: 0.00079712, Average Error: 0.0000000000000000, Culminative Send Cost: 10125920090\n",
      "Epoch [174/200], Average Loss: 0.00078953, Average Error: 0.0000000000000000, Culminative Send Cost: 10184451420\n",
      "Epoch [175/200], Average Loss: 0.00078207, Average Error: 0.0000000000000000, Culminative Send Cost: 10242982750\n",
      "Epoch [176/200], Average Loss: 0.00077475, Average Error: 0.0000000000000000, Culminative Send Cost: 10301514080\n",
      "Epoch [177/200], Average Loss: 0.00076755, Average Error: 0.0000000000000000, Culminative Send Cost: 10360045410\n",
      "Epoch [178/200], Average Loss: 0.00076048, Average Error: 0.0000000000000000, Culminative Send Cost: 10418576740\n",
      "Epoch [179/200], Average Loss: 0.00075352, Average Error: 0.0000000000000000, Culminative Send Cost: 10477108070\n",
      "Epoch [180/200], Average Loss: 0.00074669, Average Error: 0.0000000000000000, Culminative Send Cost: 10535639400\n",
      "Epoch [181/200], Average Loss: 0.00073998, Average Error: 0.0000000000000000, Culminative Send Cost: 10594170730\n",
      "Epoch [182/200], Average Loss: 0.00073337, Average Error: 0.0000000000000000, Culminative Send Cost: 10652702060\n",
      "Epoch [183/200], Average Loss: 0.00072687, Average Error: 0.0000000000000000, Culminative Send Cost: 10711233390\n",
      "Epoch [184/200], Average Loss: 0.00072049, Average Error: 0.0000000000000000, Culminative Send Cost: 10769764720\n",
      "Epoch [185/200], Average Loss: 0.00071420, Average Error: 0.0000000000000000, Culminative Send Cost: 10828296050\n",
      "Epoch [186/200], Average Loss: 0.00070803, Average Error: 0.0000000000000000, Culminative Send Cost: 10886827380\n",
      "Epoch [187/200], Average Loss: 0.00070195, Average Error: 0.0000000000000000, Culminative Send Cost: 10945358710\n",
      "Epoch [188/200], Average Loss: 0.00069597, Average Error: 0.0000000000000000, Culminative Send Cost: 11003890040\n",
      "Epoch [189/200], Average Loss: 0.00069008, Average Error: 0.0000000000000000, Culminative Send Cost: 11062421370\n",
      "Epoch [190/200], Average Loss: 0.00068429, Average Error: 0.0000000000000000, Culminative Send Cost: 11120952700\n",
      "Epoch [191/200], Average Loss: 0.00067858, Average Error: 0.0000000000000000, Culminative Send Cost: 11179484030\n",
      "Epoch [192/200], Average Loss: 0.00067297, Average Error: 0.0000000000000000, Culminative Send Cost: 11238015360\n",
      "Epoch [193/200], Average Loss: 0.00066745, Average Error: 0.0000000000000000, Culminative Send Cost: 11296546690\n",
      "Epoch [194/200], Average Loss: 0.00066200, Average Error: 0.0000000000000000, Culminative Send Cost: 11355078020\n",
      "Epoch [195/200], Average Loss: 0.00065664, Average Error: 0.0000000000000000, Culminative Send Cost: 11413609350\n",
      "Epoch [196/200], Average Loss: 0.00065137, Average Error: 0.0000000000000000, Culminative Send Cost: 11472140680\n",
      "Epoch [197/200], Average Loss: 0.00064617, Average Error: 0.0000000000000000, Culminative Send Cost: 11530672010\n",
      "Epoch [198/200], Average Loss: 0.00064104, Average Error: 0.0000000000000000, Culminative Send Cost: 11589203340\n",
      "Epoch [199/200], Average Loss: 0.00063600, Average Error: 0.0000000000000000, Culminative Send Cost: 11647734670\n",
      "Epoch [200/200], Average Loss: 0.00063103, Average Error: 0.0000000000000000, Culminative Send Cost: 11706266000\n",
      "Time for all iteration:  1437.5083419\n",
      "!-- Testing Session --!\n",
      "Epoch [1/200], Average Loss: 0.00062612, Average Error: 0.0000000000000000, Culminative Send Cost: 58531330\n",
      "Epoch [2/200], Average Loss: 0.00062130, Average Error: 0.0000000000000000, Culminative Send Cost: 117062660\n",
      "Epoch [3/200], Average Loss: 0.00061654, Average Error: 0.0000000000000000, Culminative Send Cost: 175593990\n",
      "Epoch [4/200], Average Loss: 0.00061185, Average Error: 0.0000000000000000, Culminative Send Cost: 234125320\n",
      "Epoch [5/200], Average Loss: 0.00060722, Average Error: 0.0000000000000000, Culminative Send Cost: 292656650\n",
      "Epoch [6/200], Average Loss: 0.00060267, Average Error: 0.0000000000000000, Culminative Send Cost: 351187980\n",
      "Epoch [7/200], Average Loss: 0.00059817, Average Error: 0.0000000000000000, Culminative Send Cost: 409719310\n",
      "Epoch [8/200], Average Loss: 0.00059374, Average Error: 0.0000000000000000, Culminative Send Cost: 468250640\n",
      "Epoch [9/200], Average Loss: 0.00058937, Average Error: 0.0000000000000000, Culminative Send Cost: 526781970\n",
      "Epoch [10/200], Average Loss: 0.00058506, Average Error: 0.0000000000000000, Culminative Send Cost: 585313300\n",
      "Epoch [11/200], Average Loss: 0.00058081, Average Error: 0.0000000000000000, Culminative Send Cost: 643844630\n",
      "Epoch [12/200], Average Loss: 0.00057661, Average Error: 0.0000000000000000, Culminative Send Cost: 702375960\n",
      "Epoch [13/200], Average Loss: 0.00057247, Average Error: 0.0000000000000000, Culminative Send Cost: 760907290\n",
      "Epoch [14/200], Average Loss: 0.00056839, Average Error: 0.0000000000000000, Culminative Send Cost: 819438620\n",
      "Epoch [15/200], Average Loss: 0.00056436, Average Error: 0.0000000000000000, Culminative Send Cost: 877969950\n",
      "Epoch [16/200], Average Loss: 0.00056039, Average Error: 0.0000000000000000, Culminative Send Cost: 936501280\n",
      "Epoch [17/200], Average Loss: 0.00055647, Average Error: 0.0000000000000000, Culminative Send Cost: 995032610\n",
      "Epoch [18/200], Average Loss: 0.00055260, Average Error: 0.0000000000000000, Culminative Send Cost: 1053563940\n",
      "Epoch [19/200], Average Loss: 0.00054877, Average Error: 0.0000000000000000, Culminative Send Cost: 1112095270\n",
      "Epoch [20/200], Average Loss: 0.00054501, Average Error: 0.0000000000000000, Culminative Send Cost: 1170626600\n",
      "Epoch [21/200], Average Loss: 0.00054128, Average Error: 0.0000000000000000, Culminative Send Cost: 1229157930\n",
      "Epoch [22/200], Average Loss: 0.00053760, Average Error: 0.0000000000000000, Culminative Send Cost: 1287689260\n",
      "Epoch [23/200], Average Loss: 0.00053398, Average Error: 0.0000000000000000, Culminative Send Cost: 1346220590\n",
      "Epoch [24/200], Average Loss: 0.00053040, Average Error: 0.0000000000000000, Culminative Send Cost: 1404751920\n",
      "Epoch [25/200], Average Loss: 0.00052686, Average Error: 0.0000000000000000, Culminative Send Cost: 1463283250\n",
      "Epoch [26/200], Average Loss: 0.00052337, Average Error: 0.0000000000000000, Culminative Send Cost: 1521814580\n",
      "Epoch [27/200], Average Loss: 0.00051992, Average Error: 0.0000000000000000, Culminative Send Cost: 1580345910\n",
      "Epoch [28/200], Average Loss: 0.00051651, Average Error: 0.0000000000000000, Culminative Send Cost: 1638877240\n",
      "Epoch [29/200], Average Loss: 0.00051315, Average Error: 0.0000000000000000, Culminative Send Cost: 1697408570\n",
      "Epoch [30/200], Average Loss: 0.00050982, Average Error: 0.0000000000000000, Culminative Send Cost: 1755939900\n",
      "Epoch [31/200], Average Loss: 0.00050654, Average Error: 0.0000000000000000, Culminative Send Cost: 1814471230\n",
      "Epoch [32/200], Average Loss: 0.00050329, Average Error: 0.0000000000000000, Culminative Send Cost: 1873002560\n",
      "Epoch [33/200], Average Loss: 0.00050010, Average Error: 0.0000000000000000, Culminative Send Cost: 1931533890\n",
      "Epoch [34/200], Average Loss: 0.00049693, Average Error: 0.0000000000000000, Culminative Send Cost: 1990065220\n",
      "Epoch [35/200], Average Loss: 0.00049380, Average Error: 0.0000000000000000, Culminative Send Cost: 2048596550\n",
      "Epoch [36/200], Average Loss: 0.00049071, Average Error: 0.0000000000000000, Culminative Send Cost: 2107127880\n",
      "Epoch [37/200], Average Loss: 0.00048765, Average Error: 0.0000000000000000, Culminative Send Cost: 2165659210\n",
      "Epoch [38/200], Average Loss: 0.00048463, Average Error: 0.0000000000000000, Culminative Send Cost: 2224190540\n",
      "Epoch [39/200], Average Loss: 0.00048165, Average Error: 0.0000000000000000, Culminative Send Cost: 2282721870\n",
      "Epoch [40/200], Average Loss: 0.00047869, Average Error: 0.0000000000000000, Culminative Send Cost: 2341253200\n",
      "Epoch [41/200], Average Loss: 0.00047578, Average Error: 0.0000000000000000, Culminative Send Cost: 2399784530\n",
      "Epoch [42/200], Average Loss: 0.00047289, Average Error: 0.0000000000000000, Culminative Send Cost: 2458315860\n",
      "Epoch [43/200], Average Loss: 0.00047004, Average Error: 0.0000000000000000, Culminative Send Cost: 2516847190\n",
      "Epoch [44/200], Average Loss: 0.00046722, Average Error: 0.0000000000000000, Culminative Send Cost: 2575378520\n",
      "Epoch [45/200], Average Loss: 0.00046443, Average Error: 0.0000000000000000, Culminative Send Cost: 2633909850\n",
      "Epoch [46/200], Average Loss: 0.00046168, Average Error: 0.0000000000000000, Culminative Send Cost: 2692441180\n",
      "Epoch [47/200], Average Loss: 0.00045896, Average Error: 0.0000000000000000, Culminative Send Cost: 2750972510\n",
      "Epoch [48/200], Average Loss: 0.00045626, Average Error: 0.0000000000000000, Culminative Send Cost: 2809503840\n",
      "Epoch [49/200], Average Loss: 0.00045360, Average Error: 0.0000000000000000, Culminative Send Cost: 2868035170\n",
      "Epoch [50/200], Average Loss: 0.00045096, Average Error: 0.0000000000000000, Culminative Send Cost: 2926566500\n",
      "Epoch [51/200], Average Loss: 0.00044835, Average Error: 0.0000000000000000, Culminative Send Cost: 2985097830\n",
      "Epoch [52/200], Average Loss: 0.00044577, Average Error: 0.0000000000000000, Culminative Send Cost: 3043629160\n",
      "Epoch [53/200], Average Loss: 0.00044322, Average Error: 0.0000000000000000, Culminative Send Cost: 3102160490\n",
      "Epoch [54/200], Average Loss: 0.00044069, Average Error: 0.0000000000000000, Culminative Send Cost: 3160691820\n",
      "Epoch [55/200], Average Loss: 0.00043819, Average Error: 0.0000000000000000, Culminative Send Cost: 3219223150\n",
      "Epoch [56/200], Average Loss: 0.00043573, Average Error: 0.0000000000000000, Culminative Send Cost: 3277754480\n",
      "Epoch [57/200], Average Loss: 0.00043328, Average Error: 0.0000000000000000, Culminative Send Cost: 3336285810\n",
      "Epoch [58/200], Average Loss: 0.00043086, Average Error: 0.0000000000000000, Culminative Send Cost: 3394817140\n",
      "Epoch [59/200], Average Loss: 0.00042847, Average Error: 0.0000000000000000, Culminative Send Cost: 3453348470\n",
      "Epoch [60/200], Average Loss: 0.00042609, Average Error: 0.0000000000000000, Culminative Send Cost: 3511879800\n",
      "Epoch [61/200], Average Loss: 0.00042375, Average Error: 0.0000000000000000, Culminative Send Cost: 3570411130\n",
      "Epoch [62/200], Average Loss: 0.00042143, Average Error: 0.0000000000000000, Culminative Send Cost: 3628942460\n",
      "Epoch [63/200], Average Loss: 0.00041913, Average Error: 0.0000000000000000, Culminative Send Cost: 3687473790\n",
      "Epoch [64/200], Average Loss: 0.00041686, Average Error: 0.0000000000000000, Culminative Send Cost: 3746005120\n",
      "Epoch [65/200], Average Loss: 0.00041461, Average Error: 0.0000000000000000, Culminative Send Cost: 3804536450\n",
      "Epoch [66/200], Average Loss: 0.00041238, Average Error: 0.0000000000000000, Culminative Send Cost: 3863067780\n",
      "Epoch [67/200], Average Loss: 0.00041017, Average Error: 0.0000000000000000, Culminative Send Cost: 3921599110\n",
      "Epoch [68/200], Average Loss: 0.00040800, Average Error: 0.0000000000000000, Culminative Send Cost: 3980130440\n",
      "Epoch [69/200], Average Loss: 0.00040583, Average Error: 0.0000000000000000, Culminative Send Cost: 4038661770\n",
      "Epoch [70/200], Average Loss: 0.00040369, Average Error: 0.0000000000000000, Culminative Send Cost: 4097193100\n",
      "Epoch [71/200], Average Loss: 0.00040157, Average Error: 0.0000000000000000, Culminative Send Cost: 4155724430\n",
      "Epoch [72/200], Average Loss: 0.00039948, Average Error: 0.0000000000000000, Culminative Send Cost: 4214255760\n",
      "Epoch [73/200], Average Loss: 0.00039740, Average Error: 0.0000000000000000, Culminative Send Cost: 4272787090\n",
      "Epoch [74/200], Average Loss: 0.00039534, Average Error: 0.0000000000000000, Culminative Send Cost: 4331318420\n",
      "Epoch [75/200], Average Loss: 0.00039331, Average Error: 0.0000000000000000, Culminative Send Cost: 4389849750\n",
      "Epoch [76/200], Average Loss: 0.00039129, Average Error: 0.0000000000000000, Culminative Send Cost: 4448381080\n",
      "Epoch [77/200], Average Loss: 0.00038929, Average Error: 0.0000000000000000, Culminative Send Cost: 4506912410\n",
      "Epoch [78/200], Average Loss: 0.00038731, Average Error: 0.0000000000000000, Culminative Send Cost: 4565443740\n",
      "Epoch [79/200], Average Loss: 0.00038535, Average Error: 0.0000000000000000, Culminative Send Cost: 4623975070\n",
      "Epoch [80/200], Average Loss: 0.00038341, Average Error: 0.0000000000000000, Culminative Send Cost: 4682506400\n",
      "Epoch [81/200], Average Loss: 0.00038149, Average Error: 0.0000000000000000, Culminative Send Cost: 4741037730\n",
      "Epoch [82/200], Average Loss: 0.00037959, Average Error: 0.0000000000000000, Culminative Send Cost: 4799569060\n",
      "Epoch [83/200], Average Loss: 0.00037770, Average Error: 0.0000000000000000, Culminative Send Cost: 4858100390\n",
      "Epoch [84/200], Average Loss: 0.00037583, Average Error: 0.0000000000000000, Culminative Send Cost: 4916631720\n",
      "Epoch [85/200], Average Loss: 0.00037398, Average Error: 0.0000000000000000, Culminative Send Cost: 4975163050\n",
      "Epoch [86/200], Average Loss: 0.00037215, Average Error: 0.0000000000000000, Culminative Send Cost: 5033694380\n",
      "Epoch [87/200], Average Loss: 0.00037033, Average Error: 0.0000000000000000, Culminative Send Cost: 5092225710\n",
      "Epoch [88/200], Average Loss: 0.00036853, Average Error: 0.0000000000000000, Culminative Send Cost: 5150757040\n",
      "Epoch [89/200], Average Loss: 0.00036674, Average Error: 0.0000000000000000, Culminative Send Cost: 5209288370\n",
      "Epoch [90/200], Average Loss: 0.00036497, Average Error: 0.0000000000000000, Culminative Send Cost: 5267819700\n",
      "Epoch [91/200], Average Loss: 0.00036322, Average Error: 0.0000000000000000, Culminative Send Cost: 5326351030\n",
      "Epoch [92/200], Average Loss: 0.00036149, Average Error: 0.0000000000000000, Culminative Send Cost: 5384882360\n",
      "Epoch [93/200], Average Loss: 0.00035976, Average Error: 0.0000000000000000, Culminative Send Cost: 5443413690\n",
      "Epoch [94/200], Average Loss: 0.00035806, Average Error: 0.0000000000000000, Culminative Send Cost: 5501945020\n",
      "Epoch [95/200], Average Loss: 0.00035637, Average Error: 0.0000000000000000, Culminative Send Cost: 5560476350\n",
      "Epoch [96/200], Average Loss: 0.00035470, Average Error: 0.0000000000000000, Culminative Send Cost: 5619007680\n",
      "Epoch [97/200], Average Loss: 0.00035304, Average Error: 0.0000000000000000, Culminative Send Cost: 5677539010\n",
      "Epoch [98/200], Average Loss: 0.00035139, Average Error: 0.0000000000000000, Culminative Send Cost: 5736070340\n",
      "Epoch [99/200], Average Loss: 0.00034976, Average Error: 0.0000000000000000, Culminative Send Cost: 5794601670\n",
      "Epoch [100/200], Average Loss: 0.00034815, Average Error: 0.0000000000000000, Culminative Send Cost: 5853133000\n",
      "Epoch [101/200], Average Loss: 0.00034654, Average Error: 0.0000000000000000, Culminative Send Cost: 5911664330\n",
      "Epoch [102/200], Average Loss: 0.00034495, Average Error: 0.0000000000000000, Culminative Send Cost: 5970195660\n",
      "Epoch [103/200], Average Loss: 0.00034337, Average Error: 0.0000000000000000, Culminative Send Cost: 6028726990\n",
      "Epoch [104/200], Average Loss: 0.00034181, Average Error: 0.0000000000000000, Culminative Send Cost: 6087258320\n",
      "Epoch [105/200], Average Loss: 0.00034026, Average Error: 0.0000000000000000, Culminative Send Cost: 6145789650\n",
      "Epoch [106/200], Average Loss: 0.00033873, Average Error: 0.0000000000000000, Culminative Send Cost: 6204320980\n",
      "Epoch [107/200], Average Loss: 0.00033720, Average Error: 0.0000000000000000, Culminative Send Cost: 6262852310\n",
      "Epoch [108/200], Average Loss: 0.00033570, Average Error: 0.0000000000000000, Culminative Send Cost: 6321383640\n",
      "Epoch [109/200], Average Loss: 0.00033420, Average Error: 0.0000000000000000, Culminative Send Cost: 6379914970\n",
      "Epoch [110/200], Average Loss: 0.00033271, Average Error: 0.0000000000000000, Culminative Send Cost: 6438446300\n",
      "Epoch [111/200], Average Loss: 0.00033124, Average Error: 0.0000000000000000, Culminative Send Cost: 6496977630\n",
      "Epoch [112/200], Average Loss: 0.00032978, Average Error: 0.0000000000000000, Culminative Send Cost: 6555508960\n",
      "Epoch [113/200], Average Loss: 0.00032834, Average Error: 0.0000000000000000, Culminative Send Cost: 6614040290\n",
      "Epoch [114/200], Average Loss: 0.00032690, Average Error: 0.0000000000000000, Culminative Send Cost: 6672571620\n",
      "Epoch [115/200], Average Loss: 0.00032547, Average Error: 0.0000000000000000, Culminative Send Cost: 6731102950\n",
      "Epoch [116/200], Average Loss: 0.00032406, Average Error: 0.0000000000000000, Culminative Send Cost: 6789634280\n",
      "Epoch [117/200], Average Loss: 0.00032266, Average Error: 0.0000000000000000, Culminative Send Cost: 6848165610\n",
      "Epoch [118/200], Average Loss: 0.00032127, Average Error: 0.0000000000000000, Culminative Send Cost: 6906696940\n",
      "Epoch [119/200], Average Loss: 0.00031990, Average Error: 0.0000000000000000, Culminative Send Cost: 6965228270\n",
      "Epoch [120/200], Average Loss: 0.00031852, Average Error: 0.0000000000000000, Culminative Send Cost: 7023759600\n",
      "Epoch [121/200], Average Loss: 0.00031717, Average Error: 0.0000000000000000, Culminative Send Cost: 7082290930\n",
      "Epoch [122/200], Average Loss: 0.00031583, Average Error: 0.0000000000000000, Culminative Send Cost: 7140822260\n",
      "Epoch [123/200], Average Loss: 0.00031449, Average Error: 0.0000000000000000, Culminative Send Cost: 7199353590\n",
      "Epoch [124/200], Average Loss: 0.00031317, Average Error: 0.0000000000000000, Culminative Send Cost: 7257884920\n",
      "Epoch [125/200], Average Loss: 0.00031185, Average Error: 0.0000000000000000, Culminative Send Cost: 7316416250\n",
      "Epoch [126/200], Average Loss: 0.00031055, Average Error: 0.0000000000000000, Culminative Send Cost: 7374947580\n",
      "Epoch [127/200], Average Loss: 0.00030926, Average Error: 0.0000000000000000, Culminative Send Cost: 7433478910\n",
      "Epoch [128/200], Average Loss: 0.00030797, Average Error: 0.0000000000000000, Culminative Send Cost: 7492010240\n",
      "Epoch [129/200], Average Loss: 0.00030670, Average Error: 0.0000000000000000, Culminative Send Cost: 7550541570\n",
      "Epoch [130/200], Average Loss: 0.00030544, Average Error: 0.0000000000000000, Culminative Send Cost: 7609072900\n",
      "Epoch [131/200], Average Loss: 0.00030418, Average Error: 0.0000000000000000, Culminative Send Cost: 7667604230\n",
      "Epoch [132/200], Average Loss: 0.00030294, Average Error: 0.0000000000000000, Culminative Send Cost: 7726135560\n",
      "Epoch [133/200], Average Loss: 0.00030171, Average Error: 0.0000000000000000, Culminative Send Cost: 7784666890\n",
      "Epoch [134/200], Average Loss: 0.00030049, Average Error: 0.0000000000000000, Culminative Send Cost: 7843198220\n",
      "Epoch [135/200], Average Loss: 0.00029927, Average Error: 0.0000000000000000, Culminative Send Cost: 7901729550\n",
      "Epoch [136/200], Average Loss: 0.00029807, Average Error: 0.0000000000000000, Culminative Send Cost: 7960260880\n",
      "Epoch [137/200], Average Loss: 0.00029687, Average Error: 0.0000000000000000, Culminative Send Cost: 8018792210\n",
      "Epoch [138/200], Average Loss: 0.00029568, Average Error: 0.0000000000000000, Culminative Send Cost: 8077323540\n",
      "Epoch [139/200], Average Loss: 0.00029450, Average Error: 0.0000000000000000, Culminative Send Cost: 8135854870\n",
      "Epoch [140/200], Average Loss: 0.00029334, Average Error: 0.0000000000000000, Culminative Send Cost: 8194386200\n",
      "Epoch [141/200], Average Loss: 0.00029217, Average Error: 0.0000000000000000, Culminative Send Cost: 8252917530\n",
      "Epoch [142/200], Average Loss: 0.00029102, Average Error: 0.0000000000000000, Culminative Send Cost: 8311448860\n",
      "Epoch [143/200], Average Loss: 0.00028988, Average Error: 0.0000000000000000, Culminative Send Cost: 8369980190\n",
      "Epoch [144/200], Average Loss: 0.00028874, Average Error: 0.0000000000000000, Culminative Send Cost: 8428511520\n",
      "Epoch [145/200], Average Loss: 0.00028761, Average Error: 0.0000000000000000, Culminative Send Cost: 8487042850\n",
      "Epoch [146/200], Average Loss: 0.00028650, Average Error: 0.0000000000000000, Culminative Send Cost: 8545574180\n",
      "Epoch [147/200], Average Loss: 0.00028538, Average Error: 0.0000000000000000, Culminative Send Cost: 8604105510\n",
      "Epoch [148/200], Average Loss: 0.00028428, Average Error: 0.0000000000000000, Culminative Send Cost: 8662636840\n",
      "Epoch [149/200], Average Loss: 0.00028318, Average Error: 0.0000000000000000, Culminative Send Cost: 8721168170\n",
      "Epoch [150/200], Average Loss: 0.00028210, Average Error: 0.0000000000000000, Culminative Send Cost: 8779699500\n",
      "Epoch [151/200], Average Loss: 0.00028102, Average Error: 0.0000000000000000, Culminative Send Cost: 8838230830\n",
      "Epoch [152/200], Average Loss: 0.00027995, Average Error: 0.0000000000000000, Culminative Send Cost: 8896762160\n",
      "Epoch [153/200], Average Loss: 0.00027889, Average Error: 0.0000000000000000, Culminative Send Cost: 8955293490\n",
      "Epoch [154/200], Average Loss: 0.00027782, Average Error: 0.0000000000000000, Culminative Send Cost: 9013824820\n",
      "Epoch [155/200], Average Loss: 0.00027678, Average Error: 0.0000000000000000, Culminative Send Cost: 9072356150\n",
      "Epoch [156/200], Average Loss: 0.00027574, Average Error: 0.0000000000000000, Culminative Send Cost: 9130887480\n",
      "Epoch [157/200], Average Loss: 0.00027470, Average Error: 0.0000000000000000, Culminative Send Cost: 9189418810\n",
      "Epoch [158/200], Average Loss: 0.00027368, Average Error: 0.0000000000000000, Culminative Send Cost: 9247950140\n",
      "Epoch [159/200], Average Loss: 0.00027265, Average Error: 0.0000000000000000, Culminative Send Cost: 9306481470\n",
      "Epoch [160/200], Average Loss: 0.00027164, Average Error: 0.0000000000000000, Culminative Send Cost: 9365012800\n",
      "Epoch [161/200], Average Loss: 0.00027064, Average Error: 0.0000000000000000, Culminative Send Cost: 9423544130\n",
      "Epoch [162/200], Average Loss: 0.00026964, Average Error: 0.0000000000000000, Culminative Send Cost: 9482075460\n",
      "Epoch [163/200], Average Loss: 0.00026865, Average Error: 0.0000000000000000, Culminative Send Cost: 9540606790\n",
      "Epoch [164/200], Average Loss: 0.00026767, Average Error: 0.0000000000000000, Culminative Send Cost: 9599138120\n",
      "Epoch [165/200], Average Loss: 0.00026669, Average Error: 0.0000000000000000, Culminative Send Cost: 9657669450\n",
      "Epoch [166/200], Average Loss: 0.00026571, Average Error: 0.0000000000000000, Culminative Send Cost: 9716200780\n",
      "Epoch [167/200], Average Loss: 0.00026475, Average Error: 0.0000000000000000, Culminative Send Cost: 9774732110\n",
      "Epoch [168/200], Average Loss: 0.00026379, Average Error: 0.0000000000000000, Culminative Send Cost: 9833263440\n",
      "Epoch [169/200], Average Loss: 0.00026285, Average Error: 0.0000000000000000, Culminative Send Cost: 9891794770\n",
      "Epoch [170/200], Average Loss: 0.00026190, Average Error: 0.0000000000000000, Culminative Send Cost: 9950326100\n",
      "Epoch [171/200], Average Loss: 0.00026097, Average Error: 0.0000000000000000, Culminative Send Cost: 10008857430\n",
      "Epoch [172/200], Average Loss: 0.00026004, Average Error: 0.0000000000000000, Culminative Send Cost: 10067388760\n",
      "Epoch [173/200], Average Loss: 0.00025911, Average Error: 0.0000000000000000, Culminative Send Cost: 10125920090\n",
      "Epoch [174/200], Average Loss: 0.00025819, Average Error: 0.0000000000000000, Culminative Send Cost: 10184451420\n",
      "Epoch [175/200], Average Loss: 0.00025728, Average Error: 0.0000000000000000, Culminative Send Cost: 10242982750\n",
      "Epoch [176/200], Average Loss: 0.00025637, Average Error: 0.0000000000000000, Culminative Send Cost: 10301514080\n",
      "Epoch [177/200], Average Loss: 0.00025546, Average Error: 0.0000000000000000, Culminative Send Cost: 10360045410\n",
      "Epoch [178/200], Average Loss: 0.00025457, Average Error: 0.0000000000000000, Culminative Send Cost: 10418576740\n",
      "Epoch [179/200], Average Loss: 0.00025367, Average Error: 0.0000000000000000, Culminative Send Cost: 10477108070\n",
      "Epoch [180/200], Average Loss: 0.00025280, Average Error: 0.0000000000000000, Culminative Send Cost: 10535639400\n",
      "Epoch [181/200], Average Loss: 0.00025192, Average Error: 0.0000000000000000, Culminative Send Cost: 10594170730\n",
      "Epoch [182/200], Average Loss: 0.00025105, Average Error: 0.0000000000000000, Culminative Send Cost: 10652702060\n",
      "Epoch [183/200], Average Loss: 0.00025018, Average Error: 0.0000000000000000, Culminative Send Cost: 10711233390\n",
      "Epoch [184/200], Average Loss: 0.00024931, Average Error: 0.0000000000000000, Culminative Send Cost: 10769764720\n",
      "Epoch [185/200], Average Loss: 0.00024846, Average Error: 0.0000000000000000, Culminative Send Cost: 10828296050\n",
      "Epoch [186/200], Average Loss: 0.00024761, Average Error: 0.0000000000000000, Culminative Send Cost: 10886827380\n",
      "Epoch [187/200], Average Loss: 0.00024677, Average Error: 0.0000000000000000, Culminative Send Cost: 10945358710\n",
      "Epoch [188/200], Average Loss: 0.00024593, Average Error: 0.0000000000000000, Culminative Send Cost: 11003890040\n",
      "Epoch [189/200], Average Loss: 0.00024509, Average Error: 0.0000000000000000, Culminative Send Cost: 11062421370\n",
      "Epoch [190/200], Average Loss: 0.00024427, Average Error: 0.0000000000000000, Culminative Send Cost: 11120952700\n",
      "Epoch [191/200], Average Loss: 0.00024344, Average Error: 0.0000000000000000, Culminative Send Cost: 11179484030\n",
      "Epoch [192/200], Average Loss: 0.00024262, Average Error: 0.0000000000000000, Culminative Send Cost: 11238015360\n",
      "Epoch [193/200], Average Loss: 0.00024181, Average Error: 0.0000000000000000, Culminative Send Cost: 11296546690\n",
      "Epoch [194/200], Average Loss: 0.00024100, Average Error: 0.0000000000000000, Culminative Send Cost: 11355078020\n",
      "Epoch [195/200], Average Loss: 0.00024020, Average Error: 0.0000000000000000, Culminative Send Cost: 11413609350\n",
      "Epoch [196/200], Average Loss: 0.00023941, Average Error: 0.0000000000000000, Culminative Send Cost: 11472140680\n",
      "Epoch [197/200], Average Loss: 0.00023861, Average Error: 0.0000000000000000, Culminative Send Cost: 11530672010\n",
      "Epoch [198/200], Average Loss: 0.00023783, Average Error: 0.0000000000000000, Culminative Send Cost: 11589203340\n",
      "Epoch [199/200], Average Loss: 0.00023704, Average Error: 0.0000000000000000, Culminative Send Cost: 11647734670\n",
      "Epoch [200/200], Average Loss: 0.00023627, Average Error: 0.0000000000000000, Culminative Send Cost: 11706266000\n",
      "Time for all iteration:  1489.2163461999999\n",
      "activation_stack.0.weight: tensor([[[[-4.8519e-02, -7.5044e-02,  4.0868e-02],\n",
      "          [ 1.7880e-01,  5.3798e-02, -5.8583e-02],\n",
      "          [-3.5968e-02, -1.6397e-01, -4.5745e-02]],\n",
      "\n",
      "         [[ 4.8675e-02,  1.3284e-01,  6.8101e-02],\n",
      "          [ 1.8255e-01,  1.3198e-01, -1.4425e-01],\n",
      "          [-1.0217e-01, -1.7948e-01, -4.2477e-02]],\n",
      "\n",
      "         [[-9.4931e-02,  1.5114e-01,  9.6745e-02],\n",
      "          [-5.7167e-02, -1.3660e-01, -1.2618e-01],\n",
      "          [ 1.4180e-01,  1.1037e-01,  1.7112e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3285e-02, -7.2027e-02,  1.4796e-01],\n",
      "          [-2.5510e-02,  1.6812e-01,  2.3874e-02],\n",
      "          [-1.2526e-02,  6.0707e-02, -1.5332e-01]],\n",
      "\n",
      "         [[-1.3892e-01, -6.6288e-02,  1.1017e-01],\n",
      "          [ 1.8468e-01,  9.4627e-02,  8.0501e-02],\n",
      "          [ 1.6934e-01,  1.1254e-01, -9.9559e-02]],\n",
      "\n",
      "         [[-1.6528e-01,  1.2044e-01,  5.6739e-02],\n",
      "          [-2.1243e-01,  1.5102e-01, -2.1121e-01],\n",
      "          [-6.3207e-02, -2.3327e-01, -7.6295e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1453e-02, -1.1598e-01, -6.6526e-02],\n",
      "          [ 1.8364e-01, -8.6730e-02, -6.2666e-02],\n",
      "          [ 1.1901e-02,  6.2341e-02,  1.7143e-01]],\n",
      "\n",
      "         [[ 1.6014e-01,  1.4231e-01,  1.2472e-01],\n",
      "          [-1.6156e-02, -1.3273e-01, -1.0953e-01],\n",
      "          [-9.4593e-02, -3.2287e-02,  7.9109e-03]],\n",
      "\n",
      "         [[-5.1427e-02,  1.6884e-01,  1.1552e-01],\n",
      "          [-1.8274e-01, -1.7200e-02, -8.9649e-02],\n",
      "          [-1.9063e-01,  8.0274e-02,  1.6621e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.4936e-02,  2.3655e-03, -8.0020e-02],\n",
      "          [ 9.8706e-03,  1.3430e-01,  2.3295e-01],\n",
      "          [-1.2424e-01, -4.3166e-02, -3.0090e-02]],\n",
      "\n",
      "         [[-8.1528e-02,  8.0443e-02, -6.0925e-02],\n",
      "          [-4.2881e-02, -3.4209e-02,  1.2585e-01],\n",
      "          [ 9.1460e-02, -1.7723e-01,  1.7860e-01]],\n",
      "\n",
      "         [[-5.9593e-02, -9.1662e-02,  6.2061e-02],\n",
      "          [ 9.2865e-02,  1.5589e-01,  9.2291e-02],\n",
      "          [-2.6642e-02, -1.5869e-01,  1.5673e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9713e-01, -4.9550e-02, -1.5639e-02],\n",
      "          [ 1.8687e-01, -8.6319e-02,  2.0358e-02],\n",
      "          [-1.9000e-01, -1.4935e-02,  2.0321e-01]],\n",
      "\n",
      "         [[ 4.7482e-02,  2.0207e-01, -5.9913e-02],\n",
      "          [ 8.3242e-02, -9.4048e-02, -6.8855e-03],\n",
      "          [ 4.2465e-02, -7.0694e-02,  1.0141e-01]],\n",
      "\n",
      "         [[-1.6488e-01, -6.9544e-02, -6.9444e-03],\n",
      "          [-3.1376e-02, -5.7617e-02,  5.2370e-02],\n",
      "          [ 1.6772e-01, -8.9156e-02, -1.6664e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.9153e-02,  1.0927e-01,  1.9071e-02],\n",
      "          [ 1.3322e-01,  2.2872e-02,  3.1350e-02],\n",
      "          [ 1.4774e-01, -5.2150e-03,  1.3659e-01]],\n",
      "\n",
      "         [[ 1.2481e-01,  1.5706e-01, -1.8574e-01],\n",
      "          [-9.4345e-02,  6.6770e-03,  1.2478e-01],\n",
      "          [-1.0797e-01, -1.6263e-01,  1.5019e-01]],\n",
      "\n",
      "         [[-2.1259e-01,  6.7012e-02, -1.0195e-02],\n",
      "          [-2.2035e-01, -2.2485e-01,  4.2077e-02],\n",
      "          [-2.0469e-01,  1.5230e-03, -8.3163e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.9596e-02, -1.3159e-02,  5.0515e-02],\n",
      "          [-1.9980e-01, -2.0027e-01,  1.8219e-01],\n",
      "          [-4.5032e-02,  1.9848e-01, -7.5836e-02]],\n",
      "\n",
      "         [[ 4.9524e-02,  1.5607e-02,  1.9989e-01],\n",
      "          [-1.4403e-01, -5.1750e-03,  1.7550e-01],\n",
      "          [-1.2073e-01,  1.5988e-01,  1.7366e-01]],\n",
      "\n",
      "         [[-1.9736e-01,  1.8316e-01, -1.6620e-01],\n",
      "          [-1.6550e-01, -1.1418e-01,  1.0093e-01],\n",
      "          [-1.4753e-02,  1.7442e-01, -1.1085e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0964e-01,  4.1774e-02, -1.2867e-01],\n",
      "          [-1.5074e-01, -4.8152e-02,  1.4627e-01],\n",
      "          [-1.7756e-01, -1.6729e-01,  1.6730e-01]],\n",
      "\n",
      "         [[-1.1485e-02, -1.4722e-02,  7.5518e-03],\n",
      "          [ 2.6659e-02, -7.3003e-02,  1.0410e-01],\n",
      "          [-1.3045e-01, -1.7081e-01,  1.3733e-01]],\n",
      "\n",
      "         [[-2.8344e-02, -8.6982e-03, -1.0722e-01],\n",
      "          [-1.4165e-01, -1.4740e-01,  1.7584e-01],\n",
      "          [ 1.3700e-01,  4.0864e-03,  1.8940e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0192e-02,  1.3078e-01, -1.2777e-01],\n",
      "          [-2.1404e-01, -1.2945e-01, -6.7656e-02],\n",
      "          [ 4.8201e-02,  8.0628e-03,  8.8117e-02]],\n",
      "\n",
      "         [[ 9.8525e-02,  4.7664e-02,  7.3392e-02],\n",
      "          [ 2.9410e-02, -1.4599e-01, -2.0556e-01],\n",
      "          [ 1.1463e-01,  8.4393e-02, -1.3533e-01]],\n",
      "\n",
      "         [[ 1.5217e-01,  1.3441e-01,  1.7854e-01],\n",
      "          [ 2.5145e-02,  1.1041e-01,  1.1713e-01],\n",
      "          [-1.3683e-01, -1.1618e-01,  2.8423e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3313e-02, -2.1100e-01, -1.0548e-01],\n",
      "          [ 3.3087e-02, -5.9741e-02,  1.5387e-02],\n",
      "          [ 1.6444e-02,  9.6735e-02, -2.7706e-02]],\n",
      "\n",
      "         [[-2.8812e-02,  1.0868e-03,  7.0972e-02],\n",
      "          [ 1.3241e-01,  4.7455e-02,  2.5610e-02],\n",
      "          [-1.2377e-01,  2.0246e-01,  1.6965e-01]],\n",
      "\n",
      "         [[-1.1103e-01,  1.7811e-02, -2.1178e-02],\n",
      "          [ 6.7512e-02, -1.1201e-01, -2.0090e-01],\n",
      "          [ 1.4730e-01,  7.5072e-02,  1.8054e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8397e-02, -8.3276e-03,  3.7777e-02],\n",
      "          [ 2.1214e-01,  2.2088e-02, -2.0850e-02],\n",
      "          [-1.9267e-01, -2.0122e-01,  1.3993e-01]],\n",
      "\n",
      "         [[-1.4986e-01,  1.4092e-01,  1.3571e-01],\n",
      "          [-4.3513e-02,  1.2037e-01,  3.2881e-02],\n",
      "          [ 1.0102e-01,  6.7111e-02,  1.3417e-01]],\n",
      "\n",
      "         [[-1.5763e-01, -1.7821e-01,  2.2608e-04],\n",
      "          [ 1.9685e-01,  1.4019e-01, -6.5342e-02],\n",
      "          [-8.9226e-02,  1.4011e-01, -1.7685e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8567e-01,  5.6246e-02,  1.8380e-01],\n",
      "          [ 5.2724e-02, -1.3980e-01, -2.0251e-01],\n",
      "          [ 6.6634e-02,  2.3121e-01, -3.2346e-02]],\n",
      "\n",
      "         [[-6.2460e-02,  1.4961e-01,  2.0093e-01],\n",
      "          [ 1.2164e-01, -1.9558e-01,  1.5093e-01],\n",
      "          [ 1.7644e-01,  6.0365e-03,  1.3150e-01]],\n",
      "\n",
      "         [[ 5.1547e-02, -8.3946e-02, -9.3848e-02],\n",
      "          [-3.5938e-02,  7.5833e-02, -4.0470e-02],\n",
      "          [-2.2361e-01,  1.2802e-01, -6.7266e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8382e-03,  4.3322e-03, -5.2761e-02],\n",
      "          [-1.5984e-01,  1.3544e-01,  3.3981e-02],\n",
      "          [-2.4518e-02, -8.9599e-02,  1.2364e-01]],\n",
      "\n",
      "         [[ 6.4535e-02, -3.9304e-02, -2.1724e-02],\n",
      "          [-8.7093e-03,  1.7772e-01,  9.2332e-02],\n",
      "          [-4.8123e-02,  4.1636e-02, -1.5694e-02]],\n",
      "\n",
      "         [[-1.4674e-01, -8.5794e-02,  1.5373e-01],\n",
      "          [ 8.5805e-02, -1.9368e-01, -1.2385e-01],\n",
      "          [ 3.6392e-02, -1.3180e-02,  1.8499e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8329e-02, -1.8941e-01,  6.4503e-02],\n",
      "          [-6.4748e-02,  1.0467e-01, -1.1340e-01],\n",
      "          [ 3.2889e-02, -4.6879e-03,  7.5201e-02]],\n",
      "\n",
      "         [[-4.7729e-02,  9.1315e-02,  3.5467e-02],\n",
      "          [-1.0303e-01,  1.2974e-01,  1.8243e-01],\n",
      "          [ 3.3568e-02,  1.2447e-01, -4.9828e-02]],\n",
      "\n",
      "         [[-5.3719e-02,  3.0691e-02, -4.3619e-02],\n",
      "          [-1.9758e-01,  3.8697e-02,  1.3769e-01],\n",
      "          [-1.9276e-01,  8.0250e-02, -8.2516e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7190e-03,  1.1710e-01, -1.1840e-01],\n",
      "          [-1.8644e-01, -4.9254e-02,  9.9221e-02],\n",
      "          [ 1.1168e-01, -5.2326e-02,  1.5242e-01]],\n",
      "\n",
      "         [[ 9.4412e-02, -1.9082e-02, -7.4302e-02],\n",
      "          [-9.3910e-02,  2.2902e-01,  1.3310e-03],\n",
      "          [-2.4438e-01, -4.2036e-02, -1.6735e-01]],\n",
      "\n",
      "         [[ 1.8367e-01, -1.0043e-03,  8.3296e-02],\n",
      "          [-2.6735e-02, -1.7390e-01, -4.3533e-02],\n",
      "          [-3.2547e-02,  7.1313e-02,  1.5462e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8526e-01,  1.0995e-01,  4.4253e-02],\n",
      "          [ 3.6378e-02,  1.1688e-02, -1.6777e-01],\n",
      "          [-7.5489e-02, -9.3038e-02, -4.0992e-02]],\n",
      "\n",
      "         [[-1.6800e-01,  8.0461e-02, -1.1342e-01],\n",
      "          [-7.7270e-02, -4.8996e-02,  1.9774e-01],\n",
      "          [ 2.0891e-01, -1.2721e-01, -1.2105e-01]],\n",
      "\n",
      "         [[ 8.6677e-02,  1.3414e-01, -1.1424e-01],\n",
      "          [ 1.1131e-01,  1.4987e-01, -9.3779e-02],\n",
      "          [-1.6451e-01,  4.9295e-02, -2.0254e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.3556e-02,  1.4521e-01,  8.3749e-02],\n",
      "          [ 4.4767e-02,  1.2579e-01, -9.0378e-02],\n",
      "          [-1.9604e-01,  3.9055e-03, -8.2818e-02]],\n",
      "\n",
      "         [[-1.2152e-01, -4.7002e-03, -5.8242e-02],\n",
      "          [-1.5083e-01, -1.0116e-01,  6.0111e-02],\n",
      "          [ 2.8851e-02,  1.4516e-01,  1.9236e-03]],\n",
      "\n",
      "         [[-1.7838e-02, -1.6822e-01,  1.5011e-01],\n",
      "          [-1.2133e-01,  8.8307e-02, -1.6214e-01],\n",
      "          [-1.5683e-02,  7.0801e-02,  5.0678e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5219e-01,  1.0611e-02, -1.1393e-01],\n",
      "          [-2.2706e-02,  1.9046e-02,  1.4874e-01],\n",
      "          [ 1.8959e-01,  1.5954e-01,  1.1256e-01]],\n",
      "\n",
      "         [[-5.7278e-02,  9.9418e-02, -1.0928e-03],\n",
      "          [ 4.1691e-02,  6.8552e-02,  1.8039e-01],\n",
      "          [-1.6116e-01, -7.8222e-02, -1.6623e-01]],\n",
      "\n",
      "         [[ 4.1348e-02,  1.1469e-01,  4.1455e-02],\n",
      "          [-1.0738e-01,  1.0924e-01, -5.7048e-02],\n",
      "          [ 5.9074e-02, -1.8559e-01, -1.5815e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8032e-01, -3.2832e-02, -3.6801e-02],\n",
      "          [ 1.3858e-02, -1.0678e-01, -9.9437e-02],\n",
      "          [-5.1631e-02,  1.0592e-01,  1.0578e-01]],\n",
      "\n",
      "         [[-9.7676e-02,  2.3012e-02,  1.8032e-02],\n",
      "          [-1.2738e-01, -1.6618e-01,  9.5346e-02],\n",
      "          [ 8.1607e-02, -3.9053e-02, -1.7256e-01]],\n",
      "\n",
      "         [[ 5.4199e-02, -1.7778e-01, -6.6683e-02],\n",
      "          [-8.9740e-02, -1.0244e-01, -7.0221e-02],\n",
      "          [ 1.0375e-02, -5.7484e-02,  4.0363e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0777e-02, -7.0833e-02,  3.4652e-02],\n",
      "          [ 6.7140e-02, -9.9429e-02,  1.0235e-01],\n",
      "          [ 1.2562e-01,  3.2554e-02, -9.7739e-02]],\n",
      "\n",
      "         [[-8.5061e-02,  1.0517e-01, -4.1121e-04],\n",
      "          [-1.8862e-01,  7.3292e-02, -2.2019e-01],\n",
      "          [-1.1390e-01,  5.5215e-02, -5.6175e-02]],\n",
      "\n",
      "         [[-6.2309e-02,  1.4274e-01, -2.0453e-01],\n",
      "          [-1.0191e-01, -6.8846e-03,  3.6082e-02],\n",
      "          [ 6.0587e-02,  1.0126e-01,  9.5211e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3765e-01,  1.1734e-02,  1.9434e-01],\n",
      "          [-1.2220e-01,  4.3390e-02,  8.8509e-02],\n",
      "          [ 4.6933e-02,  5.4677e-02, -1.8780e-01]],\n",
      "\n",
      "         [[-1.6590e-02, -1.5039e-01,  1.0022e-01],\n",
      "          [-1.1021e-01, -1.1098e-01, -6.4230e-02],\n",
      "          [-3.9888e-02, -8.5901e-02,  1.2552e-01]],\n",
      "\n",
      "         [[-8.3017e-02,  3.7543e-02, -3.3636e-02],\n",
      "          [-7.7386e-02,  1.8809e-01,  1.3888e-01],\n",
      "          [-1.8281e-01, -3.0677e-02,  1.2654e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2512e-02, -1.0280e-01, -1.5671e-01],\n",
      "          [-4.3998e-02,  5.0384e-02, -1.4333e-01],\n",
      "          [-1.3728e-02,  1.3306e-01, -4.0298e-02]],\n",
      "\n",
      "         [[ 1.0454e-01,  1.7766e-02, -1.7503e-01],\n",
      "          [-8.5729e-03, -1.4943e-01, -1.0127e-01],\n",
      "          [-1.7330e-02, -6.5981e-03,  2.5030e-02]],\n",
      "\n",
      "         [[-1.8482e-02, -1.7806e-01,  1.2437e-01],\n",
      "          [ 1.4311e-02, -1.4493e-01,  3.7300e-02],\n",
      "          [-5.1464e-02, -1.0042e-01, -1.4087e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6884e-02,  8.8016e-02,  8.4309e-02],\n",
      "          [ 1.3758e-01,  1.3518e-02, -1.0404e-01],\n",
      "          [-1.1647e-01, -1.1985e-01,  9.2526e-02]],\n",
      "\n",
      "         [[-1.7760e-01, -1.5555e-01, -1.2937e-01],\n",
      "          [ 1.4055e-01, -3.8948e-02,  1.1620e-01],\n",
      "          [ 1.8588e-02, -1.6515e-01,  6.4466e-02]],\n",
      "\n",
      "         [[ 1.9780e-03, -9.8972e-02,  1.2156e-01],\n",
      "          [ 1.1110e-01,  1.1908e-01, -2.0591e-01],\n",
      "          [ 1.1195e-01,  1.4026e-01,  8.8188e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8046e-02,  5.0062e-03, -4.6298e-02],\n",
      "          [ 8.6511e-02,  4.7921e-02, -1.2601e-01],\n",
      "          [-2.0007e-01, -1.3778e-01,  1.1388e-01]],\n",
      "\n",
      "         [[ 2.1313e-01, -5.0229e-02,  3.4763e-04],\n",
      "          [-2.0382e-02,  1.8553e-01, -1.7686e-01],\n",
      "          [-2.1523e-01,  5.2457e-02,  1.9793e-01]],\n",
      "\n",
      "         [[ 1.6414e-01,  1.5360e-01,  9.8747e-02],\n",
      "          [-6.2791e-02, -2.5051e-01, -6.3010e-03],\n",
      "          [ 6.8513e-02, -1.3627e-01,  1.4926e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9833e-02, -2.0558e-01,  4.5030e-02],\n",
      "          [-1.7707e-02, -1.3144e-01,  6.6530e-03],\n",
      "          [ 5.5581e-02,  2.2837e-01,  6.4645e-02]],\n",
      "\n",
      "         [[-9.2560e-02, -1.4462e-01, -9.2204e-02],\n",
      "          [ 1.7426e-01, -1.3760e-01,  2.5864e-03],\n",
      "          [ 8.6943e-02, -1.8973e-01, -8.7930e-02]],\n",
      "\n",
      "         [[-4.9682e-02, -1.4131e-01, -1.9237e-01],\n",
      "          [ 4.2592e-02,  5.8439e-02,  1.0276e-01],\n",
      "          [ 1.5881e-01,  1.9377e-01,  4.9665e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0043e-01,  1.1402e-01, -2.2825e-01],\n",
      "          [ 5.1244e-02, -7.1192e-02,  1.0167e-01],\n",
      "          [ 1.7907e-01, -4.8605e-02,  7.8879e-02]],\n",
      "\n",
      "         [[ 1.0613e-01,  6.2656e-03, -1.4331e-01],\n",
      "          [-2.8106e-02,  2.1262e-02, -1.3117e-01],\n",
      "          [-4.3465e-02,  9.0458e-02,  1.9324e-01]],\n",
      "\n",
      "         [[ 1.6656e-01,  8.9991e-02,  1.3963e-01],\n",
      "          [-1.6327e-02, -1.7347e-01,  9.5232e-02],\n",
      "          [ 6.8740e-02, -2.5883e-02, -1.9049e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0815e-02, -8.3375e-02, -1.6495e-01],\n",
      "          [ 1.8527e-02,  1.5484e-01,  1.0574e-01],\n",
      "          [ 6.2869e-02,  2.2372e-02, -1.5562e-01]],\n",
      "\n",
      "         [[ 1.9940e-01,  1.8655e-01, -1.0063e-01],\n",
      "          [-1.0760e-01, -3.6132e-03,  1.0822e-01],\n",
      "          [-6.8693e-02,  1.2556e-02, -1.1614e-01]],\n",
      "\n",
      "         [[ 2.6303e-02,  7.1479e-02, -1.2494e-02],\n",
      "          [-1.8587e-01,  1.2250e-01,  1.2893e-01],\n",
      "          [-1.0518e-01, -3.5101e-03, -2.0799e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7304e-01, -1.9032e-02,  3.8797e-02],\n",
      "          [ 7.7804e-02,  9.3118e-02, -1.2020e-02],\n",
      "          [-4.4828e-02, -3.9045e-02, -4.8650e-02]],\n",
      "\n",
      "         [[-1.5369e-01,  1.3195e-01, -1.5822e-01],\n",
      "          [ 1.2654e-01, -7.6315e-02, -6.2629e-03],\n",
      "          [-1.5242e-01, -1.7421e-01, -3.5203e-02]],\n",
      "\n",
      "         [[ 9.7935e-02, -1.5842e-02,  5.5817e-03],\n",
      "          [-1.3602e-01,  2.9261e-02,  8.4687e-02],\n",
      "          [ 5.7053e-02, -9.3856e-02, -3.1463e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8818e-02,  7.1754e-02,  7.0496e-02],\n",
      "          [ 1.5339e-01,  1.0331e-01,  1.7253e-01],\n",
      "          [-1.4307e-01, -1.1288e-01, -7.7940e-02]],\n",
      "\n",
      "         [[ 7.1285e-02, -9.6523e-02,  1.0524e-01],\n",
      "          [ 1.5488e-01, -1.6284e-01,  1.2616e-01],\n",
      "          [-1.1828e-01, -1.4532e-01,  4.1559e-02]],\n",
      "\n",
      "         [[-2.1273e-01,  6.9115e-02, -1.0645e-01],\n",
      "          [-9.4664e-03, -2.2006e-01,  5.2810e-02],\n",
      "          [ 1.5835e-01,  2.2607e-01,  1.4827e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9280e-02, -1.1658e-01, -8.0286e-02],\n",
      "          [-1.6921e-01,  2.7510e-02, -8.0077e-02],\n",
      "          [-2.2504e-02,  5.3371e-02,  8.3103e-02]],\n",
      "\n",
      "         [[ 3.5195e-02,  1.9111e-01, -3.6908e-02],\n",
      "          [ 2.0197e-01, -2.5688e-02,  1.0952e-01],\n",
      "          [-2.6467e-02, -3.7898e-02,  6.5707e-02]],\n",
      "\n",
      "         [[-1.4121e-01,  1.2115e-01, -1.3432e-01],\n",
      "          [ 7.8674e-02, -2.0223e-02, -5.3167e-03],\n",
      "          [ 1.0798e-01, -4.3187e-02,  5.2844e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5849e-02,  1.3737e-02,  1.5060e-01],\n",
      "          [ 1.9381e-01,  9.1841e-02,  1.5556e-01],\n",
      "          [-7.1559e-02, -1.1315e-01, -4.4173e-02]],\n",
      "\n",
      "         [[-1.6817e-01, -1.5899e-01,  8.5475e-02],\n",
      "          [-5.8597e-02,  2.0885e-01,  1.7572e-01],\n",
      "          [-5.9650e-02, -1.4852e-01, -1.7648e-01]],\n",
      "\n",
      "         [[-1.5709e-01, -1.7616e-01, -2.0853e-01],\n",
      "          [ 5.1911e-03,  1.2720e-01,  7.5535e-03],\n",
      "          [-1.5341e-01, -1.5044e-01, -9.2669e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4840e-02,  9.9775e-02, -1.5152e-02],\n",
      "          [-1.4030e-02,  1.7332e-02,  6.6669e-02],\n",
      "          [-6.5590e-02, -1.4406e-01,  1.2278e-01]],\n",
      "\n",
      "         [[-2.9578e-02, -2.2312e-02, -1.0652e-01],\n",
      "          [ 1.9631e-01, -4.9486e-02,  1.6852e-01],\n",
      "          [-1.6847e-01,  2.0143e-01,  1.2080e-01]],\n",
      "\n",
      "         [[-3.5543e-02,  2.7005e-02,  1.9449e-01],\n",
      "          [ 1.2881e-01,  6.2073e-02, -1.4872e-01],\n",
      "          [-1.7454e-01,  1.5596e-01, -1.2270e-01]]]])\n",
      "activation_stack.0.bias: tensor([ 0.1262, -0.1479,  0.0699, -0.0465,  0.1461, -0.1989,  0.1421,  0.0295,\n",
      "         0.0877, -0.0433, -0.0219, -0.1874,  0.0621,  0.0306,  0.1535,  0.1286,\n",
      "         0.0736,  0.1365, -0.1538, -0.2246,  0.0461,  0.1570,  0.0692,  0.1057,\n",
      "         0.2017,  0.0336,  0.1606,  0.0038,  0.0561, -0.1505,  0.0911, -0.1542])\n",
      "activation_stack.2.weight: tensor([[[[ 4.7028e-02, -1.3512e-02,  6.0451e-02],\n",
      "          [-4.8718e-02,  3.6850e-02, -2.3924e-02],\n",
      "          [ 3.4540e-03, -2.5923e-06,  4.5283e-02]],\n",
      "\n",
      "         [[-1.6011e-02,  3.2764e-02,  3.7872e-02],\n",
      "          [-7.8881e-03,  3.9157e-03,  3.1919e-02],\n",
      "          [-4.5339e-02,  2.7446e-02, -3.6831e-04]],\n",
      "\n",
      "         [[-6.2374e-02,  8.7282e-03, -1.7207e-02],\n",
      "          [ 2.9274e-02, -2.0520e-02,  6.5355e-02],\n",
      "          [ 1.0194e-02, -5.0368e-02,  5.1693e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5740e-02, -1.6008e-02, -3.6705e-02],\n",
      "          [ 5.5211e-03, -2.9164e-02,  6.7312e-03],\n",
      "          [-2.1706e-02, -3.5778e-02,  1.6160e-02]],\n",
      "\n",
      "         [[-5.6981e-02, -1.5282e-02, -2.8160e-02],\n",
      "          [ 4.8690e-02,  4.6871e-02,  3.9681e-02],\n",
      "          [-3.6489e-02,  1.8110e-02, -2.6594e-02]],\n",
      "\n",
      "         [[-2.4213e-02,  1.4011e-02, -2.0457e-02],\n",
      "          [-2.7608e-02, -1.9821e-02, -4.7464e-03],\n",
      "          [-4.1781e-03, -2.5344e-02,  4.0295e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6334e-02, -3.4688e-02,  6.3751e-02],\n",
      "          [ 3.3277e-02,  1.1797e-02,  3.6361e-02],\n",
      "          [ 4.3795e-02, -4.6213e-02, -4.2098e-03]],\n",
      "\n",
      "         [[ 2.2775e-02, -4.0840e-02, -7.3290e-03],\n",
      "          [ 4.3489e-03, -2.6590e-02,  6.3376e-02],\n",
      "          [ 6.2176e-02, -3.0740e-02, -5.1499e-02]],\n",
      "\n",
      "         [[ 4.4858e-02,  2.0307e-04, -3.3526e-02],\n",
      "          [-3.6883e-02,  2.7184e-02,  6.2386e-02],\n",
      "          [ 5.1025e-02,  4.2584e-02, -1.6092e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6672e-02,  3.3001e-02,  4.5354e-02],\n",
      "          [ 4.1975e-02, -3.8104e-02,  1.4790e-02],\n",
      "          [ 2.2599e-02,  1.2742e-02,  4.7374e-02]],\n",
      "\n",
      "         [[-4.6893e-02, -6.2046e-03, -3.7187e-02],\n",
      "          [-4.4012e-02,  8.0804e-03,  3.4228e-02],\n",
      "          [ 2.4064e-02,  5.0527e-02,  5.5085e-02]],\n",
      "\n",
      "         [[-3.4723e-02,  6.9605e-02,  4.2482e-02],\n",
      "          [ 6.2163e-02,  4.6183e-02,  6.0397e-02],\n",
      "          [ 1.7786e-02,  2.5673e-02,  6.7282e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.0257e-02, -5.3151e-02,  5.4370e-03],\n",
      "          [-4.2089e-02, -4.8871e-02,  2.9489e-02],\n",
      "          [ 5.8131e-03, -1.7619e-02,  2.2341e-02]],\n",
      "\n",
      "         [[-3.7491e-02, -3.1680e-02,  2.2742e-02],\n",
      "          [ 1.9573e-02,  6.3579e-02,  2.5417e-02],\n",
      "          [ 4.0865e-02, -3.4215e-02, -1.5509e-02]],\n",
      "\n",
      "         [[ 4.4993e-02, -2.9136e-02, -1.8054e-02],\n",
      "          [-1.4063e-02,  2.1446e-02,  4.4135e-02],\n",
      "          [-6.0988e-02,  3.4033e-02, -4.6434e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7413e-03, -2.1805e-02, -2.0941e-02],\n",
      "          [ 3.1959e-02, -4.0645e-02, -2.0698e-02],\n",
      "          [-1.7107e-02, -4.5843e-02, -1.6038e-02]],\n",
      "\n",
      "         [[ 7.5031e-02,  7.6505e-02,  3.0304e-02],\n",
      "          [ 8.1791e-03,  5.3339e-02,  5.8868e-02],\n",
      "          [-3.1674e-02, -8.5394e-04,  2.8182e-02]],\n",
      "\n",
      "         [[ 5.1219e-02,  4.8788e-02, -5.1646e-02],\n",
      "          [ 4.6266e-03, -2.8438e-02, -3.1416e-02],\n",
      "          [-1.5295e-02, -2.3228e-02,  2.5603e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.4125e-02, -2.9422e-02, -5.1578e-02],\n",
      "          [ 4.7778e-02,  3.6350e-02,  4.6000e-02],\n",
      "          [-5.5325e-02, -2.2756e-02, -4.5566e-02]],\n",
      "\n",
      "         [[ 2.2945e-02,  3.2024e-03, -1.0257e-02],\n",
      "          [ 1.5346e-02,  5.7578e-02,  3.6769e-02],\n",
      "          [-9.4413e-04, -1.3516e-02, -4.5351e-02]],\n",
      "\n",
      "         [[ 9.5115e-03, -3.9337e-02,  1.3826e-02],\n",
      "          [-8.5943e-04,  4.5791e-02, -6.6873e-02],\n",
      "          [-6.1317e-02, -6.0926e-02, -3.8487e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5220e-02,  1.9394e-02, -2.3448e-02],\n",
      "          [ 1.7011e-02, -2.3084e-02,  1.5573e-02],\n",
      "          [-2.5684e-02,  8.2040e-03,  5.9242e-02]],\n",
      "\n",
      "         [[-4.8291e-02, -2.2031e-02, -1.9279e-02],\n",
      "          [-4.4884e-02,  4.1013e-03,  3.3020e-02],\n",
      "          [-2.4391e-03, -5.1669e-03,  2.0014e-02]],\n",
      "\n",
      "         [[-1.1935e-03, -1.2591e-02, -3.9546e-02],\n",
      "          [-2.3015e-02,  2.1154e-02, -4.8432e-02],\n",
      "          [ 1.4298e-02,  1.3604e-02, -5.7602e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0025e-02, -8.9287e-03, -3.6677e-02],\n",
      "          [-6.4168e-02,  3.5728e-02,  4.8393e-02],\n",
      "          [-6.7961e-02, -6.5744e-02, -7.3465e-02]],\n",
      "\n",
      "         [[-5.3069e-02,  6.3781e-02,  6.4383e-02],\n",
      "          [-5.7080e-02, -4.6104e-02,  2.5775e-02],\n",
      "          [-2.2696e-02,  1.9192e-02,  6.5183e-03]],\n",
      "\n",
      "         [[-1.7613e-03, -2.3827e-02, -2.7846e-02],\n",
      "          [ 5.2877e-02,  3.7106e-02, -3.9072e-02],\n",
      "          [-1.3187e-03, -6.7934e-02, -6.3572e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1340e-02, -1.9796e-02, -5.2528e-03],\n",
      "          [ 9.4143e-03,  2.1910e-02, -3.7628e-02],\n",
      "          [-3.0351e-02, -4.4825e-03, -4.0111e-02]],\n",
      "\n",
      "         [[ 5.5031e-02,  5.7982e-02,  2.6289e-02],\n",
      "          [-5.7544e-04, -3.5361e-02,  2.4775e-02],\n",
      "          [-3.2535e-02,  7.1206e-02,  6.4121e-02]],\n",
      "\n",
      "         [[ 3.5068e-02, -2.4640e-02,  4.2594e-02],\n",
      "          [-2.4048e-02, -5.8107e-02, -2.0129e-02],\n",
      "          [-4.2129e-02, -4.5652e-03,  1.6769e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5906e-02,  3.2529e-04, -7.8703e-02],\n",
      "          [ 3.4269e-02, -9.2892e-03,  1.8455e-02],\n",
      "          [ 9.2073e-03,  2.8086e-02, -7.7313e-02]],\n",
      "\n",
      "         [[ 2.7315e-02, -8.8103e-03,  2.5821e-02],\n",
      "          [ 5.4272e-02, -2.9905e-03,  3.2258e-02],\n",
      "          [ 3.6414e-02,  5.4294e-02,  1.5462e-02]],\n",
      "\n",
      "         [[ 4.2227e-02,  3.5497e-02,  6.2430e-03],\n",
      "          [ 4.2921e-02,  4.1782e-02,  3.7121e-02],\n",
      "          [-7.0229e-03, -9.0258e-03, -3.8690e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2456e-02,  3.2028e-02, -2.6702e-02],\n",
      "          [-2.7674e-02, -3.2675e-02, -5.0342e-02],\n",
      "          [ 1.5118e-02, -2.6504e-02,  5.1627e-02]],\n",
      "\n",
      "         [[ 3.9497e-02,  4.3150e-02, -1.3389e-02],\n",
      "          [-6.1153e-02,  2.0630e-02,  2.9424e-02],\n",
      "          [ 5.4684e-02,  5.0818e-02, -3.2261e-03]],\n",
      "\n",
      "         [[ 1.7160e-02,  5.5046e-02,  1.3994e-02],\n",
      "          [-5.7898e-03,  3.6633e-02, -1.6830e-02],\n",
      "          [-2.8533e-02,  2.2743e-02, -1.7030e-02]]]])\n",
      "activation_stack.2.bias: tensor([ 0.0020,  0.0364, -0.0677, -0.0391,  0.0337,  0.0546, -0.0375,  0.0635,\n",
      "         0.0587, -0.0174,  0.0301,  0.0575, -0.0705, -0.0544,  0.0447,  0.0359,\n",
      "         0.0204,  0.0593, -0.0238,  0.0718, -0.0364,  0.0065,  0.0389, -0.0134,\n",
      "         0.0419, -0.0681, -0.0243, -0.0150,  0.0388, -0.0616, -0.0530,  0.0541,\n",
      "        -0.0044,  0.0254, -0.0452,  0.0308,  0.0667, -0.0181,  0.0132, -0.0685,\n",
      "         0.0250, -0.0070, -0.0042,  0.0013,  0.0485,  0.0161,  0.0611,  0.0127,\n",
      "         0.0454, -0.0733,  0.0354,  0.0359,  0.0526,  0.0392,  0.0044, -0.0251,\n",
      "        -0.0213,  0.0291,  0.0047, -0.0577, -0.0096, -0.0515, -0.0366, -0.0673])\n",
      "activation_stack.5.weight: tensor([1.0191, 0.9832, 0.9811, 0.9969, 0.9710, 0.9826, 0.9994, 1.0121, 1.0063,\n",
      "        1.0034, 1.0032, 1.0057, 0.9776, 0.9819, 0.9982, 1.0338, 0.9901, 1.0048,\n",
      "        0.9994, 0.9880, 0.9831, 1.0103, 0.9987, 1.0292, 1.0054, 0.9981, 1.0019,\n",
      "        1.0048, 1.0083, 0.9973, 0.9995, 1.0119, 1.0138, 0.9911, 1.0002, 1.0178,\n",
      "        1.0057, 0.9881, 1.0068, 0.9974, 1.0094, 0.9981, 1.0303, 0.9851, 1.0144,\n",
      "        0.9915, 1.0143, 0.9935, 0.9973, 1.0035, 0.9925, 1.0237, 0.9939, 1.0000,\n",
      "        0.9922, 0.9967, 0.9912, 1.0027, 0.9969, 0.9910, 1.0211, 0.9805, 0.9901,\n",
      "        0.9800])\n",
      "activation_stack.5.bias: tensor([ 2.1126e-03, -3.1074e-03,  7.4508e-03, -3.0790e-03,  3.6580e-03,\n",
      "        -1.7417e-03,  5.1405e-03,  5.9101e-03,  2.6665e-03, -1.7989e-03,\n",
      "         8.1427e-03, -3.6664e-03,  1.2591e-02, -8.7427e-03, -4.0122e-03,\n",
      "        -2.4878e-03,  1.3244e-02,  5.6703e-03,  1.6141e-02, -3.2656e-03,\n",
      "        -1.7415e-03,  6.9249e-03,  7.4083e-05,  8.3978e-03,  1.5701e-03,\n",
      "         2.3355e-03,  5.2424e-03,  9.0289e-03,  5.8652e-03,  1.3142e-04,\n",
      "         9.5927e-04,  7.2437e-03,  1.3424e-02,  5.3349e-03,  1.4565e-02,\n",
      "         6.3573e-03, -7.1480e-03,  7.7152e-03,  1.8456e-02,  1.4860e-03,\n",
      "         1.3013e-02,  4.5663e-03,  1.2968e-02,  4.1554e-03,  7.7346e-03,\n",
      "        -2.3661e-03,  7.1372e-03,  6.2814e-03,  1.6038e-03, -7.9489e-03,\n",
      "        -6.6860e-03,  2.5987e-02,  1.4965e-04,  1.0942e-02,  4.6781e-03,\n",
      "         3.8362e-03,  7.1380e-03,  9.6592e-04, -1.9124e-03, -2.0304e-03,\n",
      "         5.6575e-03,  1.0286e-03,  1.9920e-05, -2.6675e-03])\n",
      "activation_stack.6.weight: tensor([[[[ 0.0339, -0.0106,  0.0322],\n",
      "          [-0.0148, -0.0095,  0.0294],\n",
      "          [-0.0226, -0.0290, -0.0092]],\n",
      "\n",
      "         [[ 0.0110, -0.0359, -0.0182],\n",
      "          [-0.0404, -0.0273, -0.0229],\n",
      "          [ 0.0160, -0.0324,  0.0235]],\n",
      "\n",
      "         [[-0.0201, -0.0374, -0.0301],\n",
      "          [ 0.0366, -0.0274,  0.0206],\n",
      "          [ 0.0082,  0.0036,  0.0323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0322,  0.0232, -0.0409],\n",
      "          [ 0.0056,  0.0359, -0.0421],\n",
      "          [-0.0222,  0.0250, -0.0333]],\n",
      "\n",
      "         [[ 0.0128,  0.0066, -0.0176],\n",
      "          [ 0.0018,  0.0172,  0.0381],\n",
      "          [-0.0055, -0.0235, -0.0219]],\n",
      "\n",
      "         [[-0.0142, -0.0413, -0.0378],\n",
      "          [ 0.0161,  0.0209,  0.0044],\n",
      "          [ 0.0410,  0.0380, -0.0337]]],\n",
      "\n",
      "\n",
      "        [[[-0.0140, -0.0045,  0.0221],\n",
      "          [-0.0155, -0.0309,  0.0208],\n",
      "          [-0.0032,  0.0213, -0.0137]],\n",
      "\n",
      "         [[ 0.0019,  0.0289, -0.0191],\n",
      "          [ 0.0430,  0.0037,  0.0296],\n",
      "          [ 0.0295,  0.0279,  0.0326]],\n",
      "\n",
      "         [[-0.0279, -0.0134,  0.0301],\n",
      "          [ 0.0046, -0.0166,  0.0051],\n",
      "          [-0.0177,  0.0209,  0.0011]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0373,  0.0192,  0.0034],\n",
      "          [ 0.0222, -0.0200,  0.0077],\n",
      "          [-0.0027, -0.0323, -0.0288]],\n",
      "\n",
      "         [[-0.0091, -0.0137,  0.0135],\n",
      "          [ 0.0365, -0.0088, -0.0218],\n",
      "          [-0.0174,  0.0103, -0.0238]],\n",
      "\n",
      "         [[-0.0314, -0.0174,  0.0022],\n",
      "          [ 0.0169, -0.0007,  0.0382],\n",
      "          [-0.0254, -0.0383, -0.0154]]],\n",
      "\n",
      "\n",
      "        [[[-0.0161,  0.0145,  0.0204],\n",
      "          [ 0.0223, -0.0175, -0.0314],\n",
      "          [-0.0108,  0.0228, -0.0277]],\n",
      "\n",
      "         [[ 0.0053,  0.0025,  0.0448],\n",
      "          [-0.0397,  0.0161,  0.0389],\n",
      "          [ 0.0370,  0.0041,  0.0263]],\n",
      "\n",
      "         [[-0.0202, -0.0207,  0.0139],\n",
      "          [ 0.0126,  0.0351,  0.0163],\n",
      "          [-0.0223, -0.0220,  0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0274,  0.0321, -0.0289],\n",
      "          [ 0.0356,  0.0261,  0.0113],\n",
      "          [ 0.0047,  0.0390, -0.0139]],\n",
      "\n",
      "         [[-0.0202, -0.0138,  0.0050],\n",
      "          [-0.0411,  0.0236,  0.0163],\n",
      "          [-0.0358,  0.0327, -0.0291]],\n",
      "\n",
      "         [[-0.0212,  0.0377, -0.0203],\n",
      "          [-0.0029,  0.0396, -0.0288],\n",
      "          [-0.0006, -0.0202,  0.0361]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0359, -0.0142, -0.0221],\n",
      "          [ 0.0358,  0.0095,  0.0166],\n",
      "          [-0.0047,  0.0161, -0.0128]],\n",
      "\n",
      "         [[-0.0330, -0.0427,  0.0090],\n",
      "          [ 0.0211, -0.0094,  0.0190],\n",
      "          [-0.0068,  0.0184, -0.0310]],\n",
      "\n",
      "         [[ 0.0152,  0.0228,  0.0369],\n",
      "          [-0.0296,  0.0021,  0.0004],\n",
      "          [-0.0100,  0.0206,  0.0293]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0346, -0.0437,  0.0158],\n",
      "          [-0.0162, -0.0410, -0.0044],\n",
      "          [ 0.0275,  0.0226,  0.0075]],\n",
      "\n",
      "         [[-0.0042,  0.0482, -0.0131],\n",
      "          [ 0.0195, -0.0249, -0.0255],\n",
      "          [-0.0369, -0.0171, -0.0218]],\n",
      "\n",
      "         [[ 0.0157, -0.0023, -0.0069],\n",
      "          [ 0.0392,  0.0254,  0.0102],\n",
      "          [ 0.0364,  0.0133,  0.0305]]],\n",
      "\n",
      "\n",
      "        [[[-0.0085, -0.0083, -0.0138],\n",
      "          [-0.0206,  0.0112, -0.0322],\n",
      "          [ 0.0134,  0.0041, -0.0314]],\n",
      "\n",
      "         [[ 0.0318,  0.0030,  0.0201],\n",
      "          [ 0.0311,  0.0227, -0.0104],\n",
      "          [ 0.0204, -0.0297,  0.0167]],\n",
      "\n",
      "         [[ 0.0237,  0.0199,  0.0299],\n",
      "          [ 0.0228, -0.0301,  0.0132],\n",
      "          [ 0.0388,  0.0153, -0.0023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0328,  0.0301, -0.0205],\n",
      "          [ 0.0392,  0.0363,  0.0077],\n",
      "          [ 0.0268,  0.0082,  0.0140]],\n",
      "\n",
      "         [[ 0.0115, -0.0349,  0.0317],\n",
      "          [-0.0303,  0.0371,  0.0366],\n",
      "          [-0.0309, -0.0195, -0.0272]],\n",
      "\n",
      "         [[-0.0384, -0.0250, -0.0105],\n",
      "          [ 0.0127,  0.0279,  0.0360],\n",
      "          [ 0.0062,  0.0413, -0.0241]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0303,  0.0451,  0.0241],\n",
      "          [ 0.0350, -0.0271, -0.0054],\n",
      "          [-0.0286,  0.0353, -0.0322]],\n",
      "\n",
      "         [[-0.0078,  0.0148,  0.0238],\n",
      "          [-0.0225, -0.0323, -0.0075],\n",
      "          [-0.0215,  0.0046,  0.0271]],\n",
      "\n",
      "         [[ 0.0202,  0.0012,  0.0250],\n",
      "          [-0.0365,  0.0355, -0.0201],\n",
      "          [-0.0174,  0.0226, -0.0444]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0125,  0.0309, -0.0231],\n",
      "          [ 0.0137, -0.0165, -0.0313],\n",
      "          [ 0.0292,  0.0378, -0.0141]],\n",
      "\n",
      "         [[-0.0111,  0.0049, -0.0115],\n",
      "          [ 0.0005,  0.0276,  0.0280],\n",
      "          [ 0.0490, -0.0024, -0.0015]],\n",
      "\n",
      "         [[ 0.0125, -0.0289,  0.0089],\n",
      "          [-0.0032, -0.0018,  0.0121],\n",
      "          [ 0.0229,  0.0305, -0.0373]]]])\n",
      "activation_stack.6.bias: tensor([ 1.1549e-02, -3.6396e-03, -1.1514e-02, -9.5150e-03, -1.0465e-02,\n",
      "         9.8457e-03,  5.1339e-03,  4.5394e-02, -2.3891e-02, -1.0410e-02,\n",
      "         3.3521e-02, -1.7818e-02, -2.6923e-03, -1.7954e-02, -1.2734e-02,\n",
      "        -3.1951e-02, -2.4286e-02,  5.9697e-03, -3.1887e-02,  2.4421e-02,\n",
      "        -1.2534e-02, -2.2410e-02, -1.8428e-02,  2.9083e-02, -1.8065e-02,\n",
      "         3.3675e-02, -3.6084e-02,  1.4618e-02, -3.2725e-02, -3.1117e-02,\n",
      "        -1.5874e-02, -2.3982e-03, -6.3694e-03, -1.6437e-02,  9.8547e-03,\n",
      "         3.4198e-02, -1.4122e-02, -3.0884e-02, -3.2481e-02,  1.6721e-02,\n",
      "        -2.1748e-03,  2.7445e-02,  1.6054e-02,  1.2151e-02, -1.6387e-03,\n",
      "        -2.0677e-02,  5.5880e-03,  2.1725e-02, -3.0297e-02,  3.7462e-02,\n",
      "        -4.3807e-02,  2.0064e-02, -6.3122e-03, -3.8292e-02,  9.0492e-04,\n",
      "        -2.4668e-02, -8.7020e-03,  2.3739e-02, -2.6533e-02, -3.5918e-03,\n",
      "        -2.8938e-02,  5.7319e-03, -8.0136e-03, -4.2686e-03,  1.5866e-02,\n",
      "        -4.6235e-02, -1.5826e-02, -3.9303e-02, -3.0200e-02,  3.3192e-02,\n",
      "        -1.7054e-02,  2.9653e-02, -5.1411e-03,  3.8952e-02, -3.9392e-02,\n",
      "        -4.6454e-02,  2.5548e-02, -2.8858e-02, -1.5716e-03, -2.7886e-02,\n",
      "         7.6431e-04, -3.2869e-02,  1.1129e-02, -3.8081e-02, -2.9374e-02,\n",
      "         5.6233e-05, -3.9781e-03, -3.7484e-02,  3.3761e-02,  2.9906e-03,\n",
      "        -1.1267e-02, -3.8987e-02, -1.5017e-02,  3.1291e-02,  3.0423e-02,\n",
      "        -4.0898e-02, -6.0451e-03,  3.6678e-03,  2.9072e-02,  8.1407e-03,\n",
      "        -2.7671e-02, -8.5399e-03, -8.6728e-03, -1.5965e-02,  4.1436e-02,\n",
      "         2.0423e-03,  3.8623e-02, -3.8562e-03,  1.3024e-02, -4.3231e-02,\n",
      "         1.9092e-02, -1.5581e-03, -5.6180e-03, -1.7179e-02, -1.6839e-02,\n",
      "         2.5640e-02, -2.2867e-02, -4.0603e-02, -3.4089e-02,  3.1493e-02,\n",
      "         1.7367e-03, -2.3036e-02, -3.7767e-02,  3.7645e-02, -4.4516e-02,\n",
      "        -2.7751e-02, -2.4196e-02,  3.6659e-02])\n",
      "activation_stack.8.weight: tensor([[[[ 0.0105,  0.0216, -0.0205],\n",
      "          [-0.0169,  0.0233,  0.0213],\n",
      "          [-0.0081, -0.0038,  0.0284]],\n",
      "\n",
      "         [[-0.0184, -0.0249,  0.0278],\n",
      "          [-0.0084, -0.0122, -0.0191],\n",
      "          [ 0.0138, -0.0125, -0.0045]],\n",
      "\n",
      "         [[ 0.0209, -0.0180, -0.0091],\n",
      "          [-0.0257, -0.0153,  0.0268],\n",
      "          [ 0.0055,  0.0195,  0.0271]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0189,  0.0130, -0.0196],\n",
      "          [ 0.0030,  0.0088, -0.0239],\n",
      "          [-0.0215, -0.0131, -0.0197]],\n",
      "\n",
      "         [[ 0.0059, -0.0261,  0.0046],\n",
      "          [ 0.0124,  0.0007, -0.0010],\n",
      "          [ 0.0231,  0.0120, -0.0204]],\n",
      "\n",
      "         [[ 0.0266, -0.0186, -0.0165],\n",
      "          [-0.0007,  0.0298, -0.0183],\n",
      "          [-0.0252,  0.0009, -0.0020]]],\n",
      "\n",
      "\n",
      "        [[[-0.0127,  0.0048, -0.0224],\n",
      "          [-0.0306, -0.0236, -0.0163],\n",
      "          [-0.0270,  0.0184, -0.0211]],\n",
      "\n",
      "         [[ 0.0019, -0.0083,  0.0122],\n",
      "          [ 0.0292, -0.0052, -0.0176],\n",
      "          [ 0.0221, -0.0272,  0.0010]],\n",
      "\n",
      "         [[-0.0101, -0.0232,  0.0108],\n",
      "          [-0.0056,  0.0123, -0.0244],\n",
      "          [ 0.0015, -0.0149, -0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0252, -0.0159, -0.0163],\n",
      "          [ 0.0270, -0.0008, -0.0197],\n",
      "          [ 0.0217,  0.0012,  0.0123]],\n",
      "\n",
      "         [[-0.0146,  0.0198, -0.0036],\n",
      "          [ 0.0273, -0.0024, -0.0056],\n",
      "          [-0.0007, -0.0047,  0.0130]],\n",
      "\n",
      "         [[-0.0223, -0.0158,  0.0058],\n",
      "          [ 0.0257, -0.0177, -0.0080],\n",
      "          [ 0.0101, -0.0045, -0.0085]]],\n",
      "\n",
      "\n",
      "        [[[-0.0255, -0.0224,  0.0063],\n",
      "          [ 0.0192, -0.0048,  0.0053],\n",
      "          [-0.0216,  0.0058,  0.0261]],\n",
      "\n",
      "         [[-0.0021, -0.0021,  0.0054],\n",
      "          [-0.0312,  0.0161,  0.0018],\n",
      "          [ 0.0213,  0.0286,  0.0094]],\n",
      "\n",
      "         [[ 0.0093, -0.0054, -0.0233],\n",
      "          [-0.0114,  0.0241, -0.0212],\n",
      "          [ 0.0120, -0.0037,  0.0256]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0149,  0.0048, -0.0264],\n",
      "          [-0.0105, -0.0114,  0.0027],\n",
      "          [-0.0195,  0.0249,  0.0171]],\n",
      "\n",
      "         [[ 0.0063, -0.0002, -0.0130],\n",
      "          [-0.0071,  0.0061,  0.0055],\n",
      "          [-0.0154, -0.0133,  0.0288]],\n",
      "\n",
      "         [[ 0.0129, -0.0008,  0.0109],\n",
      "          [-0.0107,  0.0102, -0.0019],\n",
      "          [ 0.0214,  0.0282, -0.0033]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0043,  0.0342, -0.0010],\n",
      "          [-0.0177,  0.0213, -0.0212],\n",
      "          [ 0.0159,  0.0372,  0.0223]],\n",
      "\n",
      "         [[ 0.0017, -0.0256, -0.0267],\n",
      "          [ 0.0182,  0.0070, -0.0001],\n",
      "          [-0.0121,  0.0202, -0.0106]],\n",
      "\n",
      "         [[-0.0197, -0.0103, -0.0142],\n",
      "          [-0.0257, -0.0067, -0.0213],\n",
      "          [ 0.0021, -0.0339, -0.0138]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0162,  0.0169, -0.0290],\n",
      "          [ 0.0202,  0.0117,  0.0042],\n",
      "          [-0.0207, -0.0064, -0.0149]],\n",
      "\n",
      "         [[-0.0326,  0.0113, -0.0169],\n",
      "          [-0.0277,  0.0137, -0.0220],\n",
      "          [ 0.0230, -0.0343,  0.0085]],\n",
      "\n",
      "         [[-0.0015,  0.0229,  0.0170],\n",
      "          [-0.0076,  0.0011,  0.0014],\n",
      "          [ 0.0283, -0.0120, -0.0191]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0123,  0.0183,  0.0354],\n",
      "          [ 0.0095,  0.0006, -0.0113],\n",
      "          [ 0.0173, -0.0183,  0.0017]],\n",
      "\n",
      "         [[ 0.0130, -0.0125, -0.0281],\n",
      "          [ 0.0265,  0.0064, -0.0114],\n",
      "          [ 0.0088, -0.0170,  0.0044]],\n",
      "\n",
      "         [[ 0.0149, -0.0092,  0.0301],\n",
      "          [-0.0132,  0.0024,  0.0211],\n",
      "          [-0.0187,  0.0198, -0.0274]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0052, -0.0246, -0.0163],\n",
      "          [ 0.0083, -0.0041,  0.0302],\n",
      "          [-0.0255,  0.0216,  0.0138]],\n",
      "\n",
      "         [[ 0.0186, -0.0111, -0.0135],\n",
      "          [ 0.0143, -0.0311, -0.0108],\n",
      "          [ 0.0107, -0.0046, -0.0107]],\n",
      "\n",
      "         [[ 0.0229, -0.0005,  0.0177],\n",
      "          [-0.0051, -0.0080,  0.0117],\n",
      "          [ 0.0127, -0.0233, -0.0168]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0121, -0.0041,  0.0161],\n",
      "          [-0.0313,  0.0040,  0.0026],\n",
      "          [-0.0189, -0.0236, -0.0315]],\n",
      "\n",
      "         [[-0.0078,  0.0003, -0.0083],\n",
      "          [-0.0183,  0.0007, -0.0212],\n",
      "          [ 0.0078, -0.0054, -0.0289]],\n",
      "\n",
      "         [[ 0.0205, -0.0135,  0.0154],\n",
      "          [-0.0265,  0.0005, -0.0060],\n",
      "          [ 0.0152, -0.0084, -0.0097]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0048, -0.0152,  0.0070],\n",
      "          [ 0.0249,  0.0043, -0.0198],\n",
      "          [-0.0157, -0.0195, -0.0199]],\n",
      "\n",
      "         [[-0.0093,  0.0143,  0.0005],\n",
      "          [ 0.0217,  0.0036,  0.0130],\n",
      "          [ 0.0183,  0.0129, -0.0103]],\n",
      "\n",
      "         [[ 0.0239, -0.0101,  0.0201],\n",
      "          [-0.0176, -0.0289, -0.0048],\n",
      "          [-0.0274, -0.0245,  0.0199]]]])\n",
      "activation_stack.8.bias: tensor([ 0.0280, -0.0052, -0.0016,  0.0244, -0.0313,  0.0020,  0.0264, -0.0011,\n",
      "        -0.0062, -0.0188,  0.0167,  0.0214,  0.0085,  0.0352, -0.0259, -0.0076,\n",
      "         0.0028,  0.0124, -0.0129, -0.0033,  0.0020,  0.0229,  0.0209,  0.0237,\n",
      "         0.0072,  0.0170, -0.0016, -0.0261,  0.0197, -0.0230, -0.0149, -0.0225,\n",
      "         0.0190,  0.0025, -0.0183, -0.0157,  0.0144, -0.0004, -0.0029, -0.0218,\n",
      "        -0.0111,  0.0187,  0.0038, -0.0152,  0.0171, -0.0197,  0.0291,  0.0222,\n",
      "        -0.0026,  0.0083, -0.0314, -0.0054, -0.0345, -0.0220,  0.0182, -0.0089,\n",
      "        -0.0090,  0.0255,  0.0256,  0.0332,  0.0032,  0.0153,  0.0287,  0.0227,\n",
      "         0.0226, -0.0121,  0.0022,  0.0080,  0.0240, -0.0158, -0.0249, -0.0079,\n",
      "        -0.0181,  0.0335, -0.0116,  0.0292, -0.0263, -0.0184, -0.0183, -0.0299,\n",
      "         0.0292, -0.0074, -0.0147,  0.0181,  0.0109,  0.0209, -0.0109,  0.0054,\n",
      "         0.0226, -0.0211,  0.0007,  0.0192,  0.0267, -0.0033,  0.0143, -0.0082,\n",
      "         0.0060, -0.0231, -0.0035, -0.0096,  0.0251,  0.0290, -0.0098,  0.0146,\n",
      "         0.0055,  0.0082, -0.0071, -0.0150, -0.0081,  0.0021,  0.0139, -0.0202,\n",
      "        -0.0064,  0.0259,  0.0035,  0.0188,  0.0048,  0.0243, -0.0149, -0.0234,\n",
      "         0.0036, -0.0151,  0.0193, -0.0122, -0.0013,  0.0131,  0.0250, -0.0047])\n",
      "activation_stack.11.weight: tensor([1.0041, 0.9971, 1.0026, 1.0093, 1.0088, 1.0094, 1.0054, 1.0002, 0.9949,\n",
      "        0.9918, 0.9962, 1.0024, 0.9984, 1.0005, 0.9989, 1.0016, 1.0054, 0.9962,\n",
      "        1.0030, 1.0012, 1.0027, 0.9999, 0.9940, 1.0080, 0.9995, 1.0004, 1.0095,\n",
      "        0.9947, 1.0051, 0.9907, 0.9980, 1.0022, 0.9994, 0.9966, 0.9953, 1.0087,\n",
      "        0.9885, 1.0044, 0.9964, 1.0001, 0.9963, 0.9883, 0.9963, 0.9980, 0.9928,\n",
      "        1.0028, 0.9991, 0.9958, 0.9937, 0.9986, 0.9921, 1.0061, 0.9983, 1.0009,\n",
      "        0.9974, 1.0044, 0.9919, 1.0022, 0.9923, 0.9998, 0.9998, 1.0001, 0.9990,\n",
      "        0.9936, 0.9981, 0.9987, 0.9992, 1.0061, 0.9959, 1.0018, 1.0013, 1.0005,\n",
      "        0.9983, 1.0024, 0.9964, 0.9952, 1.0009, 0.9908, 1.0132, 0.9924, 1.0021,\n",
      "        1.0029, 1.0125, 1.0015, 1.0039, 0.9992, 1.0018, 0.9971, 1.0072, 0.9920,\n",
      "        0.9963, 1.0021, 0.9989, 1.0048, 0.9947, 1.0027, 0.9992, 1.0053, 0.9946,\n",
      "        1.0026, 1.0033, 1.0069, 0.9968, 1.0005, 1.0031, 0.9972, 1.0054, 0.9934,\n",
      "        1.0013, 1.0158, 0.9912, 0.9937, 1.0015, 1.0032, 1.0084, 0.9962, 1.0000,\n",
      "        1.0009, 1.0146, 1.0005, 1.0115, 0.9967, 1.0019, 0.9993, 0.9986, 0.9949,\n",
      "        1.0007, 0.9970])\n",
      "activation_stack.11.bias: tensor([ 4.7520e-03,  3.5256e-03,  5.0061e-03,  5.6376e-04,  5.1772e-03,\n",
      "        -3.6113e-03,  9.0223e-04,  2.3354e-03,  2.5760e-03, -2.1882e-04,\n",
      "         4.6509e-03,  6.4364e-03, -3.2417e-03, -2.9329e-03,  2.7103e-03,\n",
      "         5.5607e-03,  3.4298e-03,  2.2283e-03, -3.4081e-03,  3.0044e-04,\n",
      "         3.9536e-04, -5.1088e-03, -6.0493e-03, -2.6412e-03,  1.1115e-03,\n",
      "        -3.3997e-03,  3.0017e-03, -4.5543e-03,  3.5493e-03,  6.8642e-03,\n",
      "         1.6800e-03,  2.1529e-03, -5.1487e-04,  3.8738e-03,  3.0327e-03,\n",
      "         4.1403e-03, -2.2366e-03,  5.0314e-03,  2.2529e-03, -1.3928e-03,\n",
      "         2.5190e-03,  3.4559e-03,  3.0885e-03,  2.3461e-04,  4.4916e-03,\n",
      "         2.3740e-03,  5.8512e-04,  1.6307e-03,  3.5443e-03, -8.6535e-04,\n",
      "         5.0174e-03, -1.5613e-03,  2.0299e-03, -2.2069e-05, -3.5454e-04,\n",
      "         3.2522e-04,  4.2681e-03, -9.0799e-04,  7.1606e-04, -1.5267e-03,\n",
      "         1.9710e-03,  2.1856e-03,  1.1522e-03, -1.3994e-03,  4.1403e-03,\n",
      "         5.4134e-04,  2.5231e-03, -4.4081e-04,  1.1882e-03,  2.2355e-04,\n",
      "         5.5508e-03, -3.8261e-05, -3.7596e-03,  4.6851e-04,  2.6734e-03,\n",
      "         4.8688e-03,  3.1973e-03,  3.5942e-03, -1.0468e-02, -9.9933e-04,\n",
      "         1.4064e-04,  9.3688e-04, -1.4362e-04,  6.7532e-04,  3.0338e-03,\n",
      "         3.4094e-03,  4.2094e-03, -6.9707e-04,  4.9851e-03,  4.4263e-03,\n",
      "        -3.7620e-03,  1.5563e-03,  4.9725e-03,  5.8057e-03,  4.9355e-03,\n",
      "         5.0304e-03, -2.2540e-03, -6.3408e-04,  4.3160e-03,  5.2805e-03,\n",
      "         3.9232e-03,  3.2148e-03,  3.2491e-04, -2.7768e-03,  4.9626e-03,\n",
      "        -3.5064e-04, -3.1692e-03,  7.2488e-03, -3.3809e-03, -1.2159e-03,\n",
      "         3.0772e-03,  2.7567e-04, -3.5048e-04,  9.6173e-03,  4.5489e-03,\n",
      "         3.7645e-03,  5.4352e-04,  9.7198e-04, -1.4627e-03,  5.4527e-03,\n",
      "         1.2849e-03,  2.0089e-03,  2.7469e-03, -3.0160e-03,  8.2878e-04,\n",
      "         1.6916e-03,  4.7634e-03, -5.2976e-03])\n",
      "activation_stack.12.weight: tensor([[[[ 1.2021e-02,  2.0070e-02, -1.6990e-02],\n",
      "          [-6.2680e-03,  6.0217e-03, -5.8578e-03],\n",
      "          [-1.8566e-02,  5.8112e-03,  4.8429e-03]],\n",
      "\n",
      "         [[ 1.9554e-02,  5.7182e-03,  2.2649e-02],\n",
      "          [-2.1162e-03, -8.0096e-03,  5.0156e-03],\n",
      "          [-2.8285e-02, -1.5747e-02, -6.9718e-03]],\n",
      "\n",
      "         [[-1.3276e-02, -1.0614e-02, -2.4974e-02],\n",
      "          [ 1.4848e-02, -1.5803e-02,  2.1661e-02],\n",
      "          [-4.9512e-03, -1.4860e-03, -2.8425e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5677e-03,  1.6472e-02, -5.8225e-03],\n",
      "          [ 2.7826e-03, -3.0235e-02,  5.2683e-05],\n",
      "          [-1.5828e-02, -1.6413e-02,  2.4595e-02]],\n",
      "\n",
      "         [[ 9.3788e-03,  1.7572e-03,  3.0898e-04],\n",
      "          [ 8.4798e-03, -9.6440e-03,  2.8769e-02],\n",
      "          [-1.2242e-02, -4.4675e-03,  1.3046e-02]],\n",
      "\n",
      "         [[-9.6056e-03, -8.7696e-03, -1.9230e-03],\n",
      "          [ 2.3704e-02, -1.8688e-02,  4.8750e-03],\n",
      "          [-1.1457e-02,  8.1910e-04,  5.4061e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2466e-02, -4.1217e-03, -2.8934e-02],\n",
      "          [-3.2037e-02, -2.4333e-02, -2.5845e-02],\n",
      "          [-1.6340e-02, -2.5257e-02,  1.1257e-02]],\n",
      "\n",
      "         [[-2.1347e-02, -3.1236e-02,  1.4515e-03],\n",
      "          [ 2.1868e-02,  6.4150e-03,  2.6818e-02],\n",
      "          [-3.8606e-03,  2.2655e-02,  2.9065e-02]],\n",
      "\n",
      "         [[ 2.4053e-02,  1.5635e-02,  2.0876e-02],\n",
      "          [ 1.6810e-02, -1.0330e-02,  6.4950e-03],\n",
      "          [-2.7530e-02, -6.3623e-03, -1.3241e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9710e-02, -7.6045e-03, -2.6735e-02],\n",
      "          [ 4.0503e-03, -5.4398e-03, -2.5055e-03],\n",
      "          [-8.1441e-03,  1.7228e-02, -2.2938e-03]],\n",
      "\n",
      "         [[-2.1771e-02, -2.4602e-02, -3.6910e-03],\n",
      "          [ 6.5599e-03, -2.6657e-02, -1.1963e-02],\n",
      "          [-1.8783e-02,  1.4358e-02,  1.3891e-02]],\n",
      "\n",
      "         [[-1.7513e-02,  3.1351e-02,  3.0224e-02],\n",
      "          [ 1.1944e-02,  2.6953e-02,  1.8249e-02],\n",
      "          [-2.2512e-02, -8.5801e-03,  1.8074e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1032e-03,  8.3436e-03, -1.9517e-02],\n",
      "          [ 3.1409e-02,  2.5747e-02, -6.8592e-03],\n",
      "          [-2.7815e-02,  1.1440e-02,  2.5361e-03]],\n",
      "\n",
      "         [[-1.4298e-02,  1.5907e-03,  2.5017e-02],\n",
      "          [-2.7446e-02, -9.6645e-03,  3.8674e-03],\n",
      "          [ 1.7248e-02,  1.5030e-02,  2.0307e-03]],\n",
      "\n",
      "         [[-1.2174e-02,  3.4556e-03, -2.7512e-02],\n",
      "          [-1.7140e-02,  5.9977e-03,  1.3452e-02],\n",
      "          [ 1.1936e-02,  1.2728e-02,  8.9306e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2326e-03, -4.0021e-03, -6.5647e-03],\n",
      "          [ 2.3717e-02, -6.4064e-04, -5.0351e-03],\n",
      "          [-2.2029e-02,  1.0960e-02,  1.4035e-02]],\n",
      "\n",
      "         [[ 5.9420e-03,  1.2808e-02,  8.3898e-03],\n",
      "          [ 4.7274e-03, -2.0763e-02, -1.8577e-02],\n",
      "          [-5.1635e-03,  5.7764e-03, -1.3651e-02]],\n",
      "\n",
      "         [[ 2.1647e-02,  2.0693e-02, -1.7729e-02],\n",
      "          [-2.8002e-02, -2.5490e-02, -2.2261e-02],\n",
      "          [ 1.4496e-02, -2.1992e-02,  2.1345e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.5546e-02, -1.6248e-02,  1.9834e-02],\n",
      "          [ 1.5733e-02,  6.7554e-03,  1.7217e-02],\n",
      "          [-1.4437e-02, -2.3513e-02,  1.4938e-02]],\n",
      "\n",
      "         [[ 1.4045e-02,  2.7284e-02, -2.4725e-02],\n",
      "          [-2.1003e-02,  2.7845e-02,  2.0702e-02],\n",
      "          [-1.8325e-02,  7.1243e-03,  1.4333e-02]],\n",
      "\n",
      "         [[ 1.8451e-02,  2.6228e-02, -1.3083e-02],\n",
      "          [ 2.9725e-02,  2.5480e-02,  4.7724e-03],\n",
      "          [-1.3583e-02,  2.2703e-02,  2.4342e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3390e-02,  1.5264e-02,  2.3326e-02],\n",
      "          [-7.7528e-03, -1.5557e-02,  2.0506e-02],\n",
      "          [-1.6562e-02, -1.8758e-02,  1.6063e-02]],\n",
      "\n",
      "         [[-7.6241e-03, -2.6350e-02, -6.0532e-03],\n",
      "          [ 4.6215e-04, -3.2017e-02,  5.5841e-03],\n",
      "          [ 7.4228e-03, -2.9387e-02, -2.7819e-02]],\n",
      "\n",
      "         [[-7.0627e-03, -2.3006e-02,  1.1109e-02],\n",
      "          [-1.8086e-02, -1.7030e-02,  2.6690e-04],\n",
      "          [-1.6552e-02, -1.6285e-02,  2.5562e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0907e-02, -2.2085e-02, -1.8297e-02],\n",
      "          [-2.9230e-02, -2.3040e-02,  4.7916e-03],\n",
      "          [ 1.9868e-02, -1.6005e-02,  5.8263e-03]],\n",
      "\n",
      "         [[ 7.3505e-03,  1.2401e-02, -1.6118e-02],\n",
      "          [ 1.6521e-04,  4.9730e-03,  1.5067e-02],\n",
      "          [-2.6150e-02,  3.0461e-02, -2.3601e-02]],\n",
      "\n",
      "         [[-1.6161e-02, -3.2473e-02,  2.3256e-02],\n",
      "          [ 2.8994e-03,  7.3321e-04,  3.7595e-03],\n",
      "          [-1.3289e-04,  6.3182e-03, -2.7364e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1626e-03, -6.3618e-03, -1.3215e-02],\n",
      "          [-6.0783e-03,  2.7868e-02,  8.5428e-03],\n",
      "          [-2.3938e-02,  2.1140e-02, -2.1499e-02]],\n",
      "\n",
      "         [[ 1.7580e-02,  9.4736e-03,  1.2193e-02],\n",
      "          [-1.4567e-02, -5.7097e-03, -7.5037e-03],\n",
      "          [ 2.6680e-02,  1.4439e-02, -2.3935e-02]],\n",
      "\n",
      "         [[ 1.2246e-03, -2.7668e-02, -1.5011e-02],\n",
      "          [ 1.0338e-02, -1.3664e-02, -1.4849e-02],\n",
      "          [-1.9849e-02,  1.9188e-02, -4.8854e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8793e-03, -2.7911e-02,  2.6533e-02],\n",
      "          [ 1.2350e-02, -2.2606e-02,  7.7544e-03],\n",
      "          [-2.3226e-02,  2.0137e-02, -2.9079e-03]],\n",
      "\n",
      "         [[ 2.7766e-02,  1.9986e-02, -2.3551e-02],\n",
      "          [ 7.6566e-03,  1.1494e-02, -1.6949e-02],\n",
      "          [ 2.3272e-02,  2.6956e-02,  1.9539e-02]],\n",
      "\n",
      "         [[ 7.4680e-03, -2.5103e-02, -1.4232e-03],\n",
      "          [ 1.2258e-02,  1.1664e-02,  8.8186e-03],\n",
      "          [-2.0432e-02,  2.9897e-02,  1.6570e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0729e-03, -5.1512e-03,  2.4421e-02],\n",
      "          [-1.2249e-02,  1.8653e-02,  9.0489e-03],\n",
      "          [-2.6618e-02, -2.1674e-03, -1.8296e-02]],\n",
      "\n",
      "         [[ 2.6949e-02, -2.5104e-02,  1.8352e-03],\n",
      "          [-1.6630e-03, -1.8881e-02, -2.8736e-03],\n",
      "          [-1.3334e-02,  1.8877e-02,  1.3967e-02]],\n",
      "\n",
      "         [[-5.8447e-03, -6.5902e-03, -1.5632e-02],\n",
      "          [ 1.4922e-02,  1.1243e-03,  2.7915e-02],\n",
      "          [ 4.4608e-03,  6.7913e-03,  2.8127e-02]]]])\n",
      "activation_stack.12.bias: tensor([-0.0120,  0.0128,  0.0225,  0.0002, -0.0098, -0.0066,  0.0203, -0.0178,\n",
      "        -0.0013,  0.0046, -0.0314,  0.0174,  0.0169, -0.0199, -0.0095,  0.0294,\n",
      "        -0.0031,  0.0044, -0.0294,  0.0067, -0.0097,  0.0031, -0.0303,  0.0071,\n",
      "        -0.0114,  0.0196, -0.0141,  0.0040,  0.0253,  0.0133, -0.0013,  0.0102,\n",
      "         0.0140,  0.0098,  0.0150,  0.0120,  0.0212,  0.0208,  0.0073, -0.0075,\n",
      "        -0.0149,  0.0282,  0.0103, -0.0211, -0.0252, -0.0205, -0.0015,  0.0047,\n",
      "        -0.0172,  0.0056, -0.0035,  0.0205, -0.0114, -0.0064,  0.0160, -0.0005,\n",
      "        -0.0298, -0.0237,  0.0262,  0.0132,  0.0221, -0.0149, -0.0024, -0.0219,\n",
      "        -0.0261,  0.0038,  0.0203, -0.0111, -0.0207, -0.0082,  0.0145,  0.0257,\n",
      "        -0.0117, -0.0181,  0.0174,  0.0018,  0.0085,  0.0117, -0.0089, -0.0085,\n",
      "        -0.0131, -0.0102,  0.0116, -0.0342,  0.0203, -0.0028,  0.0222, -0.0233,\n",
      "         0.0026, -0.0133,  0.0190, -0.0079,  0.0308, -0.0203, -0.0193, -0.0248,\n",
      "         0.0056,  0.0189, -0.0251, -0.0260,  0.0100, -0.0289,  0.0207, -0.0016,\n",
      "        -0.0052,  0.0069, -0.0261,  0.0236,  0.0256,  0.0006,  0.0055,  0.0141,\n",
      "         0.0179, -0.0042, -0.0179, -0.0053, -0.0032,  0.0049, -0.0172, -0.0136,\n",
      "        -0.0174,  0.0232,  0.0214,  0.0056,  0.0142, -0.0223,  0.0117, -0.0247,\n",
      "        -0.0164,  0.0155, -0.0187, -0.0137, -0.0115, -0.0294, -0.0017, -0.0215,\n",
      "        -0.0076, -0.0040, -0.0192, -0.0262, -0.0032,  0.0064,  0.0016,  0.0017,\n",
      "         0.0161,  0.0228, -0.0029,  0.0042,  0.0051, -0.0009, -0.0284,  0.0166,\n",
      "         0.0093,  0.0182, -0.0025,  0.0021,  0.0051, -0.0188, -0.0181, -0.0238,\n",
      "         0.0056,  0.0052,  0.0165,  0.0066, -0.0227,  0.0053,  0.0290,  0.0171,\n",
      "        -0.0030, -0.0209,  0.0078, -0.0018, -0.0058,  0.0214,  0.0076, -0.0226,\n",
      "        -0.0208, -0.0129,  0.0214,  0.0181,  0.0006,  0.0234,  0.0035,  0.0178,\n",
      "         0.0092, -0.0258, -0.0251, -0.0194, -0.0105, -0.0029, -0.0047, -0.0066,\n",
      "        -0.0116, -0.0281,  0.0114, -0.0261, -0.0350, -0.0233, -0.0070,  0.0112,\n",
      "         0.0075, -0.0213, -0.0111,  0.0022,  0.0183, -0.0186, -0.0271,  0.0101,\n",
      "         0.0091, -0.0279,  0.0206,  0.0098, -0.0048, -0.0122,  0.0193, -0.0179,\n",
      "        -0.0146, -0.0225, -0.0099, -0.0030, -0.0183, -0.0166, -0.0105, -0.0008,\n",
      "         0.0202,  0.0216, -0.0072,  0.0162, -0.0050, -0.0159,  0.0193,  0.0040,\n",
      "        -0.0259, -0.0235,  0.0160,  0.0154,  0.0057, -0.0087,  0.0020,  0.0018,\n",
      "        -0.0205, -0.0018,  0.0053, -0.0190, -0.0112, -0.0253,  0.0244,  0.0168,\n",
      "         0.0130, -0.0276,  0.0177,  0.0076, -0.0102, -0.0048, -0.0005,  0.0029])\n",
      "activation_stack.14.weight: tensor([[[[-0.0021,  0.0048, -0.0050],\n",
      "          [ 0.0200,  0.0226,  0.0033],\n",
      "          [-0.0114,  0.0068,  0.0035]],\n",
      "\n",
      "         [[ 0.0103, -0.0114, -0.0055],\n",
      "          [ 0.0011,  0.0174, -0.0074],\n",
      "          [-0.0081, -0.0005, -0.0019]],\n",
      "\n",
      "         [[ 0.0129,  0.0184, -0.0205],\n",
      "          [-0.0059,  0.0143,  0.0033],\n",
      "          [-0.0139, -0.0161, -0.0016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0007, -0.0029,  0.0056],\n",
      "          [ 0.0132, -0.0079,  0.0158],\n",
      "          [ 0.0116, -0.0029, -0.0099]],\n",
      "\n",
      "         [[-0.0066,  0.0059,  0.0185],\n",
      "          [-0.0193,  0.0034,  0.0087],\n",
      "          [ 0.0123,  0.0121,  0.0155]],\n",
      "\n",
      "         [[ 0.0175, -0.0006, -0.0153],\n",
      "          [-0.0010,  0.0092,  0.0128],\n",
      "          [ 0.0092, -0.0080,  0.0092]]],\n",
      "\n",
      "\n",
      "        [[[-0.0110, -0.0002, -0.0146],\n",
      "          [ 0.0118,  0.0150,  0.0124],\n",
      "          [ 0.0014, -0.0201, -0.0102]],\n",
      "\n",
      "         [[ 0.0013, -0.0080, -0.0121],\n",
      "          [ 0.0157, -0.0165, -0.0106],\n",
      "          [-0.0151, -0.0022, -0.0040]],\n",
      "\n",
      "         [[-0.0002,  0.0057, -0.0038],\n",
      "          [-0.0032, -0.0008,  0.0068],\n",
      "          [-0.0012, -0.0130, -0.0173]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0011,  0.0183,  0.0183],\n",
      "          [ 0.0037, -0.0110,  0.0205],\n",
      "          [ 0.0016,  0.0094,  0.0124]],\n",
      "\n",
      "         [[-0.0079,  0.0015,  0.0085],\n",
      "          [-0.0102, -0.0151, -0.0088],\n",
      "          [ 0.0165, -0.0118,  0.0056]],\n",
      "\n",
      "         [[ 0.0108,  0.0237,  0.0042],\n",
      "          [-0.0052, -0.0052, -0.0187],\n",
      "          [ 0.0006,  0.0129,  0.0106]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0162, -0.0159, -0.0022],\n",
      "          [-0.0077, -0.0172,  0.0104],\n",
      "          [ 0.0010, -0.0189, -0.0112]],\n",
      "\n",
      "         [[ 0.0009, -0.0002,  0.0119],\n",
      "          [ 0.0117, -0.0027,  0.0213],\n",
      "          [ 0.0134, -0.0089, -0.0063]],\n",
      "\n",
      "         [[-0.0114, -0.0142,  0.0087],\n",
      "          [ 0.0150,  0.0188,  0.0118],\n",
      "          [-0.0216, -0.0112, -0.0098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0100,  0.0118, -0.0152],\n",
      "          [ 0.0113,  0.0001,  0.0179],\n",
      "          [-0.0106,  0.0127,  0.0171]],\n",
      "\n",
      "         [[-0.0033, -0.0167, -0.0085],\n",
      "          [-0.0140,  0.0134, -0.0002],\n",
      "          [-0.0176, -0.0198, -0.0089]],\n",
      "\n",
      "         [[ 0.0197,  0.0195, -0.0020],\n",
      "          [-0.0233, -0.0070, -0.0077],\n",
      "          [-0.0051,  0.0057, -0.0004]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0143,  0.0118, -0.0065],\n",
      "          [-0.0231,  0.0149,  0.0100],\n",
      "          [-0.0073,  0.0068, -0.0065]],\n",
      "\n",
      "         [[ 0.0041,  0.0009, -0.0128],\n",
      "          [-0.0036,  0.0193,  0.0113],\n",
      "          [ 0.0234,  0.0254, -0.0047]],\n",
      "\n",
      "         [[ 0.0083, -0.0034,  0.0128],\n",
      "          [-0.0047, -0.0181, -0.0099],\n",
      "          [ 0.0098, -0.0080, -0.0054]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0074,  0.0217, -0.0012],\n",
      "          [-0.0144, -0.0064, -0.0036],\n",
      "          [ 0.0076, -0.0041, -0.0079]],\n",
      "\n",
      "         [[ 0.0203, -0.0054,  0.0161],\n",
      "          [ 0.0042,  0.0102,  0.0138],\n",
      "          [ 0.0013, -0.0072,  0.0030]],\n",
      "\n",
      "         [[ 0.0093, -0.0193,  0.0115],\n",
      "          [-0.0068,  0.0102,  0.0134],\n",
      "          [-0.0105,  0.0183,  0.0163]]],\n",
      "\n",
      "\n",
      "        [[[-0.0177,  0.0037,  0.0014],\n",
      "          [ 0.0173,  0.0035,  0.0202],\n",
      "          [-0.0080,  0.0025, -0.0103]],\n",
      "\n",
      "         [[-0.0079, -0.0002,  0.0162],\n",
      "          [ 0.0135, -0.0090, -0.0175],\n",
      "          [-0.0088,  0.0146,  0.0022]],\n",
      "\n",
      "         [[-0.0120,  0.0031,  0.0173],\n",
      "          [ 0.0185,  0.0045, -0.0053],\n",
      "          [-0.0058,  0.0194, -0.0031]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062,  0.0130,  0.0008],\n",
      "          [-0.0181,  0.0132, -0.0095],\n",
      "          [ 0.0020,  0.0027, -0.0016]],\n",
      "\n",
      "         [[ 0.0005, -0.0015, -0.0022],\n",
      "          [-0.0036,  0.0133,  0.0107],\n",
      "          [-0.0057,  0.0163, -0.0214]],\n",
      "\n",
      "         [[-0.0142, -0.0200, -0.0210],\n",
      "          [-0.0161, -0.0213, -0.0015],\n",
      "          [-0.0101, -0.0015, -0.0089]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0139,  0.0075, -0.0027],\n",
      "          [ 0.0223,  0.0028,  0.0149],\n",
      "          [ 0.0091,  0.0050, -0.0019]],\n",
      "\n",
      "         [[-0.0150, -0.0076, -0.0145],\n",
      "          [-0.0151,  0.0080, -0.0075],\n",
      "          [-0.0025,  0.0181,  0.0177]],\n",
      "\n",
      "         [[-0.0118,  0.0124,  0.0107],\n",
      "          [ 0.0081, -0.0048, -0.0019],\n",
      "          [-0.0031, -0.0074, -0.0145]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0053, -0.0012, -0.0127],\n",
      "          [ 0.0202,  0.0218,  0.0084],\n",
      "          [ 0.0095,  0.0068, -0.0084]],\n",
      "\n",
      "         [[-0.0163, -0.0056, -0.0014],\n",
      "          [-0.0069,  0.0179, -0.0168],\n",
      "          [ 0.0133, -0.0137, -0.0034]],\n",
      "\n",
      "         [[-0.0122,  0.0172,  0.0045],\n",
      "          [ 0.0057, -0.0008, -0.0113],\n",
      "          [ 0.0196, -0.0022,  0.0088]]]])\n",
      "activation_stack.14.bias: tensor([ 9.1472e-03, -2.3426e-03, -1.3815e-02,  7.0355e-03,  2.0431e-03,\n",
      "         1.6078e-02, -9.9846e-03,  1.2621e-02,  1.2983e-02, -3.7151e-03,\n",
      "        -1.7167e-03,  1.3897e-02, -1.1372e-02, -1.8992e-02,  5.4560e-03,\n",
      "        -1.8746e-02,  1.6316e-03,  1.5541e-02,  1.0672e-02,  1.6636e-02,\n",
      "        -1.9692e-02, -2.2691e-02, -1.9464e-02, -5.4043e-03, -6.5684e-03,\n",
      "        -1.7667e-02,  1.1927e-03, -8.9623e-03,  1.4984e-02,  1.6075e-02,\n",
      "        -8.3497e-03, -1.7546e-03, -4.2270e-03, -5.7470e-03, -1.9484e-02,\n",
      "         1.7725e-02,  1.5631e-02,  1.7999e-03,  1.1720e-02, -8.7095e-03,\n",
      "        -1.4197e-02, -8.0772e-04, -8.7841e-03, -1.6416e-02, -2.9867e-05,\n",
      "         1.9537e-02, -7.6123e-03, -1.1735e-02, -1.5302e-02,  3.3328e-03,\n",
      "        -2.4662e-02, -1.3629e-02,  2.0985e-02, -1.1510e-02, -7.4803e-03,\n",
      "        -1.5718e-02, -1.3853e-02, -2.0422e-02, -4.1390e-04,  1.3899e-02,\n",
      "        -1.5298e-02,  1.3161e-02, -6.2984e-03,  8.2605e-03,  1.3235e-02,\n",
      "         5.5708e-04,  1.9487e-02, -1.1641e-03,  1.1409e-02, -2.1809e-02,\n",
      "        -1.4053e-02,  1.3511e-02,  6.0834e-03, -9.6879e-03, -1.4003e-02,\n",
      "        -1.5562e-02, -1.6171e-02, -1.1889e-02,  6.3556e-03,  1.8434e-02,\n",
      "         1.1122e-02, -1.6123e-02,  4.7828e-03, -1.8278e-02, -2.0334e-02,\n",
      "        -1.8080e-02, -7.2777e-03, -4.1739e-04, -7.0189e-03, -1.2671e-04,\n",
      "         1.7638e-02, -9.0319e-03,  1.9447e-02,  1.3038e-02, -1.8113e-02,\n",
      "         2.2666e-02, -3.9595e-03, -2.2069e-02, -1.3879e-02,  3.6677e-03,\n",
      "         1.4054e-02,  1.7868e-02, -8.0440e-03,  1.1429e-02, -2.1647e-02,\n",
      "        -7.6156e-03, -2.0474e-03,  2.2211e-02, -6.0421e-03, -2.2502e-02,\n",
      "         1.4668e-02, -9.8478e-03, -9.8115e-03, -1.9094e-02,  1.6239e-03,\n",
      "        -1.2600e-02, -2.7077e-02,  1.7892e-02, -3.9375e-03, -4.3491e-03,\n",
      "        -1.0176e-02,  1.6374e-02, -3.8551e-03, -6.7888e-04,  8.7386e-03,\n",
      "         1.6180e-03, -3.1122e-03,  8.2476e-03, -2.0422e-02, -5.3828e-04,\n",
      "        -9.0836e-04, -1.5239e-02,  7.2851e-03, -3.5031e-03, -9.7200e-03,\n",
      "         6.3306e-03,  1.2441e-02, -1.9343e-02,  8.6121e-03, -1.2257e-03,\n",
      "        -7.5820e-03, -5.5335e-03,  8.6302e-03,  1.7641e-02,  5.2278e-03,\n",
      "        -2.6143e-03, -5.1825e-03,  1.6791e-02,  5.5093e-03, -7.5469e-03,\n",
      "         1.7664e-02,  6.4479e-03,  8.4114e-03, -2.1738e-02, -5.4820e-03,\n",
      "        -8.4567e-03,  1.5120e-02,  5.5691e-03,  1.9649e-02, -1.7191e-03,\n",
      "         1.4278e-02, -6.5843e-03, -1.7532e-02, -1.3811e-02,  1.7958e-02,\n",
      "        -7.6274e-03,  7.8848e-03,  1.0944e-02, -1.4627e-02, -1.9971e-03,\n",
      "        -8.2949e-03, -3.2506e-03, -2.3860e-02, -7.0578e-03, -1.8952e-02,\n",
      "        -2.2399e-02,  7.6784e-03, -1.4036e-02,  1.5529e-02,  3.8807e-03,\n",
      "        -9.8064e-03, -9.1316e-03,  1.7295e-02, -2.1982e-02, -8.7320e-03,\n",
      "        -8.3103e-03, -1.1507e-02, -1.2750e-02,  4.5756e-03,  7.7374e-03,\n",
      "        -1.5061e-03, -1.4265e-02,  1.3412e-02,  6.6666e-03, -1.1126e-02,\n",
      "         1.2802e-02,  4.5897e-03, -2.0727e-02,  2.8417e-03, -4.5479e-04,\n",
      "        -2.0681e-02, -1.0620e-02,  1.2083e-02, -1.8279e-02,  1.9981e-02,\n",
      "         7.2206e-03,  1.8674e-02,  1.6746e-02, -2.0365e-02,  7.4970e-03,\n",
      "         1.7645e-03, -1.1102e-02, -1.9467e-02,  1.2078e-02,  1.3767e-02,\n",
      "        -1.2895e-03, -1.0624e-02, -1.8640e-02,  4.8084e-03,  2.3607e-03,\n",
      "        -5.6551e-03, -3.9258e-03, -6.0671e-03,  1.6176e-02, -1.5328e-03,\n",
      "        -5.2034e-03,  5.5658e-03,  1.0929e-02,  7.4380e-03, -1.1775e-02,\n",
      "        -2.1921e-02,  8.2592e-03, -1.9591e-03,  4.3522e-03, -1.0614e-02,\n",
      "        -9.6728e-03, -1.0859e-02, -1.6002e-02, -5.8239e-04,  1.0041e-02,\n",
      "        -1.9245e-02,  1.6154e-02, -1.1141e-02, -1.6772e-02, -1.9921e-02,\n",
      "        -1.9445e-03,  1.6955e-02,  4.6797e-03,  8.1889e-03, -1.1065e-02,\n",
      "        -1.9500e-03,  2.3207e-03, -6.9342e-03, -4.3443e-03, -1.0159e-02,\n",
      "         1.4907e-02])\n",
      "activation_stack.17.weight: tensor([1.0044, 1.0090, 1.0035, 1.0047, 1.0074, 1.0107, 1.0078, 1.0129, 1.0108,\n",
      "        1.0090, 1.0017, 1.0078, 1.0082, 1.0116, 1.0078, 1.0123, 1.0071, 1.0118,\n",
      "        1.0126, 1.0088, 1.0076, 1.0120, 1.0085, 1.0016, 1.0085, 1.0043, 1.0083,\n",
      "        1.0104, 1.0123, 1.0059, 1.0125, 1.0167, 1.0060, 1.0109, 1.0114, 1.0135,\n",
      "        1.0024, 1.0062, 1.0084, 1.0038, 1.0097, 1.0089, 1.0139, 1.0143, 1.0082,\n",
      "        1.0090, 1.0029, 1.0123, 1.0060, 1.0081, 1.0109, 1.0063, 1.0097, 1.0110,\n",
      "        1.0153, 1.0132, 1.0079, 1.0013, 1.0082, 1.0130, 1.0061, 1.0196, 1.0049,\n",
      "        1.0084, 1.0030, 1.0077, 1.0080, 1.0037, 1.0184, 1.0162, 1.0123, 1.0088,\n",
      "        1.0099, 1.0138, 1.0122, 1.0158, 1.0087, 1.0052, 1.0083, 1.0057, 1.0135,\n",
      "        1.0155, 1.0107, 1.0120, 1.0096, 1.0098, 1.0095, 1.0117, 1.0115, 1.0084,\n",
      "        1.0118, 1.0092, 1.0074, 1.0152, 1.0111, 1.0070, 1.0082, 1.0119, 1.0062,\n",
      "        1.0158, 1.0070, 1.0028, 1.0049, 1.0075, 1.0099, 1.0104, 1.0021, 1.0176,\n",
      "        1.0057, 1.0116, 1.0103, 1.0057, 1.0094, 1.0218, 1.0118, 1.0112, 1.0129,\n",
      "        1.0075, 1.0125, 1.0080, 1.0110, 1.0089, 1.0099, 1.0101, 1.0134, 1.0126,\n",
      "        1.0134, 1.0067, 1.0096, 1.0043, 1.0082, 1.0064, 1.0060, 1.0143, 1.0116,\n",
      "        1.0066, 1.0084, 1.0081, 1.0098, 1.0046, 1.0155, 1.0106, 1.0026, 1.0094,\n",
      "        1.0120, 1.0167, 1.0050, 1.0106, 1.0209, 1.0108, 1.0080, 1.0129, 1.0135,\n",
      "        1.0104, 1.0108, 1.0062, 1.0100, 1.0136, 1.0089, 1.0073, 1.0100, 1.0098,\n",
      "        1.0109, 1.0280, 1.0061, 1.0155, 1.0112, 1.0103, 1.0089, 1.0056, 1.0076,\n",
      "        1.0075, 1.0153, 1.0092, 1.0106, 1.0092, 1.0075, 1.0141, 1.0094, 1.0109,\n",
      "        1.0083, 1.0087, 1.0203, 1.0121, 1.0051, 1.0095, 1.0096, 1.0050, 1.0111,\n",
      "        1.0076, 1.0108, 1.0086, 1.0134, 1.0088, 0.9989, 1.0086, 1.0039, 1.0077,\n",
      "        1.0091, 1.0049, 1.0045, 1.0099, 1.0147, 1.0053, 1.0119, 1.0145, 1.0082,\n",
      "        1.0087, 1.0026, 1.0066, 1.0082, 1.0082, 1.0154, 1.0080, 1.0106, 1.0090,\n",
      "        1.0103, 1.0113, 1.0080, 1.0184, 1.0148, 1.0078, 1.0051, 1.0082, 1.0064,\n",
      "        1.0096, 1.0139, 1.0172, 1.0025, 1.0069, 1.0123, 1.0133, 1.0163, 1.0078,\n",
      "        1.0089, 1.0054, 1.0042, 1.0071, 1.0185, 1.0158, 1.0092, 1.0086, 1.0212,\n",
      "        1.0082, 1.0025, 1.0085, 1.0098, 1.0082, 1.0123, 1.0065, 1.0108, 1.0060,\n",
      "        1.0099, 1.0065, 1.0078, 1.0059])\n",
      "activation_stack.17.bias: tensor([-3.9568e-03,  4.8432e-03, -1.6953e-03, -2.2717e-03,  3.0106e-03,\n",
      "         4.3937e-04,  2.5961e-03,  1.5619e-03, -2.5383e-03,  2.1710e-03,\n",
      "        -1.4885e-03,  2.3418e-03,  1.0925e-03, -1.5843e-05, -8.4896e-04,\n",
      "         5.3256e-03, -7.4630e-03,  1.5554e-03, -1.7025e-03, -6.9613e-03,\n",
      "        -3.8674e-03, -2.9489e-03,  2.2577e-03,  2.9570e-04, -2.6767e-03,\n",
      "        -8.9937e-04,  3.2874e-03,  2.3671e-04,  4.1993e-03, -4.8312e-03,\n",
      "        -5.7923e-04, -9.7006e-04, -2.7427e-03, -1.1912e-03, -3.3202e-03,\n",
      "        -3.2043e-03,  5.1810e-04, -3.3099e-03, -4.4436e-03, -1.2539e-03,\n",
      "         4.1436e-04, -4.6997e-04, -9.9840e-04, -3.8896e-03,  2.2881e-03,\n",
      "        -2.5230e-03, -4.8826e-03, -4.4614e-03, -1.7409e-03, -4.1078e-03,\n",
      "         1.7324e-03,  1.1230e-03,  3.9187e-03, -4.0392e-03, -2.9814e-03,\n",
      "         4.2619e-04, -3.9082e-04, -7.6836e-04, -1.3322e-03,  3.2546e-03,\n",
      "         5.4685e-04, -2.9395e-03, -6.8068e-03,  1.0205e-05, -3.1951e-03,\n",
      "         1.1248e-03,  1.3939e-03, -5.3237e-03, -2.3281e-03, -7.1921e-04,\n",
      "         1.5861e-03, -3.5715e-04,  6.4839e-03,  4.8962e-03,  4.5264e-03,\n",
      "         3.9925e-03,  1.6836e-03, -5.0058e-03,  1.1932e-03, -4.3156e-03,\n",
      "         2.8155e-03,  2.0985e-03, -1.3653e-03,  3.9825e-04,  1.8368e-03,\n",
      "        -3.0151e-03, -5.0299e-03, -4.5379e-03,  4.2585e-03,  7.0288e-04,\n",
      "        -2.8125e-04, -4.4491e-03,  1.7330e-03, -2.7897e-03, -1.2498e-04,\n",
      "         2.6893e-03, -1.1710e-03,  6.1010e-03, -1.1912e-03, -7.1166e-04,\n",
      "        -9.0258e-04, -4.5526e-03, -3.9720e-03,  1.6003e-05,  3.7323e-03,\n",
      "        -2.4520e-03, -1.9404e-03,  4.3708e-03, -2.7056e-03, -2.1523e-03,\n",
      "         7.4361e-04, -6.6833e-03, -5.9891e-04,  1.9814e-03, -2.3531e-03,\n",
      "        -1.0540e-03, -3.3570e-03,  1.6529e-03, -7.9177e-03, -2.2467e-03,\n",
      "         1.0717e-03,  4.4518e-03, -6.8107e-03, -2.9140e-04, -1.4048e-03,\n",
      "         2.3209e-03, -1.1868e-03, -4.1339e-03,  1.4852e-03, -2.3985e-03,\n",
      "        -2.5321e-03, -1.4470e-03,  2.2003e-03, -3.4664e-03,  1.3952e-03,\n",
      "         1.4057e-03,  1.3334e-03,  7.5371e-04,  2.7690e-04,  1.8146e-03,\n",
      "        -5.0386e-05,  5.6181e-04,  2.7930e-04,  7.7420e-04, -3.8038e-03,\n",
      "         1.6316e-03,  1.0474e-03, -1.6668e-03,  3.3399e-03, -4.2893e-03,\n",
      "        -7.4122e-03,  1.9777e-03, -2.0887e-04, -3.1909e-03,  1.3077e-03,\n",
      "         1.0588e-04, -8.3207e-03, -1.9658e-03, -1.1762e-03, -2.1229e-03,\n",
      "         5.8952e-04,  3.5377e-03, -1.3715e-04, -1.2701e-03, -2.0047e-03,\n",
      "         5.1223e-03, -1.9842e-03, -4.2383e-03, -4.0752e-04, -2.7511e-03,\n",
      "        -2.1433e-03, -6.0085e-04,  6.3578e-04, -3.0517e-03,  3.4452e-03,\n",
      "        -5.1008e-03,  2.1159e-03,  4.5439e-03, -7.8204e-04,  1.6412e-03,\n",
      "         3.3042e-03, -5.7565e-03, -3.9825e-03, -5.9370e-03, -6.3482e-03,\n",
      "        -8.7968e-04, -7.5764e-04, -6.8644e-04,  2.9104e-03,  1.8171e-03,\n",
      "        -4.2455e-04,  5.7242e-03, -1.9290e-03, -3.9230e-03, -7.0876e-03,\n",
      "         9.1657e-05, -6.3766e-04, -2.9521e-03,  4.2017e-03, -7.5809e-04,\n",
      "        -3.8102e-03,  2.6009e-03,  6.9329e-04, -1.1487e-03,  3.2110e-03,\n",
      "        -6.1468e-03,  1.8049e-03,  1.7302e-03, -2.1777e-03, -4.4293e-04,\n",
      "        -2.5784e-03,  1.4296e-03,  1.3502e-03, -3.3960e-03, -7.1218e-04,\n",
      "         1.5208e-03,  3.2315e-03, -6.2973e-04, -6.8370e-04,  1.6289e-03,\n",
      "        -2.5371e-03, -3.4378e-03, -2.3383e-04, -2.9811e-04,  2.9754e-03,\n",
      "        -3.8508e-03,  1.7723e-03,  2.1254e-03,  1.0655e-03, -1.0447e-03,\n",
      "         2.8005e-03, -6.1371e-04,  9.0085e-04,  1.6993e-03, -2.2207e-04,\n",
      "        -1.5676e-03,  9.9179e-04, -2.6921e-03,  8.7979e-04,  4.8846e-04,\n",
      "        -3.1889e-04,  1.2312e-04,  2.0198e-03,  3.6609e-03, -6.1496e-03,\n",
      "        -2.0857e-03, -3.2399e-04, -2.9807e-03,  1.4275e-03, -2.7605e-03,\n",
      "        -6.4007e-03,  7.7481e-04,  8.1588e-04,  1.1949e-03,  6.6154e-04,\n",
      "        -2.4674e-03])\n",
      "activation_stack.19.weight: tensor([[-9.9662e-03, -8.5172e-03, -1.2386e-02,  ...,  1.3601e-02,\n",
      "         -1.3883e-02, -7.8121e-03],\n",
      "        [-3.1958e-03,  1.2706e-03, -1.3095e-02,  ..., -1.1869e-02,\n",
      "          2.0899e-03, -8.0842e-03],\n",
      "        [ 1.1374e-02,  6.8407e-03,  1.2690e-02,  ..., -1.3633e-02,\n",
      "         -1.2380e-02,  1.4815e-02],\n",
      "        ...,\n",
      "        [ 1.3629e-02,  2.6452e-03, -5.6010e-03,  ..., -7.5968e-03,\n",
      "          3.0292e-03, -3.3831e-03],\n",
      "        [ 1.3857e-02, -3.8802e-03,  1.0837e-02,  ...,  2.1189e-03,\n",
      "         -3.7906e-05, -2.0657e-03],\n",
      "        [-9.3333e-03, -6.3433e-03,  9.2223e-03,  ..., -1.7456e-03,\n",
      "          1.2036e-02,  9.8222e-03]])\n",
      "activation_stack.19.bias: tensor([ 0.0082,  0.0015,  0.0150,  ...,  0.0161,  0.0064, -0.0012])\n",
      "activation_stack.21.weight: tensor([[ 0.0113, -0.0050, -0.0208,  ...,  0.0287, -0.0192, -0.0126],\n",
      "        [-0.0135,  0.0269,  0.0272,  ..., -0.0075, -0.0038,  0.0007],\n",
      "        [-0.0016,  0.0227,  0.0290,  ...,  0.0020, -0.0260, -0.0088],\n",
      "        ...,\n",
      "        [-0.0237, -0.0048, -0.0130,  ...,  0.0277, -0.0013,  0.0067],\n",
      "        [ 0.0253,  0.0074, -0.0249,  ..., -0.0167,  0.0147, -0.0009],\n",
      "        [-0.0270, -0.0239, -0.0278,  ...,  0.0252, -0.0094,  0.0062]])\n",
      "activation_stack.21.bias: tensor([ 1.9954e-02, -9.2743e-03,  4.6727e-03, -2.1293e-03,  1.9393e-02,\n",
      "        -2.5612e-02,  3.3375e-02,  1.7686e-02, -8.5600e-03,  1.7632e-03,\n",
      "         2.1258e-04,  8.0741e-03,  2.0462e-02,  5.8065e-03,  1.0565e-02,\n",
      "        -8.9548e-04,  2.9745e-03,  4.3772e-03, -2.6183e-02,  4.1838e-03,\n",
      "        -1.3973e-02, -1.5263e-02, -6.7760e-03,  2.7379e-02,  2.0067e-02,\n",
      "        -8.6009e-03,  2.0864e-02,  2.6591e-02, -1.6384e-02,  7.1795e-03,\n",
      "         2.3046e-02, -1.2614e-02, -4.1422e-03,  8.9150e-03,  2.3829e-02,\n",
      "        -2.7325e-02,  3.4868e-02, -1.6267e-02,  8.6143e-03,  2.5628e-02,\n",
      "         2.5365e-02,  1.4334e-02,  2.6498e-02, -1.0586e-02, -1.7971e-02,\n",
      "        -2.1816e-02, -2.2365e-02,  3.7558e-03, -6.1206e-03,  1.8479e-02,\n",
      "         9.0512e-03, -1.3551e-03,  1.7797e-02, -1.3930e-02,  3.4071e-02,\n",
      "        -1.8082e-02,  2.3891e-02,  7.9960e-03, -3.1988e-02,  3.3933e-02,\n",
      "        -2.1298e-02,  1.8294e-02, -7.9574e-03, -2.0976e-02, -1.1984e-02,\n",
      "        -7.3812e-03,  2.1633e-02,  1.8991e-02,  3.1008e-02, -1.5418e-02,\n",
      "        -5.2338e-03,  2.8821e-02, -7.0711e-03, -2.7396e-02,  3.2479e-02,\n",
      "         1.0100e-02,  9.8647e-03, -1.9094e-02, -1.0284e-03,  2.0732e-02,\n",
      "        -2.0657e-02,  1.6309e-02, -1.9651e-02, -1.6861e-02,  4.4155e-03,\n",
      "        -1.8384e-02, -1.8001e-02, -6.6184e-03, -2.8540e-02, -6.8566e-03,\n",
      "        -2.5146e-02,  2.7840e-02,  7.8937e-03, -3.3660e-03,  2.4474e-02,\n",
      "         1.7563e-02, -2.1183e-02, -8.8455e-03,  1.0317e-02,  2.4654e-02,\n",
      "        -8.5403e-03, -7.7957e-03,  3.2683e-02,  6.0194e-03, -1.0207e-02,\n",
      "         3.3087e-02, -2.4570e-02,  4.5558e-03, -2.6873e-02, -3.0094e-02,\n",
      "        -1.9372e-02,  2.9506e-02,  1.6613e-02,  2.4861e-02, -2.1356e-02,\n",
      "         3.0307e-02, -1.7126e-02, -2.5443e-02, -1.2481e-02, -4.5572e-03,\n",
      "         4.7770e-03, -2.0802e-02,  2.2115e-02, -1.1904e-02,  2.0334e-02,\n",
      "         1.1546e-02, -1.6196e-02, -2.4368e-02,  9.7332e-03,  1.4191e-02,\n",
      "         5.0412e-03, -1.9686e-02,  1.7937e-02,  2.7691e-02, -2.4328e-02,\n",
      "         2.6786e-02, -5.2505e-03, -1.4246e-02, -1.0643e-02,  1.2779e-02,\n",
      "         2.2528e-02,  2.2435e-02,  2.1115e-02, -1.4250e-02, -1.9652e-02,\n",
      "        -9.4597e-04,  1.6265e-02, -5.0772e-04,  1.9853e-02,  2.0382e-02,\n",
      "        -1.0681e-02,  1.8822e-02,  1.6197e-03,  1.7503e-03,  1.5584e-02,\n",
      "         1.1366e-02,  1.9122e-02,  7.3389e-03, -2.3564e-02, -4.0684e-03,\n",
      "        -3.0757e-02,  4.2705e-03,  2.1724e-02,  7.7959e-03, -1.1997e-03,\n",
      "         1.5961e-03,  2.8598e-02, -1.0659e-02, -4.1715e-04,  2.1860e-02,\n",
      "        -4.2275e-03,  1.8511e-03, -1.1333e-02,  2.9169e-03,  2.6421e-02,\n",
      "         6.1374e-03,  8.3194e-03, -1.5422e-02,  2.0680e-02,  2.5128e-02,\n",
      "        -2.6476e-02, -4.7754e-04, -1.1683e-02,  9.8584e-03,  1.8773e-03,\n",
      "         2.5076e-02,  2.8031e-02, -9.9533e-03, -2.4731e-02, -9.6826e-03,\n",
      "         1.7630e-02, -2.7604e-02, -2.4750e-03,  1.6809e-03,  1.7098e-02,\n",
      "         6.0149e-03,  3.6414e-03,  9.5879e-03,  9.2116e-03,  2.1139e-02,\n",
      "         1.0746e-02,  9.9832e-03, -2.1665e-02,  2.5658e-02,  1.3551e-02,\n",
      "         1.2414e-02,  1.5100e-02, -5.9728e-03,  3.2127e-02, -2.5111e-02,\n",
      "         3.4226e-02,  1.3621e-02,  3.3070e-02,  2.1688e-02,  3.3595e-03,\n",
      "        -4.4811e-03, -8.5227e-03,  2.3103e-02, -1.8519e-02,  2.3924e-02,\n",
      "         2.8260e-02, -1.8928e-02, -1.3405e-02,  1.5067e-02, -2.8735e-04,\n",
      "        -2.0091e-02,  3.2089e-03,  3.2477e-02,  2.5253e-02, -1.2613e-02,\n",
      "        -2.3130e-02,  7.8646e-03, -5.1235e-03,  2.3358e-02,  7.9623e-03,\n",
      "         2.9898e-02, -1.2043e-02, -1.8686e-02, -2.5353e-03, -8.5533e-03,\n",
      "        -1.3354e-02, -1.0611e-02,  1.0451e-02, -5.5346e-03, -6.3511e-03,\n",
      "        -5.6383e-03, -2.3952e-02,  3.2013e-02, -1.7753e-02, -1.2742e-02,\n",
      "         9.7635e-03, -2.6169e-02, -1.6378e-02,  3.1109e-02,  2.9503e-02,\n",
      "         2.9357e-02, -8.1910e-03,  2.4702e-02,  2.3773e-02, -2.5187e-02,\n",
      "        -1.0661e-03,  2.5761e-03,  2.8508e-02,  1.4430e-02,  2.4627e-03,\n",
      "        -2.2440e-02, -4.1198e-03,  2.9892e-02, -2.6179e-02,  2.8253e-02,\n",
      "         2.3941e-02,  2.4637e-02, -9.8838e-03, -1.7734e-02, -1.5667e-02,\n",
      "         3.1818e-02,  1.3314e-02, -4.2435e-03,  2.2932e-02,  1.1953e-03,\n",
      "        -9.4912e-03,  1.3699e-02,  1.7845e-02, -1.8867e-02, -1.2248e-02,\n",
      "         2.9398e-02,  2.8891e-02,  5.0832e-03, -1.1620e-02,  8.0839e-03,\n",
      "        -1.0515e-02,  1.6400e-02,  9.5704e-03, -9.9783e-04, -1.7234e-02,\n",
      "         1.0896e-02, -2.5037e-02, -1.4363e-02, -9.4872e-03,  1.3104e-02,\n",
      "         2.1322e-02, -2.5428e-02,  3.0434e-02,  2.2094e-02,  2.9587e-02,\n",
      "         3.2700e-02,  2.0340e-02, -2.2428e-02, -2.2954e-02,  3.3696e-02,\n",
      "         3.5987e-03,  7.0777e-03, -9.3266e-03, -2.1554e-02, -1.4520e-02,\n",
      "         7.7893e-03,  1.3969e-02,  2.2600e-02, -7.0790e-04, -2.1113e-02,\n",
      "         1.5760e-04,  8.0531e-03,  5.0711e-03, -2.1017e-02,  2.8413e-02,\n",
      "         2.7386e-02,  1.1126e-02, -1.0061e-02,  1.4027e-03, -5.3458e-03,\n",
      "         8.4177e-03,  2.5415e-02,  1.6770e-02,  2.5487e-02,  5.1947e-03,\n",
      "         1.4274e-03,  3.2116e-02,  1.4754e-02, -1.8530e-02, -6.8184e-03,\n",
      "         1.1205e-02,  3.1219e-02,  6.6349e-03, -3.2824e-03,  4.2008e-03,\n",
      "         1.6456e-02,  3.2556e-02,  1.3774e-02, -1.7230e-02,  2.2277e-02,\n",
      "         1.1823e-02,  2.2565e-02,  4.9134e-03, -9.9666e-04, -1.6720e-02,\n",
      "         1.4824e-02, -1.6542e-02, -2.1275e-05,  3.2210e-02,  1.8377e-02,\n",
      "         3.5377e-02,  2.8517e-02,  1.1582e-02,  3.4535e-02,  2.8880e-02,\n",
      "         2.3450e-03, -2.2042e-02, -2.6631e-02,  3.1585e-02,  1.2832e-02,\n",
      "         2.4383e-02,  1.9581e-02,  1.8499e-02, -2.5417e-02,  1.1972e-02,\n",
      "         6.9564e-03, -9.5255e-04, -1.0018e-02,  3.2290e-02,  8.6467e-03,\n",
      "        -5.7983e-03,  1.6451e-02, -2.0962e-02,  2.4741e-02,  3.0370e-02,\n",
      "         1.7772e-02,  2.4421e-02,  1.3729e-02,  1.3013e-02, -1.4589e-02,\n",
      "         3.1242e-02,  1.0309e-02,  2.2342e-02,  2.8288e-02,  1.8847e-02,\n",
      "        -1.7056e-02,  1.4013e-02, -1.2548e-02, -8.4223e-03,  2.4417e-02,\n",
      "        -4.9723e-04,  1.2221e-02, -8.6789e-03, -1.3702e-02,  3.4339e-02,\n",
      "        -1.7922e-02,  3.2223e-02,  1.4048e-02, -8.4156e-03, -2.2824e-02,\n",
      "        -3.0795e-02,  3.0006e-02,  1.8999e-02,  1.2275e-04, -3.5577e-03,\n",
      "        -3.2289e-03, -8.3423e-03, -5.8105e-03, -2.7575e-02, -9.4160e-03,\n",
      "         2.6582e-02, -1.2607e-03,  6.6134e-03,  2.3932e-03,  3.7063e-02,\n",
      "         3.4119e-02, -1.4372e-02, -1.5951e-02,  1.2898e-02, -4.4663e-03,\n",
      "         3.1649e-02,  9.4103e-03,  3.3000e-02, -1.7232e-03, -1.2516e-02,\n",
      "         2.4973e-02,  7.3934e-03, -1.8926e-02, -6.2237e-03,  8.1555e-03,\n",
      "        -4.9947e-03, -2.2957e-02,  4.1703e-03,  2.4591e-02,  1.9230e-02,\n",
      "         3.3458e-02, -1.9347e-02,  2.0488e-02,  1.7750e-02, -2.4586e-02,\n",
      "        -1.0914e-02,  5.0353e-03, -1.9457e-02,  3.1555e-02,  2.8733e-02,\n",
      "        -2.1840e-02,  3.6281e-02,  3.4762e-02,  3.5060e-04, -1.6915e-02,\n",
      "         1.6151e-02,  1.9618e-02,  1.5755e-02,  2.7690e-02,  1.2817e-02,\n",
      "         3.8294e-03, -5.5278e-03, -1.2145e-02,  4.7982e-04,  1.3824e-02,\n",
      "         7.0291e-03, -4.8201e-03, -5.9439e-03,  2.0830e-02,  2.8947e-02,\n",
      "         3.0500e-02, -2.2881e-02, -7.3982e-03, -2.1835e-02,  1.5359e-02,\n",
      "        -2.0395e-02, -2.1630e-02, -7.4266e-03,  1.3544e-02,  5.5759e-03,\n",
      "         5.7114e-03, -5.6512e-03, -3.3092e-03, -1.2350e-02, -9.9486e-03,\n",
      "        -2.9016e-02,  9.0966e-03,  1.2262e-02,  2.0517e-02,  1.6329e-02,\n",
      "         1.0728e-02, -2.2494e-02,  1.0649e-02,  7.0892e-04,  2.9391e-02,\n",
      "        -1.8391e-03,  8.0789e-03,  2.5201e-02,  1.9695e-02,  3.1636e-02,\n",
      "        -2.2996e-02, -1.2088e-02,  2.7259e-02, -1.5207e-02,  5.3033e-03,\n",
      "         1.0370e-02,  1.1352e-02])\n",
      "activation_stack.23.weight: tensor([[-0.0163, -0.0462, -0.0607,  ..., -0.0217, -0.0324, -0.0746],\n",
      "        [ 0.0801,  0.0499, -0.0273,  ..., -0.0553,  0.0493, -0.0302],\n",
      "        [-0.0698, -0.0610, -0.0170,  ...,  0.0010,  0.0430, -0.0379],\n",
      "        ...,\n",
      "        [ 0.0090, -0.0038, -0.0254,  ...,  0.0662,  0.0058,  0.0021],\n",
      "        [-0.0068,  0.0488, -0.0411,  ..., -0.0249, -0.0372, -0.0474],\n",
      "        [-0.0093, -0.0489,  0.0419,  ...,  0.0688, -0.0245, -0.0112]])\n",
      "activation_stack.23.bias: tensor([ 0.0295, -0.0143,  0.0184, -0.0322,  0.0501, -0.0424,  0.0387,  0.0176,\n",
      "         0.0275,  0.0114])\n",
      "Total send cost in training: 1176479733000\n",
      "Total send cost in testing: 1176479733000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss Variance: 0.5315000338647852\n",
      "Test Loss Variance: 1.152224079611004e-08\n",
      "Train Loss Variance For Half: 2.0274322951376642e-07\n",
      "Test Loss Variance For Half: 1.0175066622270001e-09\n",
      "Train error Variance: 0.06253638118505478\n",
      "Test error Variance: 0.0\n",
      "Train error Variance For Half: 2.0274322951376642e-07\n",
      "Test error Variance For Half: 1.0175066622270001e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== The training for local_update_epochs is 10 ===\n",
      "ConvolutionalNeuralNetwork_CIFAR10(\n",
      "  (activation_stack): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "    (19): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (20): ReLU()\n",
      "    (21): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (22): ReLU()\n",
      "    (23): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "!-- Training Session --!\n",
      "Epoch [1/40], Average Loss: 1.95174193, Average Error: 0.6174000501632690, Culminative Send Cost: 58531330\n",
      "Epoch [2/40], Average Loss: 1.70167189, Average Error: 0.5410000085830688, Culminative Send Cost: 117062660\n",
      "Epoch [3/40], Average Loss: 1.11625063, Average Error: 0.3407000601291656, Culminative Send Cost: 175593990\n",
      "Epoch [4/40], Average Loss: 0.46303651, Average Error: 0.1332999914884567, Culminative Send Cost: 234125320\n",
      "Epoch [5/40], Average Loss: 0.35758779, Average Error: 0.0969999879598618, Culminative Send Cost: 292656650\n",
      "Epoch [6/40], Average Loss: 0.10589249, Average Error: 0.0224999990314245, Culminative Send Cost: 351187980\n",
      "Epoch [7/40], Average Loss: 0.05171836, Average Error: 0.0098000001162291, Culminative Send Cost: 409719310\n",
      "Epoch [8/40], Average Loss: 0.01876445, Average Error: 0.0015999998431653, Culminative Send Cost: 468250640\n",
      "Epoch [9/40], Average Loss: 0.00842089, Average Error: 0.0000999999901978, Culminative Send Cost: 526781970\n",
      "Epoch [10/40], Average Loss: 0.00560566, Average Error: 0.0000000000000000, Culminative Send Cost: 585313300\n",
      "Epoch [11/40], Average Loss: 0.00433248, Average Error: 0.0000000000000000, Culminative Send Cost: 643844630\n",
      "Epoch [12/40], Average Loss: 0.00353786, Average Error: 0.0000000000000000, Culminative Send Cost: 702375960\n",
      "Epoch [13/40], Average Loss: 0.00297862, Average Error: 0.0000000000000000, Culminative Send Cost: 760907290\n",
      "Epoch [14/40], Average Loss: 0.00256028, Average Error: 0.0000000000000000, Culminative Send Cost: 819438620\n",
      "Epoch [15/40], Average Loss: 0.00223512, Average Error: 0.0000000000000000, Culminative Send Cost: 877969950\n",
      "Epoch [16/40], Average Loss: 0.00197404, Average Error: 0.0000000000000000, Culminative Send Cost: 936501280\n",
      "Epoch [17/40], Average Loss: 0.00176111, Average Error: 0.0000000000000000, Culminative Send Cost: 995032610\n",
      "Epoch [18/40], Average Loss: 0.00158395, Average Error: 0.0000000000000000, Culminative Send Cost: 1053563940\n",
      "Epoch [19/40], Average Loss: 0.00143441, Average Error: 0.0000000000000000, Culminative Send Cost: 1112095270\n",
      "Epoch [20/40], Average Loss: 0.00130703, Average Error: 0.0000000000000000, Culminative Send Cost: 1170626600\n",
      "Epoch [21/40], Average Loss: 0.00119724, Average Error: 0.0000000000000000, Culminative Send Cost: 1229157930\n",
      "Epoch [22/40], Average Loss: 0.00110207, Average Error: 0.0000000000000000, Culminative Send Cost: 1287689260\n",
      "Epoch [23/40], Average Loss: 0.00101867, Average Error: 0.0000000000000000, Culminative Send Cost: 1346220590\n",
      "Epoch [24/40], Average Loss: 0.00094528, Average Error: 0.0000000000000000, Culminative Send Cost: 1404751920\n",
      "Epoch [25/40], Average Loss: 0.00088020, Average Error: 0.0000000000000000, Culminative Send Cost: 1463283250\n",
      "Epoch [26/40], Average Loss: 0.00082217, Average Error: 0.0000000000000000, Culminative Send Cost: 1521814580\n",
      "Epoch [27/40], Average Loss: 0.00077024, Average Error: 0.0000000000000000, Culminative Send Cost: 1580345910\n",
      "Epoch [28/40], Average Loss: 0.00072354, Average Error: 0.0000000000000000, Culminative Send Cost: 1638877240\n",
      "Epoch [29/40], Average Loss: 0.00068139, Average Error: 0.0000000000000000, Culminative Send Cost: 1697408570\n",
      "Epoch [30/40], Average Loss: 0.00064313, Average Error: 0.0000000000000000, Culminative Send Cost: 1755939900\n",
      "Epoch [31/40], Average Loss: 0.00060833, Average Error: 0.0000000000000000, Culminative Send Cost: 1814471230\n",
      "Epoch [32/40], Average Loss: 0.00057656, Average Error: 0.0000000000000000, Culminative Send Cost: 1873002560\n",
      "Epoch [33/40], Average Loss: 0.00054747, Average Error: 0.0000000000000000, Culminative Send Cost: 1931533890\n",
      "Epoch [34/40], Average Loss: 0.00052076, Average Error: 0.0000000000000000, Culminative Send Cost: 1990065220\n",
      "Epoch [35/40], Average Loss: 0.00049616, Average Error: 0.0000000000000000, Culminative Send Cost: 2048596550\n",
      "Epoch [36/40], Average Loss: 0.00047347, Average Error: 0.0000000000000000, Culminative Send Cost: 2107127880\n",
      "Epoch [37/40], Average Loss: 0.00045246, Average Error: 0.0000000000000000, Culminative Send Cost: 2165659210\n",
      "Epoch [38/40], Average Loss: 0.00043299, Average Error: 0.0000000000000000, Culminative Send Cost: 2224190540\n",
      "Epoch [39/40], Average Loss: 0.00041493, Average Error: 0.0000000000000000, Culminative Send Cost: 2282721870\n",
      "Epoch [40/40], Average Loss: 0.00039810, Average Error: 0.0000000000000000, Culminative Send Cost: 2341253200\n",
      "Time for all iteration:  2951.0939676999997\n",
      "!-- Testing Session --!\n",
      "Epoch [1/40], Average Loss: 0.00038239, Average Error: 0.0000000000000000, Culminative Send Cost: 58531330\n",
      "Epoch [2/40], Average Loss: 0.00036771, Average Error: 0.0000000000000000, Culminative Send Cost: 117062660\n",
      "Epoch [3/40], Average Loss: 0.00035397, Average Error: 0.0000000000000000, Culminative Send Cost: 175593990\n",
      "Epoch [4/40], Average Loss: 0.00034109, Average Error: 0.0000000000000000, Culminative Send Cost: 234125320\n",
      "Epoch [5/40], Average Loss: 0.00032899, Average Error: 0.0000000000000000, Culminative Send Cost: 292656650\n",
      "Epoch [6/40], Average Loss: 0.00031761, Average Error: 0.0000000000000000, Culminative Send Cost: 351187980\n",
      "Epoch [7/40], Average Loss: 0.00030690, Average Error: 0.0000000000000000, Culminative Send Cost: 409719310\n",
      "Epoch [8/40], Average Loss: 0.00029679, Average Error: 0.0000000000000000, Culminative Send Cost: 468250640\n",
      "Epoch [9/40], Average Loss: 0.00028725, Average Error: 0.0000000000000000, Culminative Send Cost: 526781970\n",
      "Epoch [10/40], Average Loss: 0.00027823, Average Error: 0.0000000000000000, Culminative Send Cost: 585313300\n",
      "Epoch [11/40], Average Loss: 0.00026969, Average Error: 0.0000000000000000, Culminative Send Cost: 643844630\n",
      "Epoch [12/40], Average Loss: 0.00026159, Average Error: 0.0000000000000000, Culminative Send Cost: 702375960\n",
      "Epoch [13/40], Average Loss: 0.00025391, Average Error: 0.0000000000000000, Culminative Send Cost: 760907290\n",
      "Epoch [14/40], Average Loss: 0.00024662, Average Error: 0.0000000000000000, Culminative Send Cost: 819438620\n",
      "Epoch [15/40], Average Loss: 0.00023968, Average Error: 0.0000000000000000, Culminative Send Cost: 877969950\n",
      "Epoch [16/40], Average Loss: 0.00023308, Average Error: 0.0000000000000000, Culminative Send Cost: 936501280\n",
      "Epoch [17/40], Average Loss: 0.00022678, Average Error: 0.0000000000000000, Culminative Send Cost: 995032610\n",
      "Epoch [18/40], Average Loss: 0.00022079, Average Error: 0.0000000000000000, Culminative Send Cost: 1053563940\n",
      "Epoch [19/40], Average Loss: 0.00021506, Average Error: 0.0000000000000000, Culminative Send Cost: 1112095270\n",
      "Epoch [20/40], Average Loss: 0.00020959, Average Error: 0.0000000000000000, Culminative Send Cost: 1170626600\n",
      "Epoch [21/40], Average Loss: 0.00020436, Average Error: 0.0000000000000000, Culminative Send Cost: 1229157930\n",
      "Epoch [22/40], Average Loss: 0.00019936, Average Error: 0.0000000000000000, Culminative Send Cost: 1287689260\n",
      "Epoch [23/40], Average Loss: 0.00019457, Average Error: 0.0000000000000000, Culminative Send Cost: 1346220590\n",
      "Epoch [24/40], Average Loss: 0.00018998, Average Error: 0.0000000000000000, Culminative Send Cost: 1404751920\n",
      "Epoch [25/40], Average Loss: 0.00018557, Average Error: 0.0000000000000000, Culminative Send Cost: 1463283250\n",
      "Epoch [26/40], Average Loss: 0.00018135, Average Error: 0.0000000000000000, Culminative Send Cost: 1521814580\n",
      "Epoch [27/40], Average Loss: 0.00017729, Average Error: 0.0000000000000000, Culminative Send Cost: 1580345910\n",
      "Epoch [28/40], Average Loss: 0.00017338, Average Error: 0.0000000000000000, Culminative Send Cost: 1638877240\n",
      "Epoch [29/40], Average Loss: 0.00016963, Average Error: 0.0000000000000000, Culminative Send Cost: 1697408570\n",
      "Epoch [30/40], Average Loss: 0.00016602, Average Error: 0.0000000000000000, Culminative Send Cost: 1755939900\n",
      "Epoch [31/40], Average Loss: 0.00016255, Average Error: 0.0000000000000000, Culminative Send Cost: 1814471230\n",
      "Epoch [32/40], Average Loss: 0.00015921, Average Error: 0.0000000000000000, Culminative Send Cost: 1873002560\n",
      "Epoch [33/40], Average Loss: 0.00015598, Average Error: 0.0000000000000000, Culminative Send Cost: 1931533890\n",
      "Epoch [34/40], Average Loss: 0.00015287, Average Error: 0.0000000000000000, Culminative Send Cost: 1990065220\n",
      "Epoch [35/40], Average Loss: 0.00014987, Average Error: 0.0000000000000000, Culminative Send Cost: 2048596550\n",
      "Epoch [36/40], Average Loss: 0.00014697, Average Error: 0.0000000000000000, Culminative Send Cost: 2107127880\n",
      "Epoch [37/40], Average Loss: 0.00014418, Average Error: 0.0000000000000000, Culminative Send Cost: 2165659210\n",
      "Epoch [38/40], Average Loss: 0.00014147, Average Error: 0.0000000000000000, Culminative Send Cost: 2224190540\n",
      "Epoch [39/40], Average Loss: 0.00013886, Average Error: 0.0000000000000000, Culminative Send Cost: 2282721870\n",
      "Epoch [40/40], Average Loss: 0.00013633, Average Error: 0.0000000000000000, Culminative Send Cost: 2341253200\n",
      "Time for all iteration:  3835.7276144999996\n",
      "activation_stack.0.weight: tensor([[[[-0.1503,  0.1323, -0.1769],\n",
      "          [ 0.0792, -0.1580, -0.1650],\n",
      "          [-0.2228, -0.1160, -0.1154]],\n",
      "\n",
      "         [[ 0.0620,  0.0675,  0.1688],\n",
      "          [-0.0227,  0.0994, -0.1701],\n",
      "          [-0.0441,  0.0304, -0.1456]],\n",
      "\n",
      "         [[-0.0497, -0.0963,  0.1839],\n",
      "          [ 0.0661,  0.1764,  0.0230],\n",
      "          [ 0.1117, -0.0302,  0.1042]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0481,  0.0237,  0.1088],\n",
      "          [-0.1540, -0.1019,  0.1162],\n",
      "          [-0.0203, -0.0321,  0.0515]],\n",
      "\n",
      "         [[-0.0924, -0.0663, -0.0728],\n",
      "          [-0.0734, -0.0442,  0.1346],\n",
      "          [-0.1365, -0.0088, -0.0333]],\n",
      "\n",
      "         [[ 0.1169,  0.1200, -0.1444],\n",
      "          [-0.1989, -0.1491,  0.1164],\n",
      "          [ 0.1241, -0.1603, -0.1237]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0731, -0.0566,  0.1826],\n",
      "          [ 0.1426, -0.1874,  0.0372],\n",
      "          [-0.0815, -0.0558,  0.0720]],\n",
      "\n",
      "         [[ 0.0992, -0.1990, -0.1659],\n",
      "          [-0.0570, -0.0138,  0.0021],\n",
      "          [ 0.0041,  0.0764,  0.1419]],\n",
      "\n",
      "         [[ 0.1720,  0.2271,  0.0842],\n",
      "          [-0.1864, -0.1070, -0.1929],\n",
      "          [ 0.1216,  0.1006, -0.1404]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1789,  0.0012,  0.1302],\n",
      "          [ 0.0682,  0.1878, -0.0394],\n",
      "          [-0.1301,  0.0702, -0.1150]],\n",
      "\n",
      "         [[-0.1869,  0.0623,  0.1848],\n",
      "          [ 0.1784, -0.1444, -0.0839],\n",
      "          [ 0.0523,  0.1558, -0.1399]],\n",
      "\n",
      "         [[-0.1847,  0.0732, -0.2153],\n",
      "          [-0.0301, -0.0891,  0.1959],\n",
      "          [-0.1758, -0.2016,  0.1580]]],\n",
      "\n",
      "\n",
      "        [[[-0.1787,  0.1091,  0.1181],\n",
      "          [ 0.1465, -0.1956, -0.1415],\n",
      "          [ 0.0903,  0.0422,  0.1563]],\n",
      "\n",
      "         [[-0.0407,  0.0921, -0.0774],\n",
      "          [-0.1270,  0.0234, -0.1209],\n",
      "          [-0.0239,  0.0849,  0.0894]],\n",
      "\n",
      "         [[ 0.0541,  0.0984, -0.1122],\n",
      "          [-0.1072, -0.1856, -0.1461],\n",
      "          [-0.1395,  0.0930,  0.1549]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1354, -0.0746,  0.0904],\n",
      "          [ 0.1685,  0.1627, -0.0587],\n",
      "          [-0.0040,  0.0682, -0.1561]],\n",
      "\n",
      "         [[-0.1711, -0.1826, -0.0054],\n",
      "          [-0.1360,  0.1065,  0.0841],\n",
      "          [ 0.1617, -0.1078, -0.0836]],\n",
      "\n",
      "         [[-0.1203,  0.1081,  0.0674],\n",
      "          [-0.0780, -0.0456,  0.0546],\n",
      "          [ 0.0679, -0.1529,  0.1732]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0490,  0.0706, -0.0404],\n",
      "          [-0.1031,  0.1983,  0.0307],\n",
      "          [ 0.1613, -0.1962,  0.1149]],\n",
      "\n",
      "         [[-0.0059,  0.0009, -0.1562],\n",
      "          [ 0.1854, -0.1130, -0.1438],\n",
      "          [ 0.0120, -0.0865,  0.0648]],\n",
      "\n",
      "         [[-0.0108,  0.1261, -0.1895],\n",
      "          [-0.0015, -0.0477, -0.1104],\n",
      "          [ 0.1408,  0.0511, -0.1208]]],\n",
      "\n",
      "\n",
      "        [[[-0.1226, -0.0096, -0.1405],\n",
      "          [ 0.0277, -0.0086, -0.0825],\n",
      "          [ 0.0113, -0.0500,  0.0430]],\n",
      "\n",
      "         [[ 0.1617, -0.1425, -0.1239],\n",
      "          [-0.0072,  0.0846,  0.0524],\n",
      "          [-0.0757,  0.1499,  0.0654]],\n",
      "\n",
      "         [[-0.0080, -0.0453, -0.1189],\n",
      "          [ 0.1779,  0.1422, -0.1211],\n",
      "          [ 0.2020, -0.1443,  0.1971]]],\n",
      "\n",
      "\n",
      "        [[[-0.1732, -0.0546, -0.0560],\n",
      "          [ 0.0149,  0.0017,  0.0282],\n",
      "          [ 0.0595,  0.0774,  0.1802]],\n",
      "\n",
      "         [[ 0.1016, -0.0074,  0.1144],\n",
      "          [-0.1550, -0.0773,  0.0100],\n",
      "          [-0.1823, -0.0333, -0.1676]],\n",
      "\n",
      "         [[-0.1897,  0.1239,  0.0284],\n",
      "          [ 0.1001,  0.0669, -0.1665],\n",
      "          [-0.1665, -0.1029, -0.1722]]],\n",
      "\n",
      "\n",
      "        [[[-0.1381,  0.1488, -0.1318],\n",
      "          [ 0.1525,  0.2040,  0.1010],\n",
      "          [-0.0989, -0.1673, -0.1555]],\n",
      "\n",
      "         [[ 0.0053, -0.0559,  0.0152],\n",
      "          [ 0.1482, -0.1436,  0.1141],\n",
      "          [ 0.1846, -0.1560,  0.0895]],\n",
      "\n",
      "         [[-0.1795,  0.1739, -0.0281],\n",
      "          [ 0.1609,  0.2017, -0.1053],\n",
      "          [-0.0329, -0.1428, -0.1837]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1281, -0.0868, -0.1817],\n",
      "          [ 0.0980,  0.2271,  0.1303],\n",
      "          [-0.1319, -0.1623,  0.1220]],\n",
      "\n",
      "         [[-0.1070,  0.0240, -0.0149],\n",
      "          [ 0.2141,  0.0358,  0.0105],\n",
      "          [-0.0760,  0.1505, -0.0366]],\n",
      "\n",
      "         [[ 0.1193, -0.0408,  0.1189],\n",
      "          [-0.1697, -0.1976, -0.1415],\n",
      "          [ 0.0408, -0.1612,  0.0753]]],\n",
      "\n",
      "\n",
      "        [[[-0.1060, -0.0763,  0.1859],\n",
      "          [ 0.0644,  0.1009, -0.0859],\n",
      "          [-0.0946,  0.0673, -0.1689]],\n",
      "\n",
      "         [[ 0.1179, -0.0186,  0.1718],\n",
      "          [-0.0647,  0.0472, -0.0868],\n",
      "          [-0.1589,  0.1255,  0.1561]],\n",
      "\n",
      "         [[ 0.1221,  0.1774,  0.0287],\n",
      "          [-0.1950, -0.0399,  0.1298],\n",
      "          [ 0.1189, -0.0124,  0.0123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1696,  0.0742,  0.0715],\n",
      "          [ 0.0965, -0.1545,  0.0251],\n",
      "          [ 0.1014, -0.1093, -0.1480]],\n",
      "\n",
      "         [[-0.1199,  0.1384,  0.1995],\n",
      "          [ 0.0308, -0.0352,  0.0201],\n",
      "          [-0.0101, -0.1379,  0.0453]],\n",
      "\n",
      "         [[ 0.1566, -0.1671, -0.0787],\n",
      "          [-0.1694,  0.0476, -0.1908],\n",
      "          [ 0.1953,  0.2077, -0.0302]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1927,  0.0010, -0.1389],\n",
      "          [ 0.1933,  0.1054,  0.0990],\n",
      "          [-0.1962, -0.2062, -0.1406]],\n",
      "\n",
      "         [[ 0.1541,  0.1488, -0.1195],\n",
      "          [ 0.0341,  0.1803, -0.0184],\n",
      "          [ 0.1510, -0.0323, -0.0633]],\n",
      "\n",
      "         [[-0.0511, -0.0058, -0.1165],\n",
      "          [-0.0785,  0.1699,  0.0489],\n",
      "          [-0.1627,  0.1744,  0.0772]]],\n",
      "\n",
      "\n",
      "        [[[-0.1258, -0.0166, -0.0999],\n",
      "          [ 0.1203, -0.0019,  0.0620],\n",
      "          [-0.1816, -0.0795,  0.1726]],\n",
      "\n",
      "         [[-0.0882, -0.0499, -0.0011],\n",
      "          [ 0.0543, -0.1472,  0.0241],\n",
      "          [ 0.2052,  0.0279,  0.1839]],\n",
      "\n",
      "         [[-0.1161, -0.0841, -0.1896],\n",
      "          [-0.1797, -0.0802, -0.0680],\n",
      "          [ 0.0418, -0.1462, -0.0881]]],\n",
      "\n",
      "\n",
      "        [[[-0.1711,  0.0506, -0.0202],\n",
      "          [ 0.1248,  0.0367, -0.0610],\n",
      "          [ 0.1383,  0.1790,  0.1882]],\n",
      "\n",
      "         [[-0.0543, -0.1681, -0.0897],\n",
      "          [-0.0986,  0.1822,  0.2137],\n",
      "          [ 0.1406, -0.1029, -0.0082]],\n",
      "\n",
      "         [[ 0.1003, -0.1626,  0.1307],\n",
      "          [-0.1589,  0.0055, -0.1463],\n",
      "          [-0.1880, -0.0775,  0.0856]]],\n",
      "\n",
      "\n",
      "        [[[-0.0861, -0.0129,  0.0822],\n",
      "          [ 0.0632, -0.1438, -0.1805],\n",
      "          [-0.0097,  0.1439,  0.1327]],\n",
      "\n",
      "         [[-0.0576, -0.1598, -0.1575],\n",
      "          [-0.1217,  0.0290,  0.0109],\n",
      "          [ 0.0296,  0.1423,  0.1124]],\n",
      "\n",
      "         [[ 0.0032, -0.1805, -0.0177],\n",
      "          [ 0.0656, -0.1064,  0.1938],\n",
      "          [ 0.0199,  0.1426,  0.1583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2032, -0.1818,  0.1418],\n",
      "          [ 0.0113,  0.1493, -0.1683],\n",
      "          [ 0.1560,  0.0060,  0.1359]],\n",
      "\n",
      "         [[ 0.0026,  0.1820,  0.0844],\n",
      "          [-0.1070, -0.0985,  0.0978],\n",
      "          [-0.1028, -0.1557, -0.1443]],\n",
      "\n",
      "         [[-0.1907, -0.1687,  0.0228],\n",
      "          [ 0.0106,  0.0776,  0.1506],\n",
      "          [ 0.1625,  0.2003, -0.0742]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1451, -0.0576, -0.1007],\n",
      "          [-0.0166, -0.0155,  0.1821],\n",
      "          [-0.0460,  0.0167, -0.0930]],\n",
      "\n",
      "         [[ 0.0131,  0.0352, -0.0381],\n",
      "          [-0.1384,  0.1794,  0.0335],\n",
      "          [-0.1216,  0.1515, -0.1099]],\n",
      "\n",
      "         [[-0.1446, -0.0337,  0.0725],\n",
      "          [ 0.1141, -0.1776,  0.1355],\n",
      "          [ 0.1320,  0.1541, -0.0789]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1222, -0.1435,  0.0500],\n",
      "          [-0.0329,  0.0700,  0.0494],\n",
      "          [-0.1961, -0.2094, -0.0531]],\n",
      "\n",
      "         [[ 0.0554, -0.2068, -0.0596],\n",
      "          [ 0.1706,  0.1767, -0.1369],\n",
      "          [ 0.0742,  0.1902,  0.1760]],\n",
      "\n",
      "         [[ 0.1757,  0.1346,  0.0794],\n",
      "          [-0.0092,  0.0395, -0.1443],\n",
      "          [-0.0933,  0.1283, -0.0827]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1599,  0.0269, -0.1746],\n",
      "          [ 0.1955,  0.2163, -0.0242],\n",
      "          [-0.1020, -0.1409,  0.0706]],\n",
      "\n",
      "         [[-0.0201,  0.0364, -0.1325],\n",
      "          [-0.1217,  0.0883, -0.0808],\n",
      "          [ 0.0384, -0.1483,  0.1769]],\n",
      "\n",
      "         [[-0.1250,  0.1792,  0.2223],\n",
      "          [-0.1146, -0.0244,  0.1098],\n",
      "          [-0.0389, -0.0579, -0.1246]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0127,  0.1227, -0.1294],\n",
      "          [ 0.0499, -0.1105,  0.1022],\n",
      "          [-0.1035, -0.0255,  0.1452]],\n",
      "\n",
      "         [[ 0.1026,  0.0253,  0.1851],\n",
      "          [-0.1221, -0.0709, -0.1432],\n",
      "          [-0.0124,  0.0716, -0.1259]],\n",
      "\n",
      "         [[ 0.1191,  0.1567, -0.1564],\n",
      "          [-0.0156, -0.0099,  0.1384],\n",
      "          [ 0.0875, -0.0850, -0.0173]]],\n",
      "\n",
      "\n",
      "        [[[-0.0270, -0.0490,  0.1161],\n",
      "          [ 0.0945,  0.1760, -0.1050],\n",
      "          [-0.1707,  0.1426,  0.0993]],\n",
      "\n",
      "         [[-0.1070, -0.1478,  0.0363],\n",
      "          [-0.0402,  0.0368, -0.1736],\n",
      "          [ 0.0051, -0.0454, -0.1935]],\n",
      "\n",
      "         [[-0.1362, -0.0026,  0.0962],\n",
      "          [-0.1500,  0.1175, -0.0693],\n",
      "          [-0.1039,  0.1001,  0.0915]]],\n",
      "\n",
      "\n",
      "        [[[-0.1434,  0.1226, -0.1254],\n",
      "          [ 0.1379, -0.0139,  0.0462],\n",
      "          [ 0.0340, -0.0303, -0.1678]],\n",
      "\n",
      "         [[-0.0639, -0.0948,  0.1270],\n",
      "          [-0.0013,  0.1052,  0.1685],\n",
      "          [ 0.1355,  0.1580,  0.2182]],\n",
      "\n",
      "         [[-0.1297, -0.1985, -0.1445],\n",
      "          [-0.0651,  0.1809, -0.2011],\n",
      "          [-0.1166,  0.1365,  0.2110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1444, -0.0246, -0.0311],\n",
      "          [-0.1013,  0.1275, -0.1186],\n",
      "          [ 0.0337, -0.1108,  0.1907]],\n",
      "\n",
      "         [[ 0.1272,  0.0862,  0.2177],\n",
      "          [ 0.0480,  0.0833, -0.0098],\n",
      "          [-0.1968, -0.1135,  0.0268]],\n",
      "\n",
      "         [[-0.1140,  0.1018,  0.0576],\n",
      "          [-0.1829, -0.2259,  0.0185],\n",
      "          [ 0.1845,  0.0086, -0.0525]]],\n",
      "\n",
      "\n",
      "        [[[-0.0866, -0.0898,  0.1280],\n",
      "          [-0.1919, -0.1331, -0.0311],\n",
      "          [-0.1432, -0.0469,  0.0690]],\n",
      "\n",
      "         [[-0.0112, -0.1195,  0.1584],\n",
      "          [-0.0639, -0.1833, -0.0992],\n",
      "          [ 0.0769, -0.0616, -0.1715]],\n",
      "\n",
      "         [[ 0.0966, -0.0006, -0.1018],\n",
      "          [-0.0512, -0.0060, -0.1255],\n",
      "          [-0.1561, -0.0450,  0.1954]]],\n",
      "\n",
      "\n",
      "        [[[-0.0870, -0.1894, -0.1206],\n",
      "          [-0.1919,  0.0926, -0.0260],\n",
      "          [-0.1672, -0.1460,  0.1047]],\n",
      "\n",
      "         [[ 0.0236,  0.1707,  0.1204],\n",
      "          [-0.0323, -0.1102,  0.0271],\n",
      "          [-0.0764, -0.0773,  0.1798]],\n",
      "\n",
      "         [[ 0.1215, -0.0842,  0.1977],\n",
      "          [-0.0431,  0.1132,  0.0886],\n",
      "          [ 0.0442, -0.0238, -0.0739]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2072,  0.0873, -0.0318],\n",
      "          [-0.0642,  0.1866, -0.1035],\n",
      "          [-0.2006, -0.1767,  0.0007]],\n",
      "\n",
      "         [[ 0.0861, -0.1395,  0.0490],\n",
      "          [ 0.1126, -0.0798, -0.1794],\n",
      "          [ 0.1983,  0.0150, -0.1926]],\n",
      "\n",
      "         [[-0.1634,  0.0716,  0.0933],\n",
      "          [-0.0004,  0.1853,  0.0514],\n",
      "          [-0.1387,  0.1371,  0.1345]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1370, -0.0435, -0.0007],\n",
      "          [-0.0982, -0.1021, -0.1893],\n",
      "          [-0.1079, -0.0522, -0.0554]],\n",
      "\n",
      "         [[ 0.0736, -0.1086, -0.1148],\n",
      "          [-0.0478, -0.0541, -0.0286],\n",
      "          [-0.1914, -0.0788, -0.0723]],\n",
      "\n",
      "         [[ 0.0400,  0.0433, -0.0410],\n",
      "          [ 0.0470,  0.1411,  0.0667],\n",
      "          [-0.0698, -0.1095,  0.0060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0809,  0.0073, -0.1672],\n",
      "          [ 0.0449, -0.0278, -0.0123],\n",
      "          [-0.1606,  0.0973, -0.0792]],\n",
      "\n",
      "         [[ 0.0562, -0.0119, -0.1287],\n",
      "          [-0.0348, -0.0660, -0.0997],\n",
      "          [ 0.0731,  0.1439,  0.0449]],\n",
      "\n",
      "         [[-0.0105,  0.0126, -0.1797],\n",
      "          [-0.1160, -0.0109,  0.1555],\n",
      "          [ 0.0419, -0.1328, -0.0374]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0733,  0.0032,  0.1570],\n",
      "          [-0.0897,  0.0083, -0.0178],\n",
      "          [-0.1911, -0.0850, -0.1782]],\n",
      "\n",
      "         [[-0.1876, -0.0766,  0.0656],\n",
      "          [ 0.1350,  0.2014, -0.1010],\n",
      "          [ 0.1887,  0.1088,  0.1263]],\n",
      "\n",
      "         [[ 0.1295, -0.2227, -0.2409],\n",
      "          [-0.0634,  0.1154,  0.1788],\n",
      "          [ 0.1670, -0.1020,  0.0959]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0162, -0.0634, -0.1645],\n",
      "          [ 0.0941, -0.1229, -0.1276],\n",
      "          [ 0.1589, -0.0938,  0.1072]],\n",
      "\n",
      "         [[-0.1122, -0.1560, -0.1661],\n",
      "          [ 0.1212,  0.1205,  0.0055],\n",
      "          [ 0.1849, -0.0915,  0.0251]],\n",
      "\n",
      "         [[-0.0922,  0.1881, -0.0882],\n",
      "          [-0.1416,  0.1553, -0.0997],\n",
      "          [ 0.0540,  0.1361, -0.1579]]]])\n",
      "activation_stack.0.bias: tensor([ 0.0589,  0.2022,  0.1377, -0.0281,  0.1658, -0.0704, -0.0534, -0.1794,\n",
      "        -0.1195,  0.1074,  0.1214, -0.0951, -0.0026, -0.0865,  0.1396,  0.1396,\n",
      "         0.1832, -0.0965, -0.1363,  0.0815,  0.1364, -0.0701,  0.1168, -0.0127,\n",
      "         0.0815,  0.2100,  0.0358,  0.1729, -0.0975, -0.1569,  0.1068,  0.1880])\n",
      "activation_stack.2.weight: tensor([[[[ 0.0497, -0.0319,  0.0125],\n",
      "          [ 0.0319, -0.0465,  0.0533],\n",
      "          [ 0.0549, -0.0170,  0.0114]],\n",
      "\n",
      "         [[-0.0371,  0.0173,  0.0440],\n",
      "          [-0.0046, -0.0010, -0.0362],\n",
      "          [ 0.0457,  0.0040, -0.0232]],\n",
      "\n",
      "         [[-0.0380, -0.0016,  0.0475],\n",
      "          [-0.0172,  0.0341,  0.0432],\n",
      "          [-0.0370, -0.0301,  0.0331]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0040, -0.0509, -0.0041],\n",
      "          [ 0.0272,  0.0375, -0.0530],\n",
      "          [ 0.0084,  0.0010,  0.0118]],\n",
      "\n",
      "         [[ 0.0604,  0.0216, -0.0232],\n",
      "          [ 0.0491,  0.0287,  0.0523],\n",
      "          [ 0.0454,  0.0312,  0.0295]],\n",
      "\n",
      "         [[ 0.0429, -0.0263,  0.0277],\n",
      "          [-0.0148, -0.0273, -0.0549],\n",
      "          [-0.0452, -0.0202, -0.0180]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0036,  0.0366, -0.0546],\n",
      "          [ 0.0079,  0.0249,  0.0238],\n",
      "          [ 0.0031, -0.0359, -0.0037]],\n",
      "\n",
      "         [[-0.0235,  0.0165,  0.0217],\n",
      "          [-0.0276,  0.0494,  0.0223],\n",
      "          [ 0.0577, -0.0161,  0.0429]],\n",
      "\n",
      "         [[-0.0238,  0.0125,  0.0390],\n",
      "          [ 0.0399,  0.0238, -0.0465],\n",
      "          [ 0.0543,  0.0408, -0.0427]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0343, -0.0577,  0.0050],\n",
      "          [-0.0396,  0.0498, -0.0328],\n",
      "          [ 0.0370, -0.0049, -0.0049]],\n",
      "\n",
      "         [[ 0.0392, -0.0364,  0.0226],\n",
      "          [-0.0650, -0.0518, -0.0510],\n",
      "          [ 0.0157, -0.0360,  0.0518]],\n",
      "\n",
      "         [[ 0.0384,  0.0103, -0.0239],\n",
      "          [ 0.0052, -0.0605,  0.0445],\n",
      "          [-0.0035,  0.0353, -0.0381]]],\n",
      "\n",
      "\n",
      "        [[[-0.0260,  0.0318, -0.0106],\n",
      "          [ 0.0407, -0.0439,  0.0371],\n",
      "          [ 0.0231,  0.0327, -0.0153]],\n",
      "\n",
      "         [[ 0.0539,  0.0420,  0.0210],\n",
      "          [ 0.0442, -0.0088, -0.0229],\n",
      "          [-0.0478,  0.0026,  0.0404]],\n",
      "\n",
      "         [[ 0.0539, -0.0136, -0.0325],\n",
      "          [-0.0320, -0.0074,  0.0147],\n",
      "          [ 0.0434, -0.0160,  0.0223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0292,  0.0178,  0.0343],\n",
      "          [-0.0525, -0.0259, -0.0436],\n",
      "          [-0.0061, -0.0572,  0.0291]],\n",
      "\n",
      "         [[-0.0080, -0.0360, -0.0163],\n",
      "          [ 0.0478,  0.0397,  0.0005],\n",
      "          [ 0.0293, -0.0147, -0.0419]],\n",
      "\n",
      "         [[-0.0098, -0.0265,  0.0353],\n",
      "          [-0.0546, -0.0492,  0.0061],\n",
      "          [-0.0380,  0.0211,  0.0373]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0155, -0.0184,  0.0118],\n",
      "          [ 0.0088,  0.0368,  0.0183],\n",
      "          [-0.0523, -0.0200, -0.0373]],\n",
      "\n",
      "         [[-0.0508,  0.0564,  0.0620],\n",
      "          [-0.0352,  0.0251, -0.0195],\n",
      "          [ 0.0030, -0.0584, -0.0517]],\n",
      "\n",
      "         [[ 0.0154, -0.0324,  0.0400],\n",
      "          [ 0.0763,  0.0758,  0.0504],\n",
      "          [-0.0615, -0.0483, -0.0145]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0142, -0.0155,  0.0048],\n",
      "          [ 0.0571, -0.0555,  0.0533],\n",
      "          [ 0.0295, -0.0398,  0.0083]],\n",
      "\n",
      "         [[-0.0112, -0.0553, -0.0395],\n",
      "          [-0.0356,  0.0059, -0.0025],\n",
      "          [ 0.0541,  0.0619, -0.0074]],\n",
      "\n",
      "         [[-0.0119, -0.0051,  0.0251],\n",
      "          [-0.0252, -0.0240,  0.0253],\n",
      "          [ 0.0190,  0.0177, -0.0016]]],\n",
      "\n",
      "\n",
      "        [[[-0.0485,  0.0303,  0.0239],\n",
      "          [ 0.0189, -0.0535,  0.0384],\n",
      "          [-0.0438, -0.0276,  0.0285]],\n",
      "\n",
      "         [[ 0.0239, -0.0581,  0.0102],\n",
      "          [-0.0272,  0.0310, -0.0070],\n",
      "          [ 0.0291,  0.0180,  0.0168]],\n",
      "\n",
      "         [[-0.0026, -0.0381, -0.0488],\n",
      "          [ 0.0753,  0.0444,  0.0204],\n",
      "          [ 0.0047, -0.0480,  0.0006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0033,  0.0286, -0.0197],\n",
      "          [-0.0411,  0.0103,  0.0523],\n",
      "          [-0.0356,  0.0224, -0.0430]],\n",
      "\n",
      "         [[-0.0525, -0.0197,  0.0699],\n",
      "          [-0.0625,  0.0108,  0.0350],\n",
      "          [-0.0172,  0.0392, -0.0012]],\n",
      "\n",
      "         [[ 0.0440,  0.0135, -0.0097],\n",
      "          [-0.0640, -0.0260,  0.0479],\n",
      "          [ 0.0040,  0.0042,  0.0026]]],\n",
      "\n",
      "\n",
      "        [[[-0.0238, -0.0411,  0.0261],\n",
      "          [-0.0092, -0.0226, -0.0219],\n",
      "          [ 0.0478,  0.0170, -0.0426]],\n",
      "\n",
      "         [[-0.0203, -0.0118, -0.0059],\n",
      "          [-0.0177,  0.0358, -0.0325],\n",
      "          [-0.0080,  0.0397, -0.0398]],\n",
      "\n",
      "         [[ 0.0475,  0.0379,  0.0582],\n",
      "          [-0.0269,  0.0617,  0.0221],\n",
      "          [-0.0464, -0.0715,  0.0116]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0288, -0.0444, -0.0280],\n",
      "          [-0.0380, -0.0002,  0.0414],\n",
      "          [ 0.0460,  0.0234, -0.0475]],\n",
      "\n",
      "         [[-0.0300, -0.0650,  0.0046],\n",
      "          [-0.0293,  0.0464, -0.0066],\n",
      "          [ 0.0512, -0.0075,  0.0271]],\n",
      "\n",
      "         [[ 0.0451,  0.0486, -0.0561],\n",
      "          [-0.0100,  0.0136,  0.0456],\n",
      "          [ 0.0208,  0.0219,  0.0323]]]])\n",
      "activation_stack.2.bias: tensor([ 0.0040,  0.0372,  0.0623, -0.0671,  0.0154,  0.0425, -0.0256,  0.0519,\n",
      "         0.0260, -0.0822, -0.0031,  0.0558, -0.0224, -0.0248,  0.0592,  0.0395,\n",
      "         0.0530,  0.0264, -0.0424,  0.0523,  0.0050,  0.0223, -0.0512, -0.0341,\n",
      "         0.0196, -0.0417,  0.0387,  0.0142,  0.0431,  0.0372, -0.0074,  0.0090,\n",
      "         0.0045, -0.0061,  0.0471, -0.0545,  0.0254, -0.0309, -0.0327,  0.0233,\n",
      "        -0.0409,  0.0363,  0.0375, -0.0344,  0.0396,  0.0176, -0.0503,  0.0258,\n",
      "         0.0571, -0.0181,  0.0479,  0.0125,  0.0516,  0.0103, -0.0069,  0.0826,\n",
      "         0.0040, -0.0320, -0.0108, -0.0732,  0.0037,  0.0522, -0.0177,  0.0526])\n",
      "activation_stack.5.weight: tensor([0.9976, 1.0095, 0.9984, 0.9923, 0.9970, 1.0036, 1.0017, 1.0117, 0.9788,\n",
      "        0.9956, 1.0073, 1.0068, 0.9864, 0.9974, 0.9845, 0.9922, 1.0072, 1.0047,\n",
      "        1.0077, 1.0155, 1.0156, 1.0095, 0.9929, 0.9966, 0.9978, 1.0055, 0.9872,\n",
      "        1.0096, 1.0087, 0.9957, 1.0074, 0.9981, 0.9948, 0.9985, 1.0170, 0.9890,\n",
      "        1.0123, 0.9976, 0.9921, 0.9954, 0.9929, 1.0170, 1.0022, 0.9897, 1.0200,\n",
      "        0.9846, 0.9926, 1.0041, 1.0002, 0.9862, 1.0060, 1.0051, 0.9880, 1.0023,\n",
      "        0.9951, 0.9915, 1.0078, 0.9799, 1.0098, 0.9792, 1.0116, 1.0024, 0.9985,\n",
      "        1.0161])\n",
      "activation_stack.5.bias: tensor([ 2.8136e-03,  2.4970e-03,  2.6590e-03, -9.3012e-03,  1.0185e-02,\n",
      "         4.3680e-03, -5.9981e-03,  5.0150e-03, -7.1715e-03, -9.3758e-03,\n",
      "        -4.9033e-04,  5.4427e-03, -5.3280e-03, -4.1940e-03,  7.3358e-03,\n",
      "        -3.1770e-03, -3.3435e-03,  1.0018e-02,  3.6945e-03,  1.0114e-02,\n",
      "         1.1414e-02,  2.7923e-03,  7.8682e-03,  5.9942e-03,  2.0309e-03,\n",
      "         6.5865e-03, -3.9874e-03, -8.5251e-03,  1.8466e-03,  1.2899e-02,\n",
      "         5.6843e-03,  6.9795e-03,  7.0382e-03, -2.5500e-03,  1.3267e-02,\n",
      "        -9.3272e-03,  6.0074e-03, -5.6938e-04, -2.5425e-03,  9.0654e-03,\n",
      "        -1.9427e-03,  5.2856e-03,  1.0179e-02,  3.8257e-03,  8.7173e-03,\n",
      "         3.6731e-03, -4.1319e-03,  1.0386e-02, -7.8956e-04, -5.4900e-03,\n",
      "         4.0294e-03,  7.2929e-03, -6.0194e-03, -1.5470e-03,  9.5026e-03,\n",
      "         5.1569e-03,  3.8287e-05,  1.2089e-04,  9.9627e-03, -8.2956e-03,\n",
      "         4.8802e-05,  6.7912e-03,  8.6420e-03,  4.7633e-03])\n",
      "activation_stack.6.weight: tensor([[[[-0.0278, -0.0034, -0.0121],\n",
      "          [ 0.0093,  0.0274,  0.0115],\n",
      "          [ 0.0238,  0.0023,  0.0072]],\n",
      "\n",
      "         [[-0.0163, -0.0229,  0.0030],\n",
      "          [ 0.0249, -0.0245, -0.0128],\n",
      "          [-0.0289,  0.0185,  0.0354]],\n",
      "\n",
      "         [[ 0.0382,  0.0107, -0.0063],\n",
      "          [ 0.0182,  0.0028,  0.0428],\n",
      "          [-0.0121,  0.0153, -0.0255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0330,  0.0323,  0.0167],\n",
      "          [-0.0104, -0.0170, -0.0330],\n",
      "          [ 0.0014, -0.0344,  0.0423]],\n",
      "\n",
      "         [[ 0.0212, -0.0118,  0.0233],\n",
      "          [-0.0041, -0.0141, -0.0330],\n",
      "          [-0.0329,  0.0274,  0.0349]],\n",
      "\n",
      "         [[ 0.0119,  0.0401,  0.0156],\n",
      "          [-0.0265,  0.0012, -0.0031],\n",
      "          [ 0.0334,  0.0006,  0.0325]]],\n",
      "\n",
      "\n",
      "        [[[-0.0384,  0.0149,  0.0149],\n",
      "          [ 0.0366, -0.0352, -0.0198],\n",
      "          [ 0.0264,  0.0013, -0.0154]],\n",
      "\n",
      "         [[-0.0317, -0.0238, -0.0314],\n",
      "          [ 0.0067,  0.0143, -0.0067],\n",
      "          [ 0.0326, -0.0325, -0.0344]],\n",
      "\n",
      "         [[ 0.0317,  0.0126,  0.0332],\n",
      "          [ 0.0167,  0.0383, -0.0326],\n",
      "          [ 0.0234,  0.0232,  0.0413]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0153,  0.0322, -0.0359],\n",
      "          [ 0.0186, -0.0070, -0.0077],\n",
      "          [ 0.0224, -0.0241, -0.0064]],\n",
      "\n",
      "         [[ 0.0101, -0.0169, -0.0211],\n",
      "          [ 0.0224,  0.0377,  0.0346],\n",
      "          [-0.0249, -0.0437,  0.0312]],\n",
      "\n",
      "         [[-0.0041, -0.0391,  0.0152],\n",
      "          [-0.0093, -0.0303,  0.0197],\n",
      "          [ 0.0030,  0.0303, -0.0048]]],\n",
      "\n",
      "\n",
      "        [[[-0.0311,  0.0064, -0.0163],\n",
      "          [-0.0265, -0.0092,  0.0219],\n",
      "          [ 0.0012,  0.0300,  0.0106]],\n",
      "\n",
      "         [[-0.0067,  0.0342, -0.0130],\n",
      "          [ 0.0472,  0.0117,  0.0221],\n",
      "          [-0.0156, -0.0061, -0.0176]],\n",
      "\n",
      "         [[-0.0390,  0.0084, -0.0171],\n",
      "          [ 0.0371,  0.0020, -0.0141],\n",
      "          [ 0.0006,  0.0409,  0.0177]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0207,  0.0292,  0.0157],\n",
      "          [ 0.0105,  0.0139, -0.0025],\n",
      "          [ 0.0226, -0.0263, -0.0038]],\n",
      "\n",
      "         [[-0.0052,  0.0086, -0.0266],\n",
      "          [ 0.0223, -0.0133,  0.0260],\n",
      "          [-0.0334, -0.0208, -0.0029]],\n",
      "\n",
      "         [[ 0.0281,  0.0405,  0.0038],\n",
      "          [-0.0345,  0.0236,  0.0082],\n",
      "          [ 0.0342,  0.0365, -0.0043]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0327,  0.0273,  0.0153],\n",
      "          [ 0.0069, -0.0096,  0.0200],\n",
      "          [ 0.0138, -0.0162, -0.0321]],\n",
      "\n",
      "         [[ 0.0127,  0.0256,  0.0348],\n",
      "          [ 0.0159,  0.0223,  0.0072],\n",
      "          [-0.0214,  0.0362,  0.0076]],\n",
      "\n",
      "         [[ 0.0362, -0.0062,  0.0086],\n",
      "          [-0.0387, -0.0070,  0.0042],\n",
      "          [-0.0384, -0.0208,  0.0093]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0226,  0.0085, -0.0014],\n",
      "          [ 0.0071,  0.0061,  0.0234],\n",
      "          [-0.0263,  0.0265,  0.0205]],\n",
      "\n",
      "         [[ 0.0101,  0.0345, -0.0258],\n",
      "          [ 0.0030,  0.0116,  0.0220],\n",
      "          [-0.0137,  0.0199, -0.0199]],\n",
      "\n",
      "         [[ 0.0279,  0.0193,  0.0144],\n",
      "          [ 0.0112, -0.0203, -0.0221],\n",
      "          [ 0.0027, -0.0396, -0.0322]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0357,  0.0256, -0.0429],\n",
      "          [-0.0384,  0.0373, -0.0031],\n",
      "          [-0.0375,  0.0014, -0.0330]],\n",
      "\n",
      "         [[-0.0340, -0.0203, -0.0352],\n",
      "          [ 0.0390,  0.0014, -0.0027],\n",
      "          [-0.0325, -0.0152, -0.0110]],\n",
      "\n",
      "         [[ 0.0297,  0.0055,  0.0153],\n",
      "          [-0.0429,  0.0320,  0.0226],\n",
      "          [-0.0383, -0.0379,  0.0005]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0141, -0.0335,  0.0330],\n",
      "          [ 0.0205, -0.0360,  0.0282],\n",
      "          [ 0.0109,  0.0368,  0.0338]],\n",
      "\n",
      "         [[-0.0163, -0.0334,  0.0054],\n",
      "          [-0.0349, -0.0293,  0.0237],\n",
      "          [ 0.0073,  0.0055,  0.0117]],\n",
      "\n",
      "         [[ 0.0088,  0.0285,  0.0264],\n",
      "          [-0.0113, -0.0134, -0.0130],\n",
      "          [-0.0103,  0.0359,  0.0302]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0022,  0.0125,  0.0365],\n",
      "          [ 0.0158, -0.0357,  0.0044],\n",
      "          [-0.0324, -0.0238, -0.0403]],\n",
      "\n",
      "         [[-0.0349, -0.0261,  0.0067],\n",
      "          [-0.0268,  0.0190, -0.0173],\n",
      "          [-0.0188, -0.0384, -0.0308]],\n",
      "\n",
      "         [[ 0.0268,  0.0293,  0.0246],\n",
      "          [-0.0003, -0.0335, -0.0047],\n",
      "          [-0.0282, -0.0247,  0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0384, -0.0069,  0.0341],\n",
      "          [ 0.0172,  0.0207,  0.0240],\n",
      "          [ 0.0069, -0.0231,  0.0263]],\n",
      "\n",
      "         [[-0.0115,  0.0236,  0.0332],\n",
      "          [ 0.0185, -0.0067, -0.0204],\n",
      "          [ 0.0120,  0.0052, -0.0099]],\n",
      "\n",
      "         [[ 0.0164,  0.0322,  0.0277],\n",
      "          [-0.0223, -0.0016,  0.0008],\n",
      "          [ 0.0246,  0.0028, -0.0280]]]])\n",
      "activation_stack.6.bias: tensor([ 0.0389, -0.0210, -0.0165, -0.0167,  0.0191, -0.0431,  0.0206,  0.0402,\n",
      "        -0.0339, -0.0299,  0.0202, -0.0115,  0.0252,  0.0088, -0.0064, -0.0006,\n",
      "        -0.0297, -0.0311,  0.0128,  0.0059,  0.0377,  0.0391, -0.0019,  0.0124,\n",
      "        -0.0386, -0.0268, -0.0328,  0.0012,  0.0189, -0.0131,  0.0280, -0.0069,\n",
      "        -0.0209, -0.0392,  0.0116, -0.0097, -0.0233, -0.0332, -0.0315, -0.0285,\n",
      "        -0.0092,  0.0260,  0.0257,  0.0035,  0.0285,  0.0073,  0.0059,  0.0251,\n",
      "         0.0179, -0.0204,  0.0214,  0.0207, -0.0079, -0.0029, -0.0287,  0.0053,\n",
      "        -0.0071,  0.0074, -0.0304,  0.0163,  0.0041,  0.0360, -0.0354, -0.0400,\n",
      "        -0.0292, -0.0377, -0.0123, -0.0230,  0.0085,  0.0049,  0.0199,  0.0255,\n",
      "        -0.0015, -0.0299,  0.0183,  0.0380, -0.0223, -0.0309,  0.0050, -0.0338,\n",
      "        -0.0107,  0.0130, -0.0272,  0.0138, -0.0470,  0.0203, -0.0272, -0.0037,\n",
      "         0.0385, -0.0261, -0.0414, -0.0123, -0.0185,  0.0393,  0.0213, -0.0297,\n",
      "        -0.0175,  0.0061, -0.0185, -0.0184,  0.0317, -0.0162,  0.0293,  0.0329,\n",
      "         0.0106, -0.0038, -0.0211, -0.0064, -0.0067, -0.0432, -0.0410, -0.0029,\n",
      "        -0.0148,  0.0118, -0.0161, -0.0407, -0.0056,  0.0020, -0.0195,  0.0378,\n",
      "         0.0313,  0.0109, -0.0332,  0.0065,  0.0340, -0.0226, -0.0460,  0.0222])\n",
      "activation_stack.8.weight: tensor([[[[ 2.2364e-02, -1.6628e-02, -1.9065e-02],\n",
      "          [ 1.5833e-02,  2.9554e-03, -3.6410e-03],\n",
      "          [ 1.4493e-02, -3.3194e-02,  9.8748e-04]],\n",
      "\n",
      "         [[ 1.4574e-03, -2.6407e-02, -9.1914e-04],\n",
      "          [-6.5125e-03, -2.1889e-02, -6.6579e-03],\n",
      "          [-2.9238e-02,  1.1502e-02, -9.6368e-03]],\n",
      "\n",
      "         [[-2.4404e-02,  7.4904e-04,  1.8979e-02],\n",
      "          [ 7.5792e-03, -5.7611e-03,  1.4142e-03],\n",
      "          [ 3.3719e-02, -2.3053e-02, -8.9556e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8658e-02,  1.7703e-02, -1.3224e-02],\n",
      "          [ 3.4617e-02,  2.8098e-02,  5.7580e-03],\n",
      "          [-7.8039e-03,  6.4276e-03, -2.9548e-02]],\n",
      "\n",
      "         [[ 2.4384e-02,  3.8740e-03,  1.5497e-02],\n",
      "          [-1.6034e-02, -2.1751e-02, -2.3679e-02],\n",
      "          [ 1.6441e-02, -1.5355e-02, -1.8257e-02]],\n",
      "\n",
      "         [[-1.1805e-02, -1.1982e-02,  8.9103e-03],\n",
      "          [ 2.4280e-04,  1.3104e-02,  3.0850e-03],\n",
      "          [ 2.4082e-02, -7.7162e-03, -2.5040e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.9045e-02,  1.7520e-02, -2.6591e-02],\n",
      "          [ 6.8427e-03, -1.0296e-02, -3.1560e-02],\n",
      "          [-2.7619e-02, -1.2069e-02, -2.2542e-02]],\n",
      "\n",
      "         [[ 2.1968e-02, -2.4912e-02,  2.4218e-02],\n",
      "          [ 1.8812e-02,  2.4029e-02, -2.3887e-02],\n",
      "          [ 1.9282e-02, -2.1107e-02,  3.8928e-03]],\n",
      "\n",
      "         [[ 7.2780e-03,  2.5982e-02,  3.2438e-03],\n",
      "          [ 2.2286e-02, -2.8038e-02,  1.1479e-02],\n",
      "          [ 1.6699e-02, -2.2610e-05,  8.1993e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9541e-02, -2.0088e-02, -6.0226e-03],\n",
      "          [ 1.8530e-02,  1.1012e-03,  9.9825e-03],\n",
      "          [-1.1514e-02, -8.6680e-03,  2.8165e-02]],\n",
      "\n",
      "         [[ 6.1220e-03, -1.2564e-02, -2.1102e-02],\n",
      "          [ 2.1499e-02, -9.6668e-03, -2.4855e-02],\n",
      "          [-2.6298e-02,  5.9973e-03, -7.3588e-03]],\n",
      "\n",
      "         [[-2.7148e-02,  1.2603e-02,  7.9523e-03],\n",
      "          [ 2.5398e-02,  1.3659e-02, -1.3529e-02],\n",
      "          [ 1.8026e-03,  2.3279e-02,  2.1720e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6797e-02,  2.2349e-02,  2.6568e-02],\n",
      "          [-1.5352e-02, -1.1723e-02,  1.1470e-02],\n",
      "          [-7.0692e-03,  1.1239e-02,  1.1112e-02]],\n",
      "\n",
      "         [[ 1.9065e-02, -4.7910e-03,  6.2213e-03],\n",
      "          [-1.9999e-02, -2.3894e-02,  2.0885e-02],\n",
      "          [-2.6325e-02, -1.9754e-02, -2.2844e-03]],\n",
      "\n",
      "         [[-1.0222e-02,  2.4695e-02,  1.5024e-02],\n",
      "          [ 7.8541e-03, -2.4080e-02,  1.9647e-02],\n",
      "          [-1.9898e-02,  7.5103e-03, -2.8183e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3555e-02, -1.5104e-02,  2.8592e-02],\n",
      "          [-1.6932e-02, -1.0900e-02,  1.9591e-02],\n",
      "          [-8.7703e-03, -2.0055e-02,  1.9893e-03]],\n",
      "\n",
      "         [[-6.6756e-03,  8.7769e-03, -1.4497e-03],\n",
      "          [-6.5215e-03, -1.3211e-02,  1.7902e-02],\n",
      "          [-2.5698e-02, -2.1670e-02, -6.4229e-03]],\n",
      "\n",
      "         [[ 1.1253e-03,  2.2813e-02,  3.2262e-02],\n",
      "          [-2.8184e-02, -2.0664e-02, -1.2467e-02],\n",
      "          [-2.3929e-02, -1.6528e-02, -2.6597e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.4303e-02, -2.8004e-02, -1.7803e-02],\n",
      "          [-2.5352e-02, -2.2323e-02, -3.1068e-02],\n",
      "          [ 1.1790e-02, -2.5636e-02, -1.8440e-03]],\n",
      "\n",
      "         [[-2.8533e-02,  2.5355e-02,  1.6650e-02],\n",
      "          [-1.5369e-02,  2.6215e-02,  1.2789e-02],\n",
      "          [ 5.8186e-03, -2.0326e-02,  2.0173e-02]],\n",
      "\n",
      "         [[-5.2917e-03, -1.4038e-02, -2.5240e-02],\n",
      "          [-1.9807e-02,  6.0532e-03,  1.4346e-02],\n",
      "          [ 1.5027e-02,  7.7022e-03,  2.0540e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9583e-03,  2.0412e-02, -2.1713e-02],\n",
      "          [-1.8866e-02, -4.6882e-03,  2.8068e-02],\n",
      "          [-1.1347e-02,  1.9275e-02,  7.5739e-03]],\n",
      "\n",
      "         [[ 1.1936e-02, -1.4201e-02,  6.0194e-03],\n",
      "          [ 5.0319e-03, -2.3352e-02, -5.1016e-03],\n",
      "          [ 1.2398e-03,  1.0621e-02,  2.9848e-02]],\n",
      "\n",
      "         [[-9.7572e-03, -5.2504e-03, -1.6027e-03],\n",
      "          [ 5.9249e-04,  2.8427e-02,  5.1157e-03],\n",
      "          [-2.3469e-02,  2.6124e-02,  3.5955e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8885e-02,  3.0565e-02, -1.0259e-02],\n",
      "          [ 1.6231e-02,  1.2472e-02,  1.0726e-02],\n",
      "          [-6.9926e-03,  9.7496e-03, -2.8024e-02]],\n",
      "\n",
      "         [[-7.0192e-03, -2.6887e-02, -2.2315e-02],\n",
      "          [ 1.2022e-02,  1.8563e-02,  9.0261e-04],\n",
      "          [-2.3429e-02,  1.6060e-02, -2.0802e-02]],\n",
      "\n",
      "         [[-1.6597e-02, -3.0103e-02,  3.9080e-03],\n",
      "          [-2.4052e-02,  1.0882e-02, -3.0131e-02],\n",
      "          [ 1.5141e-02,  8.3327e-03, -7.2769e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7667e-03,  2.1292e-02, -5.4508e-03],\n",
      "          [ 2.5086e-02, -2.5532e-02, -2.1199e-02],\n",
      "          [-2.6597e-04,  1.6074e-02,  1.4113e-02]],\n",
      "\n",
      "         [[ 1.7412e-02,  2.2933e-02, -6.0877e-03],\n",
      "          [-1.7252e-02,  2.7292e-04, -4.3396e-03],\n",
      "          [ 2.1335e-02, -3.2450e-02, -8.9552e-03]],\n",
      "\n",
      "         [[ 2.0016e-05,  1.1828e-02, -3.1318e-03],\n",
      "          [-1.7956e-02, -2.3819e-02,  1.4129e-02],\n",
      "          [-8.7092e-03, -1.3784e-02, -2.8813e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1383e-02,  2.6202e-02,  1.7981e-02],\n",
      "          [ 2.4772e-02, -2.4279e-02, -3.4551e-02],\n",
      "          [ 9.7468e-03, -8.4752e-03,  1.6793e-02]],\n",
      "\n",
      "         [[-2.9793e-02,  2.4440e-02, -2.3372e-02],\n",
      "          [-3.3102e-02, -2.8815e-02,  1.2666e-02],\n",
      "          [-2.1198e-02,  1.0572e-02,  8.6029e-03]],\n",
      "\n",
      "         [[ 2.9554e-02,  1.3095e-03,  1.1481e-02],\n",
      "          [-1.0593e-02,  1.5461e-03,  1.6701e-02],\n",
      "          [ 3.6150e-03, -2.2925e-02, -3.1203e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.2171e-03, -1.0670e-02, -1.2642e-02],\n",
      "          [ 1.5511e-02,  1.0259e-03, -6.6614e-04],\n",
      "          [ 2.3075e-02,  4.9572e-03, -1.8626e-02]],\n",
      "\n",
      "         [[-2.1646e-03,  2.1652e-02,  2.6908e-02],\n",
      "          [-1.3050e-02, -1.1164e-02,  2.1036e-02],\n",
      "          [-1.5643e-02, -1.1309e-02,  8.5007e-04]],\n",
      "\n",
      "         [[ 1.6735e-02, -2.9632e-02,  1.3973e-03],\n",
      "          [ 4.6064e-03, -6.9257e-03, -6.9430e-04],\n",
      "          [ 3.2465e-02,  3.1962e-03, -1.6320e-02]]]])\n",
      "activation_stack.8.bias: tensor([-0.0149,  0.0052,  0.0051,  0.0195, -0.0046, -0.0180, -0.0087, -0.0261,\n",
      "        -0.0088,  0.0218, -0.0195, -0.0111,  0.0108, -0.0207,  0.0319,  0.0124,\n",
      "        -0.0273,  0.0205, -0.0101,  0.0149,  0.0286, -0.0090, -0.0133, -0.0250,\n",
      "        -0.0026, -0.0307, -0.0261, -0.0286,  0.0167, -0.0238, -0.0054, -0.0155,\n",
      "         0.0130, -0.0125, -0.0095, -0.0076, -0.0028, -0.0129, -0.0182, -0.0171,\n",
      "         0.0149, -0.0059,  0.0155, -0.0337, -0.0223, -0.0152,  0.0299,  0.0167,\n",
      "        -0.0283, -0.0251, -0.0222, -0.0237, -0.0374,  0.0244, -0.0302,  0.0019,\n",
      "        -0.0147,  0.0068, -0.0169,  0.0054, -0.0182,  0.0358,  0.0028, -0.0014,\n",
      "        -0.0305,  0.0200, -0.0264,  0.0029,  0.0167,  0.0014, -0.0212,  0.0210,\n",
      "        -0.0118,  0.0140, -0.0092,  0.0225,  0.0232, -0.0288, -0.0020, -0.0080,\n",
      "         0.0005, -0.0189,  0.0093, -0.0239,  0.0122, -0.0235,  0.0326,  0.0112,\n",
      "         0.0100,  0.0088, -0.0014,  0.0177,  0.0081,  0.0024, -0.0226, -0.0177,\n",
      "         0.0132, -0.0098, -0.0294,  0.0078,  0.0033, -0.0123, -0.0075,  0.0054,\n",
      "        -0.0197, -0.0197,  0.0122,  0.0019, -0.0177, -0.0207, -0.0045,  0.0194,\n",
      "         0.0092, -0.0246, -0.0103, -0.0258,  0.0107, -0.0385,  0.0251,  0.0288,\n",
      "        -0.0177, -0.0030, -0.0045, -0.0176,  0.0084,  0.0198, -0.0099, -0.0246])\n",
      "activation_stack.11.weight: tensor([1.0096, 0.9977, 1.0030, 1.0016, 1.0061, 1.0043, 0.9991, 0.9921, 0.9954,\n",
      "        0.9955, 0.9958, 1.0038, 0.9946, 0.9972, 1.0095, 0.9971, 1.0003, 0.9987,\n",
      "        0.9985, 0.9949, 1.0027, 1.0050, 0.9878, 0.9922, 1.0002, 0.9920, 0.9957,\n",
      "        1.0027, 0.9978, 1.0031, 0.9991, 0.9945, 1.0024, 0.9980, 1.0063, 1.0130,\n",
      "        0.9994, 0.9914, 1.0113, 0.9985, 1.0000, 1.0012, 0.9901, 1.0028, 1.0041,\n",
      "        0.9935, 1.0015, 0.9943, 1.0000, 0.9987, 0.9960, 0.9939, 0.9999, 0.9966,\n",
      "        0.9894, 0.9988, 0.9971, 1.0011, 1.0173, 1.0084, 0.9972, 1.0092, 1.0011,\n",
      "        1.0053, 0.9898, 1.0112, 0.9940, 0.9964, 1.0028, 1.0043, 1.0062, 1.0016,\n",
      "        0.9973, 1.0000, 1.0012, 0.9964, 0.9981, 0.9997, 0.9941, 0.9939, 0.9947,\n",
      "        1.0019, 0.9983, 0.9902, 1.0129, 1.0090, 0.9999, 0.9961, 1.0033, 1.0024,\n",
      "        0.9951, 1.0008, 0.9963, 0.9979, 1.0013, 1.0025, 1.0022, 0.9968, 0.9975,\n",
      "        1.0000, 0.9971, 0.9984, 1.0017, 0.9913, 0.9961, 1.0116, 1.0015, 1.0043,\n",
      "        0.9977, 1.0102, 1.0044, 1.0020, 1.0024, 1.0002, 1.0003, 1.0091, 1.0064,\n",
      "        1.0001, 0.9985, 0.9993, 0.9929, 0.9963, 0.9993, 1.0025, 1.0004, 1.0097,\n",
      "        0.9983, 1.0093])\n",
      "activation_stack.11.bias: tensor([ 3.0869e-04,  1.5052e-03, -4.9895e-04, -6.6039e-04, -2.1404e-03,\n",
      "        -3.0344e-03, -6.1405e-04,  6.6321e-03, -4.2809e-04,  2.6244e-03,\n",
      "         6.0920e-04,  2.9371e-03,  1.1023e-03,  5.0236e-03,  1.0170e-03,\n",
      "         3.9370e-03, -7.2648e-04, -2.3501e-03, -2.3214e-03,  3.8000e-03,\n",
      "         1.9212e-03,  9.4303e-04, -4.7006e-03, -2.0617e-03, -4.0395e-05,\n",
      "         5.6679e-04,  1.0379e-03,  2.8895e-03,  3.3081e-03,  8.5221e-04,\n",
      "        -6.6970e-04,  2.4021e-04,  3.8641e-03,  1.1923e-03, -1.0559e-03,\n",
      "         4.5917e-03,  3.7010e-03, -2.7919e-03,  3.8746e-03,  1.7123e-03,\n",
      "         4.0398e-03,  5.1261e-03,  7.4826e-03,  2.4148e-05, -4.1061e-03,\n",
      "        -3.7155e-03,  3.2740e-03, -6.5996e-03, -7.4219e-04, -1.2472e-03,\n",
      "         1.2196e-04,  4.7770e-03, -6.1068e-05,  3.8642e-03,  1.9870e-04,\n",
      "         4.8855e-03,  2.5227e-03, -3.5363e-04,  3.5411e-03, -2.8081e-03,\n",
      "         1.5649e-03,  1.1848e-03, -1.4562e-03, -1.2577e-03,  3.3810e-04,\n",
      "         1.2387e-03, -4.0827e-04,  2.9209e-03,  1.3798e-03,  1.3146e-03,\n",
      "        -1.3357e-03,  2.9080e-03,  3.6726e-03, -5.2291e-03,  1.1718e-03,\n",
      "         5.7159e-03, -1.7063e-03,  1.7757e-03, -7.9482e-04,  2.6014e-03,\n",
      "        -4.0851e-03,  3.9536e-03,  1.5056e-03, -1.8123e-04,  7.5828e-04,\n",
      "         1.6754e-03, -1.4252e-03, -2.2710e-03,  3.6727e-04,  5.5374e-04,\n",
      "         2.7361e-03,  2.1874e-03, -1.3032e-04,  1.5218e-03, -1.1538e-03,\n",
      "        -5.8582e-04, -1.3906e-03, -1.2579e-03,  1.8085e-03,  1.5609e-03,\n",
      "         3.6620e-04,  5.7164e-03, -1.5660e-03, -3.8783e-03,  4.0674e-03,\n",
      "         2.2051e-03,  4.1542e-03, -2.8159e-03,  5.7696e-03,  4.6720e-05,\n",
      "         4.6633e-04,  6.0205e-03,  1.0001e-03,  3.6930e-03,  3.0553e-03,\n",
      "        -4.7815e-05, -4.3048e-03, -2.7139e-03,  3.4454e-03,  1.0694e-03,\n",
      "         8.5785e-03, -1.3555e-03,  7.0282e-03,  2.8811e-03, -1.5106e-03,\n",
      "         2.7782e-03,  2.9983e-03,  1.2196e-04])\n",
      "activation_stack.12.weight: tensor([[[[ 1.5356e-02,  2.6153e-02,  1.2916e-02],\n",
      "          [-8.0969e-03,  2.7707e-02,  2.2727e-02],\n",
      "          [ 1.6666e-02,  2.6862e-03,  2.5562e-02]],\n",
      "\n",
      "         [[ 6.5008e-03,  2.5879e-02,  1.6520e-03],\n",
      "          [ 1.9749e-02,  2.6255e-03, -2.0263e-02],\n",
      "          [ 2.0238e-02, -2.6604e-02, -2.1236e-02]],\n",
      "\n",
      "         [[ 1.5546e-03, -2.4377e-02, -1.1066e-02],\n",
      "          [-3.5261e-03,  2.4537e-02, -1.6202e-02],\n",
      "          [-2.2985e-02,  2.2299e-02, -2.5791e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6761e-02, -1.5457e-02, -8.0088e-03],\n",
      "          [ 1.7755e-02,  1.4327e-02, -2.1237e-03],\n",
      "          [ 2.3811e-02,  9.7949e-04, -2.3580e-02]],\n",
      "\n",
      "         [[ 8.8570e-03,  1.7293e-02,  2.5383e-02],\n",
      "          [ 8.1659e-03, -2.5804e-02, -5.0577e-03],\n",
      "          [ 1.2375e-02, -1.0034e-02, -1.5587e-02]],\n",
      "\n",
      "         [[ 3.3625e-03,  2.9385e-02, -9.0452e-03],\n",
      "          [-1.0148e-02,  1.8314e-02, -7.3517e-03],\n",
      "          [-5.1779e-03,  3.0213e-02, -2.3430e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1866e-03,  2.0208e-02,  2.6993e-02],\n",
      "          [-4.4988e-03,  6.7700e-03, -5.2202e-03],\n",
      "          [ 6.2744e-03,  5.5577e-03,  2.0992e-02]],\n",
      "\n",
      "         [[-2.4805e-02, -1.6562e-03, -2.8618e-02],\n",
      "          [ 1.0221e-02,  1.9725e-02, -2.4028e-02],\n",
      "          [ 3.3313e-03, -6.8082e-03,  1.5700e-02]],\n",
      "\n",
      "         [[-2.0586e-02,  1.2573e-02, -2.4751e-02],\n",
      "          [-6.2768e-03,  2.9819e-03, -2.6791e-02],\n",
      "          [-2.3519e-02, -2.7299e-04,  1.6997e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9077e-02,  5.4181e-03,  1.9580e-02],\n",
      "          [-2.8318e-02, -1.5258e-02,  2.6432e-02],\n",
      "          [-6.2302e-03,  2.1720e-02,  1.5807e-02]],\n",
      "\n",
      "         [[-7.9006e-03, -2.4612e-02,  2.8578e-02],\n",
      "          [ 2.0564e-02,  3.0118e-03,  2.6439e-02],\n",
      "          [ 1.9728e-02,  3.8046e-03,  2.8366e-02]],\n",
      "\n",
      "         [[-2.0400e-02,  1.2765e-02, -1.6941e-02],\n",
      "          [ 1.5840e-02, -5.5191e-03, -1.7654e-02],\n",
      "          [-6.7903e-03, -9.0109e-03,  1.3905e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1642e-02, -5.1471e-03,  1.4531e-02],\n",
      "          [ 8.8481e-03, -5.2422e-03, -2.9129e-02],\n",
      "          [ 2.6827e-02,  1.8755e-02, -6.4687e-03]],\n",
      "\n",
      "         [[-2.6441e-02,  3.6643e-03,  2.5419e-02],\n",
      "          [-1.0907e-02, -4.4741e-03,  2.0294e-02],\n",
      "          [ 9.6030e-04, -1.0358e-02, -1.4471e-02]],\n",
      "\n",
      "         [[-2.6759e-02, -2.6702e-02, -1.4805e-02],\n",
      "          [-1.0767e-02,  5.8892e-03, -2.0329e-02],\n",
      "          [-1.3278e-02, -2.1351e-02, -8.7946e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1745e-02,  3.0268e-02,  1.3408e-02],\n",
      "          [-1.9017e-02,  3.3401e-03, -8.0594e-03],\n",
      "          [ 1.0011e-02,  2.5120e-03, -2.7250e-02]],\n",
      "\n",
      "         [[ 2.1248e-02, -4.6928e-03, -2.9882e-03],\n",
      "          [-2.9431e-02, -1.5609e-02, -1.7755e-03],\n",
      "          [ 1.6627e-02,  8.7378e-03,  1.8750e-02]],\n",
      "\n",
      "         [[-1.0432e-02, -8.1544e-03,  5.0219e-03],\n",
      "          [ 4.7557e-03,  6.3660e-03, -1.7963e-03],\n",
      "          [ 1.1663e-02, -2.6140e-02,  1.4797e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.4183e-03,  1.4103e-02,  2.5811e-03],\n",
      "          [-1.3925e-02,  1.5204e-02,  3.0921e-03],\n",
      "          [ 2.0754e-02,  1.7337e-03, -2.4704e-04]],\n",
      "\n",
      "         [[-1.6388e-02, -2.1724e-02, -1.7832e-02],\n",
      "          [-2.1765e-02,  2.6915e-02,  2.9956e-02],\n",
      "          [-3.8484e-03,  2.6222e-02, -1.6263e-02]],\n",
      "\n",
      "         [[-4.6018e-03, -2.0959e-02,  1.9730e-02],\n",
      "          [ 1.8176e-02, -2.2351e-02,  1.7974e-02],\n",
      "          [-2.0246e-02,  1.6217e-02,  3.2965e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1344e-02, -1.4291e-02, -1.3248e-02],\n",
      "          [ 2.7759e-03, -2.3962e-02, -4.9935e-03],\n",
      "          [ 6.5716e-03, -3.1387e-02, -2.3942e-02]],\n",
      "\n",
      "         [[ 2.7047e-02,  2.4018e-03, -1.4742e-02],\n",
      "          [ 4.4205e-03,  3.0860e-02, -7.4750e-03],\n",
      "          [ 3.0251e-02, -2.6818e-03,  1.5895e-02]],\n",
      "\n",
      "         [[-1.5946e-02, -7.9016e-03,  2.1191e-03],\n",
      "          [ 1.6309e-03,  9.0299e-03,  2.6167e-02],\n",
      "          [-2.5531e-02,  2.3837e-02,  2.4541e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8720e-02,  1.6094e-02,  5.1925e-04],\n",
      "          [ 1.3768e-02, -1.3744e-02,  2.3130e-02],\n",
      "          [ 4.5627e-03, -5.0942e-03,  2.6470e-02]],\n",
      "\n",
      "         [[ 2.9424e-02, -4.0104e-03,  2.1254e-02],\n",
      "          [ 1.1717e-02,  2.0601e-02, -1.8042e-02],\n",
      "          [-2.1166e-02, -7.3520e-03,  9.7041e-03]],\n",
      "\n",
      "         [[-5.9771e-03, -1.4722e-03,  1.1729e-02],\n",
      "          [ 1.9161e-02, -1.5172e-02, -1.2386e-02],\n",
      "          [ 3.8611e-04, -1.3089e-02,  1.6482e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6288e-03, -2.7201e-02, -8.7782e-03],\n",
      "          [-2.4370e-02, -2.1293e-03,  1.6609e-02],\n",
      "          [ 3.2689e-02,  1.5060e-02, -3.4019e-03]],\n",
      "\n",
      "         [[-2.5043e-03, -1.3832e-02,  1.9571e-02],\n",
      "          [-2.5943e-02,  5.1537e-03, -7.8848e-03],\n",
      "          [ 1.1829e-02, -2.5091e-02, -1.4428e-04]],\n",
      "\n",
      "         [[-2.1772e-02, -2.2151e-03, -1.5151e-02],\n",
      "          [ 1.3420e-03,  1.6901e-02,  1.3014e-02],\n",
      "          [-8.8287e-03, -9.9144e-03, -2.0755e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2169e-02, -3.3871e-03, -1.2594e-02],\n",
      "          [-2.9090e-02, -1.4752e-02, -1.2027e-02],\n",
      "          [ 2.5770e-03, -1.8716e-02, -2.3853e-02]],\n",
      "\n",
      "         [[ 1.3088e-02,  4.9707e-05, -2.7870e-02],\n",
      "          [-2.7210e-02,  1.4960e-02, -1.1314e-02],\n",
      "          [-2.5206e-02, -1.5002e-02, -6.8759e-03]],\n",
      "\n",
      "         [[ 1.3175e-02,  2.3548e-02,  1.6953e-02],\n",
      "          [-2.9311e-02,  2.1840e-02, -2.8913e-03],\n",
      "          [ 7.0261e-03,  1.5659e-02,  5.1183e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1544e-02, -2.1153e-03, -1.3003e-03],\n",
      "          [ 2.6636e-02, -2.5282e-02,  1.0416e-02],\n",
      "          [-2.7934e-02, -6.7045e-03,  1.7344e-02]],\n",
      "\n",
      "         [[ 3.7690e-03,  1.2472e-02, -8.8409e-03],\n",
      "          [ 1.6693e-02, -2.8907e-02, -8.4712e-03],\n",
      "          [ 6.1439e-03, -1.0669e-02,  2.0164e-02]],\n",
      "\n",
      "         [[ 2.0220e-02, -1.2147e-02, -9.0916e-03],\n",
      "          [-1.5480e-03, -2.5470e-03,  1.4141e-02],\n",
      "          [ 1.0934e-02, -1.8283e-03,  2.1638e-02]]]])\n",
      "activation_stack.12.bias: tensor([ 7.7177e-03,  1.4513e-02, -1.0390e-02, -9.7252e-05,  7.0207e-03,\n",
      "         1.2815e-02,  5.0010e-03,  2.8318e-02, -9.6734e-03,  1.6047e-02,\n",
      "        -1.5684e-02,  3.8116e-03, -1.9801e-02,  9.3654e-03, -2.7046e-02,\n",
      "        -2.5833e-02,  7.0776e-03, -2.7712e-03,  3.8241e-04, -6.8504e-03,\n",
      "        -5.6681e-03, -2.4450e-02,  2.2832e-02, -2.0991e-02, -1.3590e-02,\n",
      "         1.5120e-02,  9.3033e-03,  1.6050e-02,  1.9457e-02, -8.0276e-03,\n",
      "        -8.9544e-03, -2.5330e-02,  1.5097e-02, -2.1235e-02, -1.5698e-02,\n",
      "        -4.0533e-03, -1.0853e-02, -1.6905e-02,  9.5657e-03, -1.6670e-02,\n",
      "        -1.4094e-02,  4.3977e-03,  3.0179e-04,  1.0656e-02, -1.6798e-02,\n",
      "         7.0592e-03,  1.6091e-02,  6.1413e-03, -1.1895e-02,  9.7567e-03,\n",
      "        -2.3912e-02, -2.3275e-02,  2.8247e-02,  1.8732e-02, -8.6653e-03,\n",
      "         2.0277e-02,  2.0233e-02, -1.1023e-02, -2.0607e-02, -1.5322e-02,\n",
      "        -9.0008e-03, -2.1404e-03, -2.8462e-02,  2.4704e-02,  8.2567e-03,\n",
      "        -1.3771e-02,  2.2941e-02, -1.0248e-03,  1.2990e-02,  4.9031e-03,\n",
      "         2.1738e-02,  9.5404e-03,  6.2835e-03,  9.0272e-04,  2.1270e-02,\n",
      "        -1.1187e-02, -2.1151e-02,  1.4330e-02,  2.4167e-03,  1.8992e-02,\n",
      "        -6.9492e-03,  4.9088e-03, -1.5458e-02, -2.0668e-02, -2.6994e-03,\n",
      "        -9.1806e-03,  1.1136e-02, -2.3639e-02,  1.7414e-02,  2.4484e-02,\n",
      "        -1.3075e-02,  1.3119e-02, -2.5700e-02, -3.4130e-03,  2.8565e-02,\n",
      "        -3.6684e-04, -1.6396e-02, -1.8938e-02, -1.2964e-02, -4.9676e-03,\n",
      "        -1.9159e-02,  2.4775e-02, -1.8714e-03, -2.4468e-03,  2.6910e-02,\n",
      "         2.8439e-02, -1.7074e-02,  2.9775e-02, -2.9995e-02, -2.2082e-02,\n",
      "        -8.6246e-03,  1.1702e-02,  9.4823e-03, -2.1722e-03,  1.1843e-02,\n",
      "         2.2555e-02, -7.5251e-03, -3.8116e-04,  8.3937e-04, -1.6232e-02,\n",
      "         3.1883e-03, -1.4310e-02, -2.5009e-02,  1.2500e-02,  5.7091e-03,\n",
      "         1.4701e-02,  1.6070e-02, -5.0391e-03, -1.5987e-02,  1.3952e-02,\n",
      "        -1.6814e-03, -3.0134e-02, -1.1569e-02, -3.1644e-02,  5.5994e-03,\n",
      "         2.7314e-02, -1.4293e-02,  1.1744e-02,  1.2047e-02,  2.1385e-02,\n",
      "        -2.1004e-02,  1.5357e-02,  1.0993e-02,  4.6216e-04,  6.7134e-04,\n",
      "         8.9648e-03,  7.5173e-03, -2.2773e-02,  2.5337e-02, -2.1625e-02,\n",
      "        -1.5521e-02,  1.1207e-02, -1.8548e-02, -2.1354e-02, -3.9034e-03,\n",
      "        -1.7115e-02,  1.5715e-02,  1.0999e-02, -6.7183e-03, -1.2751e-03,\n",
      "        -2.8381e-02,  1.9236e-02, -1.4295e-03,  1.5746e-02, -1.7848e-02,\n",
      "        -6.2211e-03, -2.3683e-02, -4.4430e-03, -5.0153e-03,  9.5449e-03,\n",
      "        -3.1475e-03,  8.6012e-03,  7.4151e-03,  1.6759e-03,  1.5248e-02,\n",
      "        -1.2885e-02, -8.5153e-03, -1.9088e-02, -3.5557e-02, -2.6656e-02,\n",
      "         2.7061e-02, -2.2593e-02,  1.8849e-02,  2.4416e-03, -2.4842e-02,\n",
      "        -1.5307e-02, -3.3722e-03,  9.6581e-03, -2.5829e-03,  1.0411e-03,\n",
      "        -1.6437e-02,  1.3302e-02, -2.8493e-02, -1.0696e-02,  4.7163e-03,\n",
      "        -1.8392e-02,  1.2843e-03, -9.8018e-03, -2.5185e-02, -1.5955e-02,\n",
      "         1.0952e-02, -1.2762e-02,  2.2824e-02,  4.3419e-03, -5.0355e-03,\n",
      "         3.7780e-03, -3.3176e-02, -2.8294e-02, -2.8527e-03,  2.1772e-02,\n",
      "         2.1229e-02,  3.2084e-02, -2.1544e-02,  1.8807e-03,  2.0823e-02,\n",
      "         2.5525e-02, -1.8384e-02,  5.1058e-03,  1.7626e-02,  1.9514e-02,\n",
      "         1.5923e-02,  1.0479e-02,  1.9979e-02,  1.4875e-02, -7.7707e-03,\n",
      "         1.6373e-02, -5.7333e-03,  1.9474e-02,  2.3986e-02, -2.9268e-02,\n",
      "         1.3988e-02, -1.4791e-03, -3.1547e-03, -7.3895e-03,  1.1300e-02,\n",
      "        -7.7568e-03, -6.2431e-03,  1.0930e-02, -3.7263e-03,  2.5428e-02,\n",
      "        -2.4614e-02, -1.5654e-02,  1.2411e-02, -6.9523e-03,  3.2872e-03,\n",
      "         2.4234e-03,  7.3595e-03, -1.6130e-02, -1.2655e-02, -1.2622e-02,\n",
      "         2.0205e-02, -2.2405e-02, -1.2979e-02, -2.0880e-02,  1.6392e-02,\n",
      "        -5.6787e-03])\n",
      "activation_stack.14.weight: tensor([[[[-2.1909e-02, -2.0557e-02, -1.1609e-02],\n",
      "          [-1.9328e-02,  1.6917e-02, -2.5489e-04],\n",
      "          [ 6.9770e-03,  9.1277e-04, -1.9423e-02]],\n",
      "\n",
      "         [[ 1.6446e-02,  8.8576e-03,  1.7824e-02],\n",
      "          [ 1.3867e-02, -1.4203e-02, -1.2934e-02],\n",
      "          [-2.1857e-03, -9.4533e-03, -1.3310e-02]],\n",
      "\n",
      "         [[ 1.4374e-02, -1.1129e-02,  1.5032e-02],\n",
      "          [-1.7752e-02, -1.3188e-02, -6.5549e-03],\n",
      "          [-6.2930e-03,  1.1599e-02, -1.4756e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.8783e-03,  1.4061e-02, -1.9876e-02],\n",
      "          [-2.2199e-03, -3.1292e-03,  5.2524e-03],\n",
      "          [ 1.0121e-02, -3.8810e-03,  6.4320e-03]],\n",
      "\n",
      "         [[-1.8457e-02, -1.1704e-02, -1.1602e-02],\n",
      "          [-9.0430e-03, -3.8347e-04, -2.0839e-02],\n",
      "          [ 9.6448e-03, -2.1999e-02,  2.0308e-02]],\n",
      "\n",
      "         [[-9.1981e-03,  2.1265e-03, -7.4450e-03],\n",
      "          [-1.1044e-02, -1.1466e-02, -2.5921e-03],\n",
      "          [ 2.2366e-02,  1.0773e-02,  6.0977e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.2201e-03, -8.3837e-03, -1.5187e-02],\n",
      "          [ 1.3561e-02, -2.0512e-02, -4.0351e-03],\n",
      "          [-6.8116e-03, -1.5364e-03,  1.7620e-02]],\n",
      "\n",
      "         [[-3.2304e-03, -1.6707e-02, -8.6632e-03],\n",
      "          [-2.0813e-02, -1.4663e-02, -5.9847e-03],\n",
      "          [-2.0879e-02,  9.0179e-03,  4.9849e-03]],\n",
      "\n",
      "         [[ 1.1199e-02, -3.9014e-03,  1.6429e-02],\n",
      "          [-4.3075e-04,  1.7153e-02,  1.0485e-02],\n",
      "          [-2.0147e-02,  9.6696e-04,  1.8055e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0302e-02,  1.9630e-02,  3.9657e-03],\n",
      "          [-1.3946e-02,  5.2432e-03,  1.8546e-02],\n",
      "          [ 1.0377e-03, -1.0413e-02,  9.0084e-03]],\n",
      "\n",
      "         [[-2.8603e-03, -1.0294e-02, -7.5607e-03],\n",
      "          [ 1.0877e-02, -1.2213e-02,  2.0548e-02],\n",
      "          [-3.2147e-03,  8.3604e-03, -1.5869e-02]],\n",
      "\n",
      "         [[-4.1477e-03,  5.0941e-03, -5.9941e-03],\n",
      "          [ 6.6540e-04, -1.8245e-03,  1.5492e-02],\n",
      "          [ 3.7991e-04, -1.7733e-02,  2.0044e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5373e-02,  1.6001e-03, -1.3411e-02],\n",
      "          [ 8.5466e-03, -8.3807e-03, -1.6326e-02],\n",
      "          [ 1.5717e-02,  1.8008e-02,  1.5780e-03]],\n",
      "\n",
      "         [[-5.6233e-03, -1.8696e-02, -1.6665e-02],\n",
      "          [-6.3268e-03, -1.3192e-03, -8.9476e-03],\n",
      "          [ 9.9274e-03, -1.7872e-02,  1.6924e-02]],\n",
      "\n",
      "         [[-1.0258e-02,  1.0952e-02, -5.7410e-03],\n",
      "          [ 3.9803e-03, -9.1167e-03, -8.1834e-03],\n",
      "          [-3.4914e-03,  1.0142e-02,  8.4948e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1098e-02,  1.8817e-02, -8.3190e-03],\n",
      "          [-2.5519e-03, -1.5576e-02, -8.2735e-03],\n",
      "          [-6.8553e-03,  1.4421e-02, -1.5606e-02]],\n",
      "\n",
      "         [[-8.8959e-03, -1.2535e-02, -1.6049e-02],\n",
      "          [-2.1216e-02, -7.3751e-03, -9.0143e-03],\n",
      "          [ 1.3469e-03, -1.5983e-02,  5.6749e-03]],\n",
      "\n",
      "         [[ 1.5904e-02,  1.3316e-02,  2.1273e-02],\n",
      "          [-6.5272e-03,  1.0692e-02,  3.5189e-03],\n",
      "          [ 2.2197e-03, -5.8374e-03,  1.3516e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8556e-02, -9.3041e-04, -6.5703e-03],\n",
      "          [-1.4720e-02,  1.2240e-02, -1.0763e-03],\n",
      "          [-1.5957e-02, -8.8532e-05, -2.2669e-02]],\n",
      "\n",
      "         [[ 1.0768e-02,  9.1031e-03, -7.8510e-03],\n",
      "          [-9.6574e-03, -2.1838e-03,  1.7303e-03],\n",
      "          [-1.2808e-02,  1.2333e-02, -9.3992e-03]],\n",
      "\n",
      "         [[-1.4554e-02, -1.8584e-03, -1.0146e-02],\n",
      "          [ 3.0470e-04, -7.4024e-03, -8.1397e-04],\n",
      "          [-5.2742e-03, -7.1221e-03,  2.0693e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.7559e-03, -1.8600e-02,  1.1809e-02],\n",
      "          [ 1.5741e-02, -1.8473e-02, -1.4356e-03],\n",
      "          [ 6.0156e-03,  1.1710e-02, -2.2943e-02]],\n",
      "\n",
      "         [[-9.8556e-03,  2.1176e-02,  1.4552e-02],\n",
      "          [ 8.0835e-03, -1.9376e-02, -2.0326e-02],\n",
      "          [ 5.7878e-03,  1.9838e-02,  3.5244e-03]],\n",
      "\n",
      "         [[-1.0126e-02,  1.2097e-02,  2.3978e-03],\n",
      "          [-5.0837e-03, -8.7106e-03,  1.3699e-02],\n",
      "          [-1.3991e-02,  3.0287e-03,  1.1582e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2194e-02, -1.6312e-02,  1.5456e-02],\n",
      "          [ 9.5121e-03, -2.4335e-03, -1.5666e-03],\n",
      "          [-1.3121e-02,  8.0805e-03,  8.4585e-03]],\n",
      "\n",
      "         [[-7.1967e-03, -8.9382e-03, -1.5977e-02],\n",
      "          [ 9.9422e-03,  2.2196e-03,  1.5981e-02],\n",
      "          [-1.0641e-02, -1.6357e-03, -1.8961e-03]],\n",
      "\n",
      "         [[ 5.5380e-03, -6.1510e-03,  1.8895e-02],\n",
      "          [ 1.5338e-02,  4.6679e-03, -3.2398e-03],\n",
      "          [ 3.0557e-03,  6.8611e-03,  1.1836e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.7021e-03,  1.0737e-02, -2.6951e-03],\n",
      "          [ 1.0695e-02,  1.0050e-02, -1.8938e-02],\n",
      "          [-8.5563e-03, -9.7811e-03, -2.0887e-02]],\n",
      "\n",
      "         [[ 1.6900e-02, -5.1876e-03, -1.6390e-02],\n",
      "          [-9.1910e-03, -4.7190e-03, -6.0908e-03],\n",
      "          [ 8.1148e-03,  3.5418e-03,  1.9486e-02]],\n",
      "\n",
      "         [[-2.0802e-03,  4.7578e-03, -5.2092e-04],\n",
      "          [ 7.6229e-03, -8.9835e-03,  1.6242e-02],\n",
      "          [-7.3664e-03, -1.3658e-02,  6.7759e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1536e-02,  2.1212e-02,  1.6906e-02],\n",
      "          [-4.9457e-03, -1.7734e-02, -2.7612e-03],\n",
      "          [-1.5018e-02, -8.5219e-04,  1.4517e-02]],\n",
      "\n",
      "         [[-1.6574e-03, -6.5343e-03,  1.3454e-02],\n",
      "          [ 8.6926e-03, -1.0647e-02, -7.1968e-03],\n",
      "          [ 1.0703e-02, -1.8248e-02, -1.7098e-02]],\n",
      "\n",
      "         [[-1.2874e-02, -1.1052e-02, -1.7194e-02],\n",
      "          [-1.9368e-02,  2.1841e-02,  9.2007e-03],\n",
      "          [ 1.6447e-02,  8.0445e-03,  1.2502e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8084e-02,  1.5969e-02,  8.9556e-03],\n",
      "          [-3.1041e-03, -6.2558e-03, -1.3506e-02],\n",
      "          [ 1.1323e-02,  1.5417e-02,  1.7604e-02]],\n",
      "\n",
      "         [[ 1.3076e-02,  1.2352e-02,  3.8429e-05],\n",
      "          [-5.7702e-03,  1.2427e-02,  6.8288e-03],\n",
      "          [ 5.1788e-03, -2.3728e-02, -1.5730e-02]],\n",
      "\n",
      "         [[ 7.8904e-03, -3.6324e-03, -1.6954e-02],\n",
      "          [-6.0753e-03, -1.6241e-02,  1.7493e-02],\n",
      "          [ 1.2838e-02, -1.8504e-02,  6.6969e-03]]]])\n",
      "activation_stack.14.bias: tensor([-0.0143,  0.0126, -0.0116,  0.0158, -0.0184, -0.0175,  0.0040, -0.0072,\n",
      "        -0.0106, -0.0197,  0.0016, -0.0056,  0.0076, -0.0088, -0.0087,  0.0110,\n",
      "        -0.0117,  0.0161, -0.0071, -0.0053,  0.0031, -0.0193, -0.0095,  0.0026,\n",
      "        -0.0152,  0.0134,  0.0177, -0.0150, -0.0088, -0.0147, -0.0124, -0.0087,\n",
      "         0.0135,  0.0170,  0.0013,  0.0048, -0.0144, -0.0063, -0.0061, -0.0013,\n",
      "         0.0038, -0.0132, -0.0202,  0.0017, -0.0211,  0.0088,  0.0036, -0.0217,\n",
      "        -0.0019, -0.0222, -0.0012, -0.0138,  0.0022, -0.0049, -0.0115, -0.0096,\n",
      "         0.0045, -0.0045, -0.0145, -0.0068, -0.0121,  0.0082, -0.0016, -0.0015,\n",
      "         0.0138, -0.0213, -0.0092,  0.0015,  0.0026, -0.0131,  0.0127, -0.0039,\n",
      "        -0.0168,  0.0218, -0.0119, -0.0075,  0.0173, -0.0258,  0.0073,  0.0077,\n",
      "        -0.0163,  0.0145, -0.0188, -0.0020, -0.0175, -0.0005, -0.0114, -0.0083,\n",
      "        -0.0082,  0.0242, -0.0153,  0.0141,  0.0079, -0.0012,  0.0045, -0.0029,\n",
      "        -0.0053, -0.0243,  0.0159,  0.0102, -0.0147,  0.0112,  0.0165, -0.0100,\n",
      "        -0.0197,  0.0006, -0.0059,  0.0068, -0.0054, -0.0139, -0.0062,  0.0018,\n",
      "        -0.0145,  0.0160, -0.0071,  0.0083,  0.0004,  0.0170,  0.0020,  0.0033,\n",
      "         0.0022,  0.0058, -0.0144, -0.0177, -0.0105, -0.0055, -0.0002, -0.0039,\n",
      "         0.0099,  0.0104,  0.0159,  0.0070,  0.0106,  0.0120, -0.0156,  0.0059,\n",
      "         0.0111, -0.0121, -0.0174, -0.0054, -0.0028, -0.0023,  0.0057,  0.0183,\n",
      "        -0.0237, -0.0146,  0.0026,  0.0016,  0.0151, -0.0076,  0.0089, -0.0109,\n",
      "        -0.0010, -0.0097,  0.0078,  0.0039,  0.0059, -0.0101, -0.0033, -0.0156,\n",
      "        -0.0130, -0.0038, -0.0089, -0.0021, -0.0103, -0.0164, -0.0135,  0.0150,\n",
      "         0.0124,  0.0039, -0.0188, -0.0169,  0.0044, -0.0194,  0.0026, -0.0175,\n",
      "         0.0098,  0.0088, -0.0060,  0.0048,  0.0111,  0.0033,  0.0035,  0.0021,\n",
      "         0.0161,  0.0159,  0.0002, -0.0158,  0.0149,  0.0101, -0.0235,  0.0099,\n",
      "        -0.0058,  0.0096,  0.0160, -0.0004,  0.0097, -0.0172,  0.0168, -0.0084,\n",
      "        -0.0032,  0.0215,  0.0133, -0.0042,  0.0004,  0.0139,  0.0120, -0.0173,\n",
      "        -0.0103, -0.0083,  0.0049,  0.0109,  0.0083,  0.0127,  0.0088,  0.0074,\n",
      "        -0.0162, -0.0223,  0.0082,  0.0043, -0.0172,  0.0141,  0.0160,  0.0117,\n",
      "        -0.0148, -0.0027,  0.0203,  0.0189,  0.0164,  0.0050,  0.0146, -0.0164,\n",
      "         0.0189,  0.0019, -0.0115, -0.0199,  0.0111, -0.0204, -0.0070, -0.0125,\n",
      "         0.0032, -0.0120, -0.0098,  0.0053,  0.0072, -0.0005, -0.0203,  0.0178,\n",
      "         0.0188,  0.0101,  0.0185, -0.0171,  0.0070, -0.0020, -0.0184,  0.0032])\n",
      "activation_stack.17.weight: tensor([1.0156, 1.0140, 1.0148, 1.0124, 1.0156, 1.0087, 1.0061, 1.0141, 1.0107,\n",
      "        1.0093, 1.0120, 1.0135, 1.0068, 1.0058, 1.0112, 1.0135, 1.0109, 1.0137,\n",
      "        1.0114, 1.0121, 1.0135, 1.0135, 1.0124, 1.0121, 1.0121, 1.0108, 1.0071,\n",
      "        1.0116, 1.0121, 1.0146, 1.0122, 1.0127, 1.0119, 1.0097, 1.0132, 1.0106,\n",
      "        1.0115, 1.0109, 1.0136, 1.0095, 1.0076, 1.0086, 1.0143, 1.0104, 1.0125,\n",
      "        1.0114, 1.0176, 1.0086, 1.0143, 1.0172, 1.0096, 1.0114, 1.0051, 1.0112,\n",
      "        1.0164, 1.0096, 1.0146, 1.0139, 1.0082, 1.0118, 1.0109, 1.0110, 1.0120,\n",
      "        1.0169, 1.0101, 1.0071, 1.0158, 1.0124, 1.0158, 1.0133, 1.0117, 1.0126,\n",
      "        1.0165, 1.0091, 1.0118, 1.0133, 1.0189, 1.0120, 1.0159, 1.0147, 1.0084,\n",
      "        1.0130, 1.0140, 1.0071, 1.0162, 1.0111, 1.0071, 1.0098, 1.0162, 1.0121,\n",
      "        1.0119, 1.0108, 1.0114, 1.0133, 1.0118, 1.0099, 1.0109, 1.0113, 1.0199,\n",
      "        1.0071, 1.0090, 1.0112, 1.0064, 1.0086, 1.0134, 1.0091, 1.0120, 1.0125,\n",
      "        1.0088, 1.0133, 1.0125, 1.0148, 1.0110, 1.0150, 1.0163, 1.0091, 1.0104,\n",
      "        1.0127, 1.0192, 1.0130, 1.0139, 1.0162, 1.0124, 1.0114, 1.0127, 1.0110,\n",
      "        1.0168, 1.0124, 1.0068, 1.0095, 1.0137, 1.0104, 1.0141, 1.0167, 1.0115,\n",
      "        1.0097, 1.0110, 1.0136, 1.0075, 1.0097, 1.0134, 1.0104, 1.0090, 1.0140,\n",
      "        1.0178, 1.0168, 1.0149, 1.0102, 1.0142, 1.0174, 1.0129, 1.0099, 1.0150,\n",
      "        1.0193, 1.0115, 1.0109, 1.0107, 1.0119, 1.0101, 1.0157, 1.0082, 1.0139,\n",
      "        1.0093, 1.0082, 1.0145, 1.0104, 1.0066, 1.0135, 1.0121, 1.0097, 1.0122,\n",
      "        1.0119, 1.0070, 1.0108, 1.0149, 1.0138, 1.0105, 1.0100, 1.0118, 1.0147,\n",
      "        1.0156, 1.0110, 1.0115, 1.0103, 1.0093, 1.0098, 1.0092, 1.0128, 1.0103,\n",
      "        1.0119, 1.0090, 1.0142, 1.0117, 1.0123, 1.0079, 1.0115, 1.0139, 1.0103,\n",
      "        1.0121, 1.0136, 1.0083, 1.0137, 1.0142, 1.0156, 1.0064, 1.0094, 1.0096,\n",
      "        1.0151, 1.0073, 1.0074, 1.0120, 1.0105, 1.0151, 1.0104, 1.0076, 1.0130,\n",
      "        1.0110, 1.0128, 1.0100, 1.0148, 1.0170, 1.0101, 1.0131, 1.0126, 1.0113,\n",
      "        1.0107, 1.0127, 1.0192, 1.0103, 1.0093, 1.0103, 1.0077, 1.0130, 1.0118,\n",
      "        1.0127, 1.0067, 1.0095, 1.0097, 1.0140, 1.0132, 1.0167, 1.0104, 1.0131,\n",
      "        1.0119, 1.0100, 1.0149, 1.0150, 1.0058, 1.0085, 1.0123, 1.0111, 1.0119,\n",
      "        1.0089, 1.0099, 1.0187, 1.0166])\n",
      "activation_stack.17.bias: tensor([-2.7301e-03,  8.8433e-04,  2.7761e-03, -3.5589e-03, -2.8357e-04,\n",
      "         7.0304e-04, -5.8722e-03, -2.0327e-03, -4.8951e-03,  2.6376e-03,\n",
      "        -3.2287e-03,  5.5416e-04,  4.6717e-03, -6.1916e-03,  2.0573e-04,\n",
      "        -1.7924e-04,  2.4013e-03, -3.4953e-03, -5.1937e-03, -3.1617e-03,\n",
      "        -2.3010e-03,  3.3808e-04, -2.8608e-03, -5.9478e-03,  3.9238e-03,\n",
      "         3.0197e-03, -1.6350e-03,  1.4548e-03, -6.3193e-04, -3.2334e-04,\n",
      "        -3.2135e-03, -1.8582e-03, -3.6615e-03,  2.9316e-03, -1.3081e-03,\n",
      "        -5.0797e-03, -1.0812e-03,  4.5902e-03,  2.6759e-03, -5.9202e-04,\n",
      "         2.0959e-05, -2.0621e-03, -3.8718e-03, -2.7778e-03,  1.6660e-03,\n",
      "         3.6544e-03, -2.0607e-03,  2.1283e-03, -5.1622e-03, -1.4209e-03,\n",
      "        -6.5975e-03, -1.4848e-03, -5.0718e-04,  1.4781e-03, -4.5247e-03,\n",
      "        -1.3391e-03,  3.8772e-04,  1.1271e-03, -5.8700e-03, -1.2434e-04,\n",
      "         6.7138e-03, -6.4943e-03, -6.9432e-03, -1.1622e-03, -1.8236e-03,\n",
      "        -4.3537e-03, -5.6136e-03, -5.7277e-03, -1.8765e-03, -1.3258e-03,\n",
      "        -1.7492e-04, -3.3376e-03,  4.3787e-05, -3.5431e-03, -3.2464e-03,\n",
      "        -1.7456e-03, -3.0214e-03, -4.4082e-03,  2.6454e-03, -1.5011e-03,\n",
      "         2.4783e-03, -4.8723e-03, -7.0811e-03, -4.9708e-03,  3.0685e-03,\n",
      "        -3.6099e-03, -3.7896e-03, -1.2628e-03, -3.1619e-03,  2.0075e-03,\n",
      "        -1.4590e-03, -2.8939e-03,  6.0772e-04, -2.6630e-03, -4.5267e-03,\n",
      "         8.4497e-04, -3.6496e-03,  1.0882e-04, -1.0490e-03, -7.8498e-03,\n",
      "        -1.3758e-03, -1.0207e-03, -8.5285e-03, -2.6411e-03, -1.6890e-03,\n",
      "        -2.1578e-03, -1.2425e-04, -1.5076e-03, -7.8582e-03, -6.2689e-03,\n",
      "        -9.8635e-04,  5.1963e-04, -3.4641e-03, -7.5603e-04, -2.6666e-03,\n",
      "        -7.6688e-03, -1.7733e-03, -7.6597e-04, -2.5172e-03, -6.9370e-04,\n",
      "         2.7116e-03,  4.0160e-03, -4.2328e-03,  2.4608e-03,  3.2657e-03,\n",
      "        -7.9861e-04, -6.8006e-03,  2.3941e-03,  1.8842e-03,  2.8451e-04,\n",
      "        -6.5183e-03, -6.4045e-05, -6.0636e-03, -2.1296e-03, -1.5082e-03,\n",
      "        -2.8332e-04, -2.5686e-03, -2.0260e-03, -4.7200e-05, -3.6863e-03,\n",
      "         2.7346e-03,  1.4355e-03,  3.7137e-04,  6.5704e-03, -1.8729e-03,\n",
      "        -8.1890e-04,  3.0151e-03,  4.1671e-04, -3.1043e-03,  1.0717e-03,\n",
      "        -3.2751e-03, -6.9619e-04,  9.8704e-05,  1.2088e-03, -2.8634e-03,\n",
      "        -3.0900e-03,  3.1805e-03,  4.4807e-03, -1.8865e-03, -4.3655e-03,\n",
      "        -6.3825e-03, -8.6675e-04, -1.3899e-03,  2.7550e-03,  3.0738e-03,\n",
      "         4.2900e-04, -7.5092e-03, -3.5780e-04,  3.2190e-04,  1.6947e-04,\n",
      "        -1.1186e-03,  5.6400e-04, -3.0442e-03,  1.5204e-03,  3.1041e-03,\n",
      "        -5.6457e-04,  2.7614e-03,  6.7338e-04,  7.2533e-04, -4.1734e-03,\n",
      "         1.2469e-03, -4.8175e-05, -5.9563e-03,  2.9591e-04,  1.3853e-03,\n",
      "        -4.0851e-03, -1.1586e-04, -1.6755e-03,  3.5853e-03,  1.3551e-03,\n",
      "        -6.9652e-03, -5.2158e-03,  1.7637e-03, -3.1275e-03, -4.5135e-03,\n",
      "        -1.5461e-03, -1.4506e-03, -2.8606e-03, -1.8700e-03,  3.9149e-03,\n",
      "         4.2855e-04, -1.7037e-03, -1.1634e-03,  1.9931e-03, -6.9354e-03,\n",
      "         2.1414e-03,  5.0860e-04,  1.2993e-03, -1.5955e-03, -4.7737e-03,\n",
      "         2.2520e-03, -1.9386e-03,  2.8075e-03, -3.3248e-03, -2.6058e-03,\n",
      "        -1.8139e-03,  1.1646e-03, -4.9309e-04, -4.3702e-03,  2.9551e-03,\n",
      "        -4.9234e-04,  9.4779e-04,  8.2941e-04,  2.9618e-03,  3.5646e-04,\n",
      "        -1.1906e-03, -1.0228e-03,  3.2307e-03, -1.5002e-03,  2.0866e-03,\n",
      "        -1.9551e-03, -1.7316e-04,  7.6294e-04,  1.6320e-03, -2.0446e-03,\n",
      "        -2.4732e-03, -5.8349e-03, -3.8481e-03,  1.2269e-04, -4.1091e-03,\n",
      "         1.1908e-03, -4.0940e-05,  4.6709e-03, -2.2468e-03, -2.9183e-03,\n",
      "        -2.0981e-03,  1.2513e-03, -1.4117e-03,  2.4539e-03, -4.6397e-03,\n",
      "        -1.8679e-03, -1.0380e-03, -1.7750e-03, -2.9755e-03,  5.5099e-03,\n",
      "        -3.5480e-03])\n",
      "activation_stack.19.weight: tensor([[-1.9380e-03,  1.1284e-02,  1.3373e-02,  ..., -1.0500e-03,\n",
      "          1.2324e-02, -1.1117e-02],\n",
      "        [ 1.0133e-02, -9.0873e-03, -8.0098e-03,  ...,  1.7626e-03,\n",
      "         -1.5527e-02,  7.2251e-03],\n",
      "        [-5.4108e-03,  1.2883e-02,  5.8894e-03,  ..., -3.5717e-03,\n",
      "          1.4288e-02,  1.3218e-02],\n",
      "        ...,\n",
      "        [-1.3704e-02, -4.5640e-03,  5.2198e-03,  ...,  1.6544e-03,\n",
      "         -1.1231e-02, -4.9550e-05],\n",
      "        [ 3.3194e-03,  9.5610e-03, -1.5290e-02,  ...,  7.9884e-03,\n",
      "         -7.3957e-03, -9.0368e-03],\n",
      "        [ 7.8013e-03, -4.3671e-03, -1.4967e-03,  ..., -1.5417e-02,\n",
      "         -3.3693e-03, -9.6415e-03]])\n",
      "activation_stack.19.bias: tensor([ 0.0067,  0.0059, -0.0105,  ...,  0.0067, -0.0048, -0.0101])\n",
      "activation_stack.21.weight: tensor([[ 0.0200, -0.0203,  0.0008,  ..., -0.0103, -0.0058,  0.0059],\n",
      "        [-0.0263, -0.0025,  0.0163,  ..., -0.0324, -0.0204,  0.0128],\n",
      "        [-0.0169, -0.0145,  0.0170,  ...,  0.0284,  0.0185, -0.0089],\n",
      "        ...,\n",
      "        [-0.0199,  0.0223, -0.0020,  ..., -0.0111,  0.0236,  0.0284],\n",
      "        [ 0.0314,  0.0262, -0.0206,  ...,  0.0299, -0.0220, -0.0271],\n",
      "        [-0.0130, -0.0210, -0.0164,  ...,  0.0283, -0.0039, -0.0033]])\n",
      "activation_stack.21.bias: tensor([-0.0087, -0.0137,  0.0246,  0.0217, -0.0179, -0.0127, -0.0088,  0.0131,\n",
      "         0.0327, -0.0074, -0.0206, -0.0286, -0.0026,  0.0318, -0.0181,  0.0247,\n",
      "        -0.0180,  0.0266, -0.0125, -0.0212,  0.0166, -0.0011,  0.0151,  0.0092,\n",
      "         0.0249, -0.0141, -0.0161, -0.0042,  0.0015,  0.0318, -0.0150,  0.0036,\n",
      "         0.0340,  0.0269, -0.0231, -0.0107,  0.0045,  0.0152,  0.0012,  0.0120,\n",
      "        -0.0032,  0.0348,  0.0225, -0.0253, -0.0081,  0.0124, -0.0221, -0.0124,\n",
      "         0.0126, -0.0208,  0.0263, -0.0286,  0.0332,  0.0127,  0.0331, -0.0222,\n",
      "         0.0187, -0.0196, -0.0160, -0.0039,  0.0204,  0.0312,  0.0028,  0.0088,\n",
      "         0.0240,  0.0159,  0.0064,  0.0317,  0.0093,  0.0008, -0.0063,  0.0041,\n",
      "        -0.0022,  0.0206,  0.0130,  0.0256, -0.0170, -0.0246, -0.0227,  0.0281,\n",
      "         0.0224,  0.0169, -0.0027,  0.0328,  0.0291,  0.0306, -0.0093,  0.0181,\n",
      "        -0.0055, -0.0108, -0.0234,  0.0239,  0.0221,  0.0116, -0.0179, -0.0136,\n",
      "        -0.0310, -0.0190, -0.0139,  0.0253,  0.0155,  0.0133,  0.0289, -0.0135,\n",
      "         0.0152, -0.0154, -0.0128,  0.0027,  0.0340, -0.0244, -0.0122,  0.0293,\n",
      "        -0.0004, -0.0267,  0.0311, -0.0078,  0.0070,  0.0072,  0.0203,  0.0013,\n",
      "         0.0141,  0.0178,  0.0229, -0.0234,  0.0092,  0.0029, -0.0253, -0.0079,\n",
      "         0.0068, -0.0099, -0.0300,  0.0288,  0.0016, -0.0064, -0.0262,  0.0115,\n",
      "         0.0079,  0.0060,  0.0301, -0.0110,  0.0150, -0.0180, -0.0087, -0.0077,\n",
      "         0.0147, -0.0073, -0.0178,  0.0078,  0.0088,  0.0063, -0.0262, -0.0125,\n",
      "         0.0191,  0.0097,  0.0282,  0.0034,  0.0305, -0.0153,  0.0316,  0.0013,\n",
      "        -0.0091, -0.0017, -0.0194, -0.0210, -0.0195, -0.0099, -0.0251, -0.0241,\n",
      "        -0.0009, -0.0211, -0.0284,  0.0069,  0.0114,  0.0266,  0.0108,  0.0032,\n",
      "         0.0033,  0.0310,  0.0164,  0.0257, -0.0156,  0.0038,  0.0347,  0.0080,\n",
      "         0.0229,  0.0329,  0.0074,  0.0335, -0.0014, -0.0143, -0.0242,  0.0106,\n",
      "         0.0097,  0.0314, -0.0184,  0.0039,  0.0065,  0.0170, -0.0214,  0.0237,\n",
      "        -0.0031, -0.0329, -0.0079, -0.0126, -0.0187,  0.0196,  0.0093,  0.0230,\n",
      "        -0.0257, -0.0138, -0.0074, -0.0217, -0.0073,  0.0094,  0.0210, -0.0051,\n",
      "         0.0050,  0.0145,  0.0270,  0.0004,  0.0049,  0.0284,  0.0199,  0.0301,\n",
      "        -0.0260, -0.0178, -0.0210, -0.0019, -0.0227,  0.0266,  0.0015, -0.0232,\n",
      "        -0.0251, -0.0036, -0.0231,  0.0327,  0.0032, -0.0186, -0.0213,  0.0279,\n",
      "         0.0148,  0.0312, -0.0083, -0.0186, -0.0032, -0.0253, -0.0032,  0.0270,\n",
      "         0.0133,  0.0167,  0.0037,  0.0246,  0.0338, -0.0159, -0.0026,  0.0155,\n",
      "        -0.0053,  0.0321, -0.0280,  0.0161,  0.0229,  0.0273,  0.0212, -0.0182,\n",
      "        -0.0101,  0.0059, -0.0184,  0.0293,  0.0067,  0.0296,  0.0320,  0.0237,\n",
      "         0.0304,  0.0311,  0.0133, -0.0154,  0.0237,  0.0168,  0.0322, -0.0128,\n",
      "        -0.0113,  0.0094, -0.0175, -0.0053, -0.0205,  0.0205, -0.0009, -0.0252,\n",
      "         0.0100, -0.0242,  0.0263, -0.0076,  0.0184,  0.0035,  0.0318,  0.0226,\n",
      "         0.0011,  0.0194, -0.0142,  0.0195,  0.0107,  0.0278, -0.0036,  0.0231,\n",
      "         0.0077, -0.0178,  0.0323,  0.0317,  0.0242, -0.0200, -0.0190,  0.0319,\n",
      "        -0.0063,  0.0077,  0.0258, -0.0145, -0.0187, -0.0177,  0.0246, -0.0221,\n",
      "         0.0159, -0.0254, -0.0149, -0.0036,  0.0258, -0.0042,  0.0016,  0.0209,\n",
      "        -0.0067, -0.0052, -0.0120,  0.0277,  0.0252, -0.0168, -0.0020,  0.0088,\n",
      "        -0.0057,  0.0229,  0.0099, -0.0083,  0.0305, -0.0044,  0.0037,  0.0247,\n",
      "        -0.0224,  0.0219,  0.0070,  0.0216,  0.0119, -0.0169, -0.0059,  0.0345,\n",
      "        -0.0079, -0.0058, -0.0034, -0.0160,  0.0269, -0.0035, -0.0174, -0.0172,\n",
      "        -0.0135,  0.0019,  0.0276, -0.0177, -0.0152,  0.0144, -0.0095, -0.0225,\n",
      "         0.0155, -0.0048,  0.0278,  0.0323, -0.0193, -0.0201, -0.0168,  0.0127,\n",
      "         0.0008, -0.0042,  0.0274, -0.0177,  0.0332,  0.0296,  0.0048,  0.0009,\n",
      "         0.0253, -0.0099, -0.0148,  0.0286,  0.0299, -0.0188, -0.0258, -0.0065,\n",
      "         0.0259,  0.0250,  0.0276, -0.0237,  0.0270, -0.0252,  0.0055,  0.0015,\n",
      "        -0.0047, -0.0105, -0.0123,  0.0018,  0.0263, -0.0189,  0.0108, -0.0152,\n",
      "        -0.0074,  0.0359, -0.0032, -0.0186, -0.0063,  0.0040, -0.0207, -0.0004,\n",
      "         0.0312,  0.0306, -0.0020,  0.0111,  0.0075,  0.0096, -0.0218,  0.0092,\n",
      "        -0.0256, -0.0010,  0.0014,  0.0116,  0.0062,  0.0238, -0.0089,  0.0134,\n",
      "         0.0222, -0.0078, -0.0038, -0.0266, -0.0125,  0.0333,  0.0002, -0.0181,\n",
      "        -0.0227, -0.0027, -0.0083,  0.0055, -0.0158,  0.0248,  0.0037,  0.0227,\n",
      "        -0.0270, -0.0277, -0.0044, -0.0101, -0.0233, -0.0165,  0.0074,  0.0030,\n",
      "        -0.0062, -0.0250, -0.0246,  0.0082,  0.0267,  0.0286,  0.0266,  0.0182,\n",
      "         0.0283,  0.0320,  0.0301,  0.0325, -0.0020,  0.0070, -0.0186,  0.0202,\n",
      "        -0.0270, -0.0137,  0.0052, -0.0048,  0.0131,  0.0201,  0.0140,  0.0316,\n",
      "        -0.0099, -0.0265,  0.0262,  0.0041,  0.0203, -0.0059,  0.0054,  0.0327,\n",
      "         0.0312,  0.0226,  0.0064,  0.0132,  0.0157, -0.0248,  0.0044,  0.0074,\n",
      "        -0.0064,  0.0277,  0.0024, -0.0149,  0.0273,  0.0206, -0.0047,  0.0055,\n",
      "         0.0021, -0.0127,  0.0072, -0.0138,  0.0156, -0.0199, -0.0178,  0.0194])\n",
      "activation_stack.23.weight: tensor([[ 0.0006,  0.0811, -0.0254,  ..., -0.0232,  0.0704,  0.0738],\n",
      "        [-0.0466,  0.1211, -0.0357,  ...,  0.0173, -0.0518,  0.0590],\n",
      "        [ 0.0053, -0.0541, -0.0297,  ..., -0.0771, -0.0093,  0.0566],\n",
      "        ...,\n",
      "        [-0.0259, -0.0958,  0.0593,  ..., -0.0723,  0.0694,  0.0576],\n",
      "        [ 0.0614,  0.0554, -0.0287,  ...,  0.0156, -0.0283, -0.0624],\n",
      "        [ 0.0277,  0.1012,  0.0661,  ...,  0.0632,  0.0467, -0.0030]])\n",
      "activation_stack.23.bias: tensor([-0.0036, -0.0482, -0.0354,  0.0328, -0.0408,  0.0266, -0.0024,  0.0102,\n",
      "        -0.0076,  0.0287])\n",
      "Total send cost in training: 47995690600\n",
      "Total send cost in testing: 47995690600\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss Variance: 0.18653579051546154\n",
      "Test Loss Variance: 4.884017835867716e-09\n",
      "Train Loss Variance For Half: 5.49805606049707e-08\n",
      "Test Loss Variance For Half: 4.216544941406444e-10\n",
      "Train error Variance: 0.01849959045648575\n",
      "Test error Variance: 0.0\n",
      "Train error Variance For Half: 5.49805606049707e-08\n",
      "Test error Variance For Half: 4.216544941406444e-10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== The training for local_update_epochs is 25 ===\n",
      "ConvolutionalNeuralNetwork_CIFAR10(\n",
      "  (activation_stack): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "    (19): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (20): ReLU()\n",
      "    (21): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (22): ReLU()\n",
      "    (23): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "!-- Training Session --!\n",
      "Epoch [1/20], Average Loss: 1.54939859, Average Error: 0.4985600113868713, Culminative Send Cost: 58531330\n",
      "Epoch [2/20], Average Loss: 0.58387548, Average Error: 0.1733999997377396, Culminative Send Cost: 117062660\n",
      "Epoch [3/20], Average Loss: 0.19309949, Average Error: 0.0559599995613098, Culminative Send Cost: 175593990\n",
      "Epoch [4/20], Average Loss: 0.11751902, Average Error: 0.0307200010865927, Culminative Send Cost: 234125320\n",
      "Epoch [5/20], Average Loss: 0.04906848, Average Error: 0.0113599989563227, Culminative Send Cost: 292656650\n",
      "Epoch [6/20], Average Loss: 0.01718609, Average Error: 0.0026000002399087, Culminative Send Cost: 351187980\n",
      "Epoch [7/20], Average Loss: 0.00512831, Average Error: 0.0001599999959581, Culminative Send Cost: 409719310\n",
      "Epoch [8/20], Average Loss: 0.00291201, Average Error: 0.0000000000000000, Culminative Send Cost: 468250640\n",
      "Epoch [9/20], Average Loss: 0.00210272, Average Error: 0.0000000000000000, Culminative Send Cost: 526781970\n",
      "Epoch [10/20], Average Loss: 0.00167579, Average Error: 0.0000000000000000, Culminative Send Cost: 585313300\n",
      "Epoch [11/20], Average Loss: 0.00138618, Average Error: 0.0000000000000000, Culminative Send Cost: 643844630\n",
      "Epoch [12/20], Average Loss: 0.00117384, Average Error: 0.0000000000000000, Culminative Send Cost: 702375960\n",
      "Epoch [13/20], Average Loss: 0.00101054, Average Error: 0.0000000000000000, Culminative Send Cost: 760907290\n",
      "Epoch [14/20], Average Loss: 0.00088154, Average Error: 0.0000000000000000, Culminative Send Cost: 819438620\n",
      "Epoch [15/20], Average Loss: 0.00077775, Average Error: 0.0000000000000000, Culminative Send Cost: 877969950\n",
      "Epoch [16/20], Average Loss: 0.00069261, Average Error: 0.0000000000000000, Culminative Send Cost: 936501280\n",
      "Epoch [17/20], Average Loss: 0.00062173, Average Error: 0.0000000000000000, Culminative Send Cost: 995032610\n",
      "Epoch [18/20], Average Loss: 0.00056195, Average Error: 0.0000000000000000, Culminative Send Cost: 1053563940\n",
      "Epoch [19/20], Average Loss: 0.00051102, Average Error: 0.0000000000000000, Culminative Send Cost: 1112095270\n",
      "Epoch [20/20], Average Loss: 0.00046716, Average Error: 0.0000000000000000, Culminative Send Cost: 1170626600\n",
      "Time for all iteration:  3134.6732424\n",
      "!-- Testing Session --!\n",
      "Epoch [1/20], Average Loss: 0.00042905, Average Error: 0.0000000000000000, Culminative Send Cost: 58531330\n",
      "Epoch [2/20], Average Loss: 0.00039577, Average Error: 0.0000000000000000, Culminative Send Cost: 117062660\n",
      "Epoch [3/20], Average Loss: 0.00036642, Average Error: 0.0000000000000000, Culminative Send Cost: 175593990\n",
      "Epoch [4/20], Average Loss: 0.00034049, Average Error: 0.0000000000000000, Culminative Send Cost: 234125320\n",
      "Epoch [5/20], Average Loss: 0.00031742, Average Error: 0.0000000000000000, Culminative Send Cost: 292656650\n",
      "Epoch [6/20], Average Loss: 0.00029679, Average Error: 0.0000000000000000, Culminative Send Cost: 351187980\n",
      "Epoch [7/20], Average Loss: 0.00027826, Average Error: 0.0000000000000000, Culminative Send Cost: 409719310\n"
     ]
    }
   ],
   "source": [
    "### Experiment for local_update_epochs with CNN model\n",
    "\n",
    "# Define the model parameters\n",
    "learning_rate = 0.2\n",
    "batch_size = batch_size_preset\n",
    "\n",
    "num_epochs_list = [200, 40, 20]\n",
    "num_clients_list = [10]\n",
    "local_update_epochs_list = [1, 10, 25]\n",
    "num_epochs = num_epochs_list[0]\n",
    "\n",
    "CNN_input_shape = CNN_input_shape_preset\n",
    "\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "experiment_type = \"local_update_epochs\"\n",
    "total_filename = \"{}_{}_{}epoch_result\".format(dataset_name, experiment_type, num_epochs)\n",
    "\n",
    "# Experiment\n",
    "experiment_FedLearn_model(simple_global_model_func_CNN, train_loader, test_loader, num_epochs_list, num_clients_list, local_update_epochs_list, simple_client_setup_func_CNN, iterate_CNN_model, Federated_Averaging, compareClients=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  homogeneous_CIFAR-10 Datset1local_update_epochs200epoch_result\n",
      "['train_loss', 'train_error', 'train_send_cost', 'train_time', 'test_loss', 'test_error', 'test_send_cost', 'test_time']\n",
      "=======TRAIN RESULT=======\n",
      "train loss:  [2.30633025e+00 2.18515327e+00 2.10994499e+00 2.02539656e+00\n",
      " 2.00944207e+00 2.31130626e+00 2.25889239e+00 2.04337673e+00\n",
      " 1.93592349e+00 1.84738572e+00 1.86360134e+00 1.95429167e+00\n",
      " 1.91801770e+00 1.81722385e+00 1.80860925e+00 1.84210768e+00\n",
      " 1.94224988e+00 1.87599733e+00 1.85987318e+00 1.71152407e+00\n",
      " 1.66772224e+00 1.74506243e+00 1.79832205e+00 1.65885350e+00\n",
      " 1.63194010e+00 1.64449055e+00 1.78052111e+00 1.72173250e+00\n",
      " 1.54203142e+00 1.34081538e+00 1.42191496e+00 1.57178305e+00\n",
      " 1.66744405e+00 1.78839356e+00 1.56385937e+00 1.32333845e+00\n",
      " 1.20420241e+00 1.19979596e+00 1.34437180e+00 1.66518962e+00\n",
      " 1.67999924e+00 1.36923982e+00 1.00306628e+00 8.78963369e-01\n",
      " 1.16957204e+00 1.16322409e+00 1.27424103e+00 9.60981280e-01\n",
      " 6.61365098e-01 4.71895972e-01 4.47681463e-01 6.80914634e-01\n",
      " 7.42373961e-01 4.87510577e-01 3.98135361e-01 3.69944975e-01\n",
      " 3.80267078e-01 1.89107521e-01 7.58797489e-02 3.95120313e-02\n",
      " 2.77954929e-02 2.19704743e-02 1.82491234e-02 1.56191302e-02\n",
      " 1.36610230e-02 1.21350997e-02 1.09111055e-02 9.90838306e-03\n",
      " 9.07142423e-03 8.36178139e-03 7.75242387e-03 7.22325044e-03\n",
      " 6.75940737e-03 6.34980053e-03 5.98509307e-03 5.65884607e-03\n",
      " 5.36536016e-03 5.09970072e-03 4.85787583e-03 4.63683140e-03\n",
      " 4.43416510e-03 4.24773816e-03 4.07567567e-03 3.91635743e-03\n",
      " 3.76826893e-03 3.63031744e-03 3.50159118e-03 3.38121520e-03\n",
      " 3.26848524e-03 3.16274005e-03 3.06326961e-03 2.96953523e-03\n",
      " 2.88107134e-03 2.79745383e-03 2.71833423e-03 2.64331303e-03\n",
      " 2.57205830e-03 2.50433115e-03 2.43987495e-03 2.37844961e-03\n",
      " 2.31986057e-03 2.26393698e-03 2.21045931e-03 2.15934244e-03\n",
      " 2.11039925e-03 2.06350962e-03 2.01855990e-03 1.97542406e-03\n",
      " 1.93397668e-03 1.89413652e-03 1.85582920e-03 1.81896981e-03\n",
      " 1.78346016e-03 1.74922788e-03 1.71620650e-03 1.68436809e-03\n",
      " 1.65361351e-03 1.62390250e-03 1.59518347e-03 1.56739312e-03\n",
      " 1.54049256e-03 1.51445940e-03 1.48922403e-03 1.46478424e-03\n",
      " 1.44109168e-03 1.41811089e-03 1.39580042e-03 1.37414580e-03\n",
      " 1.35309467e-03 1.33265560e-03 1.31279409e-03 1.29346681e-03\n",
      " 1.27468319e-03 1.25639179e-03 1.23859158e-03 1.22127294e-03\n",
      " 1.20440383e-03 1.18796540e-03 1.17195841e-03 1.15633591e-03\n",
      " 1.14110792e-03 1.12625892e-03 1.11175086e-03 1.09759775e-03\n",
      " 1.08377446e-03 1.07028289e-03 1.05709873e-03 1.04421378e-03\n",
      " 1.03162625e-03 1.01933237e-03 1.00729583e-03 9.95528506e-04\n",
      " 9.84023098e-04 9.72756732e-04 9.61725338e-04 9.50933102e-04\n",
      " 9.40364861e-04 9.30018583e-04 9.19881236e-04 9.09955485e-04\n",
      " 9.00216674e-04 8.90688907e-04 8.81342910e-04 8.72175669e-04\n",
      " 8.63192003e-04 8.54382012e-04 8.45732616e-04 8.37244611e-04\n",
      " 8.28925997e-04 8.20746447e-04 8.12731718e-04 8.04853335e-04\n",
      " 7.97120592e-04 7.89530057e-04 7.82072061e-04 7.74746248e-04\n",
      " 7.67546945e-04 7.60478730e-04 7.53520255e-04 7.46689388e-04\n",
      " 7.39975320e-04 7.33367383e-04 7.26873591e-04 7.20486918e-04\n",
      " 7.14204327e-04 7.08026130e-04 7.01945554e-04 6.95966935e-04\n",
      " 6.90078788e-04 6.84286770e-04 6.78579509e-04 6.72968995e-04\n",
      " 6.67446939e-04 6.62002346e-04 6.56638358e-04 6.51366473e-04\n",
      " 6.46168255e-04 6.41043024e-04 6.36002555e-04 6.31027977e-04]\n",
      "train error:  [0.90699995 0.691      0.696      0.664      0.684      0.838\n",
      " 0.83900005 0.693      0.648      0.619      0.633      0.697\n",
      " 0.688      0.618      0.614      0.643      0.673      0.639\n",
      " 0.679      0.584      0.602      0.61499995 0.621      0.538\n",
      " 0.566      0.563      0.617      0.5730001  0.54700005 0.42999998\n",
      " 0.49700004 0.554      0.53       0.57       0.468      0.41200003\n",
      " 0.39       0.40399998 0.467      0.574      0.5400001  0.464\n",
      " 0.29599997 0.264      0.323      0.37899998 0.39800003 0.282\n",
      " 0.16699998 0.113      0.14099999 0.21300001 0.192      0.12\n",
      " 0.11400001 0.096      0.108      0.029      0.008      0.001\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "train send cost:  [   58531330   117062660   175593990   234125320   292656650   351187980\n",
      "   409719310   468250640   526781970   585313300   643844630   702375960\n",
      "   760907290   819438620   877969950   936501280   995032610  1053563940\n",
      "  1112095270  1170626600  1229157930  1287689260  1346220590  1404751920\n",
      "  1463283250  1521814580  1580345910  1638877240  1697408570  1755939900\n",
      "  1814471230  1873002560  1931533890  1990065220  2048596550  2107127880\n",
      "  2165659210  2224190540  2282721870  2341253200  2399784530  2458315860\n",
      "  2516847190  2575378520  2633909850  2692441180  2750972510  2809503840\n",
      "  2868035170  2926566500  2985097830  3043629160  3102160490  3160691820\n",
      "  3219223150  3277754480  3336285810  3394817140  3453348470  3511879800\n",
      "  3570411130  3628942460  3687473790  3746005120  3804536450  3863067780\n",
      "  3921599110  3980130440  4038661770  4097193100  4155724430  4214255760\n",
      "  4272787090  4331318420  4389849750  4448381080  4506912410  4565443740\n",
      "  4623975070  4682506400  4741037730  4799569060  4858100390  4916631720\n",
      "  4975163050  5033694380  5092225710  5150757040  5209288370  5267819700\n",
      "  5326351030  5384882360  5443413690  5501945020  5560476350  5619007680\n",
      "  5677539010  5736070340  5794601670  5853133000  5911664330  5970195660\n",
      "  6028726990  6087258320  6145789650  6204320980  6262852310  6321383640\n",
      "  6379914970  6438446300  6496977630  6555508960  6614040290  6672571620\n",
      "  6731102950  6789634280  6848165610  6906696940  6965228270  7023759600\n",
      "  7082290930  7140822260  7199353590  7257884920  7316416250  7374947580\n",
      "  7433478910  7492010240  7550541570  7609072900  7667604230  7726135560\n",
      "  7784666890  7843198220  7901729550  7960260880  8018792210  8077323540\n",
      "  8135854870  8194386200  8252917530  8311448860  8369980190  8428511520\n",
      "  8487042850  8545574180  8604105510  8662636840  8721168170  8779699500\n",
      "  8838230830  8896762160  8955293490  9013824820  9072356150  9130887480\n",
      "  9189418810  9247950140  9306481470  9365012800  9423544130  9482075460\n",
      "  9540606790  9599138120  9657669450  9716200780  9774732110  9833263440\n",
      "  9891794770  9950326100 10008857430 10067388760 10125920090 10184451420\n",
      " 10242982750 10301514080 10360045410 10418576740 10477108070 10535639400\n",
      " 10594170730 10652702060 10711233390 10769764720 10828296050 10886827380\n",
      " 10945358710 11003890040 11062421370 11120952700 11179484030 11238015360\n",
      " 11296546690 11355078020 11413609350 11472140680 11530672010 11589203340\n",
      " 11647734670 11706266000]\n",
      "train time:  [   5.6030729   12.6646809   19.7800884   25.7235658   31.5494387\n",
      "   37.2801664   44.1007713   51.3996715   59.3305106   67.1220806\n",
      "   74.0250544   81.148638    88.7001547   95.9150302  103.0321695\n",
      "  110.5972658  118.2949661  125.5981688  132.9003041  140.2865393\n",
      "  147.5061226  154.7267852  162.0902962  169.6197758  177.0293945\n",
      "  184.3064095  191.4965995  198.6167769  206.0767413  213.9136225\n",
      "  221.6285797  229.0665498  236.5056319  244.0329091  251.3104286\n",
      "  258.7148696  266.3353675  274.1481321  282.4951459  290.5339709\n",
      "  298.0246439  305.3978752  312.4804611  319.5934881  327.011847\n",
      "  334.2367631  341.5066166  348.7446226  356.0264982  363.3991944\n",
      "  370.8148825  378.5361027  386.3868263  393.7447786  401.2031344\n",
      "  408.8821437  416.2886078  424.0154872  431.9310875  439.6234393\n",
      "  447.3245892  454.8848171  462.5813373  470.389371   477.4177784\n",
      "  484.4882924  491.6098292  498.0758214  505.0926816  512.0621661\n",
      "  519.2827567  525.8868447  532.5806911  539.7742799  546.7412343\n",
      "  553.6959454  560.5427179  567.1785585  573.8248498  580.609629\n",
      "  587.1862521  595.3522183  603.1683391  609.819823   616.8868988\n",
      "  624.1740391  631.696156   639.2893782  646.6437501  653.7886594\n",
      "  661.1066902  668.381805   675.2343045  681.8060775  688.7172881\n",
      "  695.580848   702.9106703  710.1909896  717.1510075  723.9479833\n",
      "  730.5632419  737.1322248  743.5136047  749.9537807  756.2969348\n",
      "  762.8552917  769.2057617  775.7876674  782.1167578  788.5876583\n",
      "  795.0235772  801.6989638  808.2365068  814.8637676  821.7127129\n",
      "  828.9697393  836.2217341  843.45742    850.832914   858.0340616\n",
      "  865.3109042  872.2445482  879.2516202  886.3591762  894.1624486\n",
      "  902.3096482  910.8182119  917.735883   924.4860067  931.4075934\n",
      "  938.3808412  945.2218852  952.3363564  959.6880649  967.0918474\n",
      "  974.3100807  981.6805714  989.0741482  996.2466758 1003.775555\n",
      " 1011.0949407 1018.5530463 1025.3896066 1032.4710561 1039.6760779\n",
      " 1046.8791595 1054.8264833 1062.4532837 1069.7740484 1077.4977904\n",
      " 1085.0313853 1092.7320204 1100.5835259 1108.2924662 1115.7913975\n",
      " 1123.2413637 1130.3604782 1137.9986575 1145.0408629 1152.1694775\n",
      " 1160.1899629 1167.9867442 1175.6030357 1183.245827  1190.682582\n",
      " 1198.4950345 1206.258361  1214.535881  1223.3844539 1231.25303\n",
      " 1239.4043325 1245.8063719 1252.2562834 1258.9529603 1265.7698473\n",
      " 1272.5410516 1279.936295  1289.0383347 1296.0918228 1302.5007052\n",
      " 1308.7148879 1315.331262  1322.0468356 1329.6000974 1337.9277009\n",
      " 1344.6593803 1351.554345  1358.596451  1365.5441639 1372.4340987\n",
      " 1379.6105973 1386.7326738 1393.1789221 1399.7488307 1406.0151181\n",
      " 1412.4821227 1418.671448  1424.927079  1431.2021964 1437.508194 ]\n",
      "=======TEST RESULT=======\n",
      "test loss:  [0.00062612 0.0006213  0.00061654 0.00061185 0.00060722 0.00060267\n",
      " 0.00059817 0.00059374 0.00058937 0.00058506 0.00058081 0.00057661\n",
      " 0.00057247 0.00056839 0.00056436 0.00056039 0.00055647 0.0005526\n",
      " 0.00054877 0.00054501 0.00054128 0.0005376  0.00053398 0.0005304\n",
      " 0.00052686 0.00052337 0.00051992 0.00051651 0.00051315 0.00050982\n",
      " 0.00050654 0.00050329 0.0005001  0.00049693 0.0004938  0.00049071\n",
      " 0.00048765 0.00048463 0.00048165 0.00047869 0.00047578 0.00047289\n",
      " 0.00047004 0.00046722 0.00046443 0.00046168 0.00045896 0.00045626\n",
      " 0.0004536  0.00045096 0.00044835 0.00044577 0.00044322 0.00044069\n",
      " 0.00043819 0.00043573 0.00043328 0.00043086 0.00042847 0.00042609\n",
      " 0.00042375 0.00042143 0.00041913 0.00041686 0.00041461 0.00041238\n",
      " 0.00041017 0.000408   0.00040583 0.00040369 0.00040157 0.00039948\n",
      " 0.0003974  0.00039534 0.00039331 0.00039129 0.00038929 0.00038731\n",
      " 0.00038535 0.00038341 0.00038149 0.00037959 0.0003777  0.00037583\n",
      " 0.00037398 0.00037215 0.00037033 0.00036853 0.00036674 0.00036497\n",
      " 0.00036322 0.00036149 0.00035976 0.00035806 0.00035637 0.0003547\n",
      " 0.00035304 0.00035139 0.00034976 0.00034815 0.00034654 0.00034495\n",
      " 0.00034337 0.00034181 0.00034026 0.00033873 0.0003372  0.0003357\n",
      " 0.0003342  0.00033271 0.00033124 0.00032978 0.00032834 0.0003269\n",
      " 0.00032547 0.00032406 0.00032266 0.00032127 0.0003199  0.00031852\n",
      " 0.00031717 0.00031583 0.00031449 0.00031317 0.00031185 0.00031055\n",
      " 0.00030926 0.00030797 0.0003067  0.00030544 0.00030418 0.00030294\n",
      " 0.00030171 0.00030049 0.00029927 0.00029807 0.00029687 0.00029568\n",
      " 0.0002945  0.00029334 0.00029217 0.00029102 0.00028988 0.00028874\n",
      " 0.00028761 0.0002865  0.00028538 0.00028428 0.00028318 0.0002821\n",
      " 0.00028102 0.00027995 0.00027889 0.00027782 0.00027678 0.00027574\n",
      " 0.0002747  0.00027368 0.00027265 0.00027164 0.00027064 0.00026964\n",
      " 0.00026865 0.00026767 0.00026669 0.00026571 0.00026475 0.00026379\n",
      " 0.00026285 0.0002619  0.00026097 0.00026004 0.00025911 0.00025819\n",
      " 0.00025728 0.00025637 0.00025546 0.00025457 0.00025367 0.0002528\n",
      " 0.00025192 0.00025105 0.00025018 0.00024931 0.00024846 0.00024761\n",
      " 0.00024677 0.00024593 0.00024509 0.00024427 0.00024344 0.00024262\n",
      " 0.00024181 0.000241   0.0002402  0.00023941 0.00023861 0.00023783\n",
      " 0.00023704 0.00023627]\n",
      "test error:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test send cost:  [   58531330   117062660   175593990   234125320   292656650   351187980\n",
      "   409719310   468250640   526781970   585313300   643844630   702375960\n",
      "   760907290   819438620   877969950   936501280   995032610  1053563940\n",
      "  1112095270  1170626600  1229157930  1287689260  1346220590  1404751920\n",
      "  1463283250  1521814580  1580345910  1638877240  1697408570  1755939900\n",
      "  1814471230  1873002560  1931533890  1990065220  2048596550  2107127880\n",
      "  2165659210  2224190540  2282721870  2341253200  2399784530  2458315860\n",
      "  2516847190  2575378520  2633909850  2692441180  2750972510  2809503840\n",
      "  2868035170  2926566500  2985097830  3043629160  3102160490  3160691820\n",
      "  3219223150  3277754480  3336285810  3394817140  3453348470  3511879800\n",
      "  3570411130  3628942460  3687473790  3746005120  3804536450  3863067780\n",
      "  3921599110  3980130440  4038661770  4097193100  4155724430  4214255760\n",
      "  4272787090  4331318420  4389849750  4448381080  4506912410  4565443740\n",
      "  4623975070  4682506400  4741037730  4799569060  4858100390  4916631720\n",
      "  4975163050  5033694380  5092225710  5150757040  5209288370  5267819700\n",
      "  5326351030  5384882360  5443413690  5501945020  5560476350  5619007680\n",
      "  5677539010  5736070340  5794601670  5853133000  5911664330  5970195660\n",
      "  6028726990  6087258320  6145789650  6204320980  6262852310  6321383640\n",
      "  6379914970  6438446300  6496977630  6555508960  6614040290  6672571620\n",
      "  6731102950  6789634280  6848165610  6906696940  6965228270  7023759600\n",
      "  7082290930  7140822260  7199353590  7257884920  7316416250  7374947580\n",
      "  7433478910  7492010240  7550541570  7609072900  7667604230  7726135560\n",
      "  7784666890  7843198220  7901729550  7960260880  8018792210  8077323540\n",
      "  8135854870  8194386200  8252917530  8311448860  8369980190  8428511520\n",
      "  8487042850  8545574180  8604105510  8662636840  8721168170  8779699500\n",
      "  8838230830  8896762160  8955293490  9013824820  9072356150  9130887480\n",
      "  9189418810  9247950140  9306481470  9365012800  9423544130  9482075460\n",
      "  9540606790  9599138120  9657669450  9716200780  9774732110  9833263440\n",
      "  9891794770  9950326100 10008857430 10067388760 10125920090 10184451420\n",
      " 10242982750 10301514080 10360045410 10418576740 10477108070 10535639400\n",
      " 10594170730 10652702060 10711233390 10769764720 10828296050 10886827380\n",
      " 10945358710 11003890040 11062421370 11120952700 11179484030 11238015360\n",
      " 11296546690 11355078020 11413609350 11472140680 11530672010 11589203340\n",
      " 11647734670 11706266000]\n",
      "test time:  [   6.3432107   12.7859634   19.4112856   26.5201185   34.3080472\n",
      "   42.8601581   50.7950803   57.1912271   63.7597455   70.0694182\n",
      "   76.660291    83.3044341   91.1966346   98.2101406  105.7676523\n",
      "  112.770946   119.4747882  125.9928277  132.6102518  139.5580756\n",
      "  146.2706219  152.9515603  160.049273   167.0424753  173.486066\n",
      "  180.7000052  187.1433621  194.4396722  201.5450401  208.4092848\n",
      "  215.4752143  222.1599117  229.0623061  236.4263339  244.5522315\n",
      "  252.0148695  259.2748467  265.8280388  272.4272999  279.0760669\n",
      "  285.9825423  293.0974257  300.835129   308.0560344  315.3233959\n",
      "  321.9507505  328.9509993  335.617975   342.2333673  348.8040274\n",
      "  355.2604045  361.8053486  368.5178056  375.1378562  382.5282713\n",
      "  389.7301851  397.7407481  407.0067038  414.9251018  421.805898\n",
      "  428.8447537  436.07315    444.2164627  452.7543368  460.9999022\n",
      "  469.2080984  477.3688665  485.4355526  493.4934635  501.5168303\n",
      "  509.6019683  518.4436876  526.9916029  534.7940311  542.8286762\n",
      "  550.8378243  559.0945926  566.9569724  575.2008396  583.1551975\n",
      "  591.2936288  599.4163256  607.3852916  615.139443   623.5200056\n",
      "  632.3392403  640.6285401  648.4649046  656.3153619  664.1680107\n",
      "  672.2400012  680.234739   687.858412   696.4042371  704.792371\n",
      "  713.045471   721.1312153  728.8283391  736.6487419  744.4827765\n",
      "  752.4178804  760.0502232  768.0174476  775.8274326  783.526356\n",
      "  791.0390417  798.7900088  806.8765012  815.1332568  823.2612161\n",
      "  831.540333   839.4565056  847.1120832  854.5488498  862.0116062\n",
      "  869.579134   877.622931   885.8094868  893.8130161  902.0947425\n",
      "  910.8273464  919.4198828  927.6882905  935.8892902  944.5418263\n",
      "  952.6045485  960.4451547  968.3771552  976.0404357  983.9502512\n",
      "  991.9294132  999.8961033 1007.8740545 1015.5492451 1023.7359331\n",
      " 1031.6376656 1039.2767908 1046.9487139 1055.9772835 1064.0027891\n",
      " 1072.3062977 1079.5435598 1086.419786  1093.690846  1101.0950966\n",
      " 1108.4328163 1115.5600662 1122.7925469 1130.186099  1137.2260105\n",
      " 1144.9784052 1152.3323178 1159.2516165 1166.442157  1173.9294668\n",
      " 1181.3995259 1189.376985  1196.9812333 1204.2352075 1211.8267841\n",
      " 1219.2417912 1226.6650132 1234.2205847 1241.6923206 1249.0950191\n",
      " 1256.4652266 1263.5367192 1270.3533689 1276.9190649 1283.9085312\n",
      " 1291.2394365 1298.5259859 1305.7941767 1313.1575958 1321.0476577\n",
      " 1329.3068323 1336.9717334 1343.9287873 1350.6699235 1357.2884179\n",
      " 1363.8319712 1370.2446036 1376.4185964 1382.8533255 1389.2901877\n",
      " 1395.5408176 1402.1854175 1408.5803496 1415.1912287 1421.9642717\n",
      " 1428.601458  1434.8719368 1441.6788715 1447.7975542 1454.2788213\n",
      " 1461.0929464 1467.9063453 1474.8461297 1481.6707749 1489.2162002]\n",
      "filename:  homogeneous_CIFAR-10 Datset10local_update_epochs40epoch_result\n",
      "['train_loss', 'train_error', 'train_send_cost', 'train_time', 'test_loss', 'test_error', 'test_send_cost', 'test_time']\n",
      "=======TRAIN RESULT=======\n",
      "train loss:  [1.95174193e+00 1.70167189e+00 1.11625063e+00 4.63036511e-01\n",
      " 3.57587787e-01 1.05892487e-01 5.17183588e-02 1.87644526e-02\n",
      " 8.42088786e-03 5.60566255e-03 4.33247796e-03 3.53786191e-03\n",
      " 2.97861655e-03 2.56027608e-03 2.23512145e-03 1.97404202e-03\n",
      " 1.76111318e-03 1.58394901e-03 1.43440564e-03 1.30703145e-03\n",
      " 1.19723808e-03 1.10206696e-03 1.01867051e-03 9.45276287e-04\n",
      " 8.80203911e-04 8.22174273e-04 7.70241846e-04 7.23541171e-04\n",
      " 6.81388389e-04 6.43130423e-04 6.08333147e-04 5.76563278e-04\n",
      " 5.47469527e-04 5.20761012e-04 4.96156411e-04 4.73472499e-04\n",
      " 4.52463686e-04 4.32993512e-04 4.14933939e-04 3.98096235e-04]\n",
      "train error:  [6.1740005e-01 5.4100001e-01 3.4070006e-01 1.3329999e-01 9.6999988e-02\n",
      " 2.2499999e-02 9.8000001e-03 1.5999998e-03 9.9999990e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "train send cost:  [  58531330  117062660  175593990  234125320  292656650  351187980\n",
      "  409719310  468250640  526781970  585313300  643844630  702375960\n",
      "  760907290  819438620  877969950  936501280  995032610 1053563940\n",
      " 1112095270 1170626600 1229157930 1287689260 1346220590 1404751920\n",
      " 1463283250 1521814580 1580345910 1638877240 1697408570 1755939900\n",
      " 1814471230 1873002560 1931533890 1990065220 2048596550 2107127880\n",
      " 2165659210 2224190540 2282721870 2341253200]\n",
      "train time:  [  67.5152324  137.6233915  210.2782056  284.6200937  357.2536575\n",
      "  428.1262068  499.5194407  570.5356523  643.7998039  716.8538393\n",
      "  790.040309   865.7168599  943.3911319 1019.6949924 1099.3241767\n",
      " 1178.7043339 1256.8101247 1334.1990798 1415.1180451 1494.8494573\n",
      " 1573.2248025 1651.0256438 1730.1261544 1810.7125919 1888.5269811\n",
      " 1965.0321257 2042.6241431 2109.6387123 2178.6629503 2250.8321555\n",
      " 2326.3230804 2404.797577  2480.8279504 2552.0724389 2620.4423575\n",
      " 2695.1695429 2760.6329742 2823.5858999 2887.6134063 2951.0938386]\n",
      "=======TEST RESULT=======\n",
      "test loss:  [0.00038239 0.00036771 0.00035397 0.00034109 0.00032899 0.00031761\n",
      " 0.0003069  0.00029679 0.00028725 0.00027823 0.00026969 0.00026159\n",
      " 0.00025391 0.00024662 0.00023968 0.00023308 0.00022678 0.00022079\n",
      " 0.00021506 0.00020959 0.00020436 0.00019936 0.00019457 0.00018998\n",
      " 0.00018557 0.00018135 0.00017729 0.00017338 0.00016963 0.00016602\n",
      " 0.00016255 0.00015921 0.00015598 0.00015287 0.00014987 0.00014697\n",
      " 0.00014418 0.00014147 0.00013886 0.00013633]\n",
      "test error:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test send cost:  [  58531330  117062660  175593990  234125320  292656650  351187980\n",
      "  409719310  468250640  526781970  585313300  643844630  702375960\n",
      "  760907290  819438620  877969950  936501280  995032610 1053563940\n",
      " 1112095270 1170626600 1229157930 1287689260 1346220590 1404751920\n",
      " 1463283250 1521814580 1580345910 1638877240 1697408570 1755939900\n",
      " 1814471230 1873002560 1931533890 1990065220 2048596550 2107127880\n",
      " 2165659210 2224190540 2282721870 2341253200]\n",
      "test time:  [  63.2507921  125.3527145  186.8330805  249.4306678  558.4021274\n",
      "  811.7099674 1064.201226  1352.6029719 1707.2500227 1783.604386\n",
      " 1863.5326165 1944.5182872 2025.3096033 2108.1402425 2176.399212\n",
      " 2237.6593332 2299.863637  2362.2798447 2426.1781745 2488.1323764\n",
      " 2551.8303353 2616.1388762 2687.1371549 2753.2083663 2818.7832783\n",
      " 2885.1188481 2949.3728496 3016.1307014 3077.0327542 3150.1872859\n",
      " 3227.1463912 3292.4851017 3355.7958308 3417.7649334 3498.0290629\n",
      " 3588.4743668 3653.0520495 3713.647254  3774.7343846 3835.7274562]\n"
     ]
    }
   ],
   "source": [
    "num_epochs_list = [200, 40]\n",
    "open_list = [1, 10]\n",
    "experiment_type = 'local_update_epochs'\n",
    "\n",
    "for n in range(len(open_list)):\n",
    "    num_epochs = num_epochs_list[n]\n",
    "    total_filename = \"homogeneous_{}{}{}{}epoch_result\".format(dataset_name, open_list[n], experiment_type, num_epochs) #update name of result .npz file\n",
    "    result = np.load(total_filename) #load data into 'result'\n",
    "    print('filename: ', total_filename)\n",
    "    print(result.files) #show attributes inside 'result'\n",
    "    data_train_loss = result['train_loss']    #np.load(total_filename['train_loss'])\n",
    "    data_train_error = result['train_error']    #np.load(total_filename['train_error'])\n",
    "    data_train_send_cost = result['train_send_cost']    #np.load(total_filename['train_send_cost'])\n",
    "    data_train_time = result['train_time']    #np.load(total_filename['train_time'])\n",
    "    data_test_loss = result['test_loss']    #np.load(total_filename['test_loss'])\n",
    "    data_test_error = result['test_error']    #np.load(total_filename['test_error'])\n",
    "    data_test_send_cost = result['test_send_cost']    #np.load(total_filename['test_send_cost'])\n",
    "    data_test_time = result['test_time']    #np.load(total_filename['test_time'])\n",
    "\n",
    "    print(\"=======TRAIN RESULT=======\")\n",
    "    print(\"train loss: \", data_train_loss)\n",
    "    print(\"train error: \", data_train_error)\n",
    "    print(\"train send cost: \", data_train_send_cost)\n",
    "    print(\"train time: \", data_train_time)\n",
    "    print(\"=======TEST RESULT=======\")\n",
    "    print(\"test loss: \", data_test_loss)\n",
    "    print(\"test error: \", data_test_error)\n",
    "    print(\"test send cost: \", data_test_send_cost)\n",
    "    print(\"test time: \", data_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  homogeneous_CIFAR-10 Datset1local_update_epochs200epoch_result\n",
      "['train_loss', 'train_error', 'train_send_cost', 'train_time', 'test_loss', 'test_error', 'test_send_cost', 'test_time']\n",
      "=======TRAIN RESULT=======\n",
      "train loss:  [2.30633025e+00 2.18515327e+00 2.10994499e+00 2.02539656e+00\n",
      " 2.00944207e+00 2.31130626e+00 2.25889239e+00 2.04337673e+00\n",
      " 1.93592349e+00 1.84738572e+00 1.86360134e+00 1.95429167e+00\n",
      " 1.91801770e+00 1.81722385e+00 1.80860925e+00 1.84210768e+00\n",
      " 1.94224988e+00 1.87599733e+00 1.85987318e+00 1.71152407e+00\n",
      " 1.66772224e+00 1.74506243e+00 1.79832205e+00 1.65885350e+00\n",
      " 1.63194010e+00 1.64449055e+00 1.78052111e+00 1.72173250e+00\n",
      " 1.54203142e+00 1.34081538e+00 1.42191496e+00 1.57178305e+00\n",
      " 1.66744405e+00 1.78839356e+00 1.56385937e+00 1.32333845e+00\n",
      " 1.20420241e+00 1.19979596e+00 1.34437180e+00 1.66518962e+00\n",
      " 1.67999924e+00 1.36923982e+00 1.00306628e+00 8.78963369e-01\n",
      " 1.16957204e+00 1.16322409e+00 1.27424103e+00 9.60981280e-01\n",
      " 6.61365098e-01 4.71895972e-01 4.47681463e-01 6.80914634e-01\n",
      " 7.42373961e-01 4.87510577e-01 3.98135361e-01 3.69944975e-01\n",
      " 3.80267078e-01 1.89107521e-01 7.58797489e-02 3.95120313e-02\n",
      " 2.77954929e-02 2.19704743e-02 1.82491234e-02 1.56191302e-02\n",
      " 1.36610230e-02 1.21350997e-02 1.09111055e-02 9.90838306e-03\n",
      " 9.07142423e-03 8.36178139e-03 7.75242387e-03 7.22325044e-03\n",
      " 6.75940737e-03 6.34980053e-03 5.98509307e-03 5.65884607e-03\n",
      " 5.36536016e-03 5.09970072e-03 4.85787583e-03 4.63683140e-03\n",
      " 4.43416510e-03 4.24773816e-03 4.07567567e-03 3.91635743e-03\n",
      " 3.76826893e-03 3.63031744e-03 3.50159118e-03 3.38121520e-03\n",
      " 3.26848524e-03 3.16274005e-03 3.06326961e-03 2.96953523e-03\n",
      " 2.88107134e-03 2.79745383e-03 2.71833423e-03 2.64331303e-03\n",
      " 2.57205830e-03 2.50433115e-03 2.43987495e-03 2.37844961e-03\n",
      " 2.31986057e-03 2.26393698e-03 2.21045931e-03 2.15934244e-03\n",
      " 2.11039925e-03 2.06350962e-03 2.01855990e-03 1.97542406e-03\n",
      " 1.93397668e-03 1.89413652e-03 1.85582920e-03 1.81896981e-03\n",
      " 1.78346016e-03 1.74922788e-03 1.71620650e-03 1.68436809e-03\n",
      " 1.65361351e-03 1.62390250e-03 1.59518347e-03 1.56739312e-03\n",
      " 1.54049256e-03 1.51445940e-03 1.48922403e-03 1.46478424e-03\n",
      " 1.44109168e-03 1.41811089e-03 1.39580042e-03 1.37414580e-03\n",
      " 1.35309467e-03 1.33265560e-03 1.31279409e-03 1.29346681e-03\n",
      " 1.27468319e-03 1.25639179e-03 1.23859158e-03 1.22127294e-03\n",
      " 1.20440383e-03 1.18796540e-03 1.17195841e-03 1.15633591e-03\n",
      " 1.14110792e-03 1.12625892e-03 1.11175086e-03 1.09759775e-03\n",
      " 1.08377446e-03 1.07028289e-03 1.05709873e-03 1.04421378e-03\n",
      " 1.03162625e-03 1.01933237e-03 1.00729583e-03 9.95528506e-04\n",
      " 9.84023098e-04 9.72756732e-04 9.61725338e-04 9.50933102e-04\n",
      " 9.40364861e-04 9.30018583e-04 9.19881236e-04 9.09955485e-04\n",
      " 9.00216674e-04 8.90688907e-04 8.81342910e-04 8.72175669e-04\n",
      " 8.63192003e-04 8.54382012e-04 8.45732616e-04 8.37244611e-04\n",
      " 8.28925997e-04 8.20746447e-04 8.12731718e-04 8.04853335e-04\n",
      " 7.97120592e-04 7.89530057e-04 7.82072061e-04 7.74746248e-04\n",
      " 7.67546945e-04 7.60478730e-04 7.53520255e-04 7.46689388e-04\n",
      " 7.39975320e-04 7.33367383e-04 7.26873591e-04 7.20486918e-04\n",
      " 7.14204327e-04 7.08026130e-04 7.01945554e-04 6.95966935e-04\n",
      " 6.90078788e-04 6.84286770e-04 6.78579509e-04 6.72968995e-04\n",
      " 6.67446939e-04 6.62002346e-04 6.56638358e-04 6.51366473e-04\n",
      " 6.46168255e-04 6.41043024e-04 6.36002555e-04 6.31027977e-04]\n",
      "train error:  [0.90699995 0.691      0.696      0.664      0.684      0.838\n",
      " 0.83900005 0.693      0.648      0.619      0.633      0.697\n",
      " 0.688      0.618      0.614      0.643      0.673      0.639\n",
      " 0.679      0.584      0.602      0.61499995 0.621      0.538\n",
      " 0.566      0.563      0.617      0.5730001  0.54700005 0.42999998\n",
      " 0.49700004 0.554      0.53       0.57       0.468      0.41200003\n",
      " 0.39       0.40399998 0.467      0.574      0.5400001  0.464\n",
      " 0.29599997 0.264      0.323      0.37899998 0.39800003 0.282\n",
      " 0.16699998 0.113      0.14099999 0.21300001 0.192      0.12\n",
      " 0.11400001 0.096      0.108      0.029      0.008      0.001\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "train send cost:  [   58531330   117062660   175593990   234125320   292656650   351187980\n",
      "   409719310   468250640   526781970   585313300   643844630   702375960\n",
      "   760907290   819438620   877969950   936501280   995032610  1053563940\n",
      "  1112095270  1170626600  1229157930  1287689260  1346220590  1404751920\n",
      "  1463283250  1521814580  1580345910  1638877240  1697408570  1755939900\n",
      "  1814471230  1873002560  1931533890  1990065220  2048596550  2107127880\n",
      "  2165659210  2224190540  2282721870  2341253200  2399784530  2458315860\n",
      "  2516847190  2575378520  2633909850  2692441180  2750972510  2809503840\n",
      "  2868035170  2926566500  2985097830  3043629160  3102160490  3160691820\n",
      "  3219223150  3277754480  3336285810  3394817140  3453348470  3511879800\n",
      "  3570411130  3628942460  3687473790  3746005120  3804536450  3863067780\n",
      "  3921599110  3980130440  4038661770  4097193100  4155724430  4214255760\n",
      "  4272787090  4331318420  4389849750  4448381080  4506912410  4565443740\n",
      "  4623975070  4682506400  4741037730  4799569060  4858100390  4916631720\n",
      "  4975163050  5033694380  5092225710  5150757040  5209288370  5267819700\n",
      "  5326351030  5384882360  5443413690  5501945020  5560476350  5619007680\n",
      "  5677539010  5736070340  5794601670  5853133000  5911664330  5970195660\n",
      "  6028726990  6087258320  6145789650  6204320980  6262852310  6321383640\n",
      "  6379914970  6438446300  6496977630  6555508960  6614040290  6672571620\n",
      "  6731102950  6789634280  6848165610  6906696940  6965228270  7023759600\n",
      "  7082290930  7140822260  7199353590  7257884920  7316416250  7374947580\n",
      "  7433478910  7492010240  7550541570  7609072900  7667604230  7726135560\n",
      "  7784666890  7843198220  7901729550  7960260880  8018792210  8077323540\n",
      "  8135854870  8194386200  8252917530  8311448860  8369980190  8428511520\n",
      "  8487042850  8545574180  8604105510  8662636840  8721168170  8779699500\n",
      "  8838230830  8896762160  8955293490  9013824820  9072356150  9130887480\n",
      "  9189418810  9247950140  9306481470  9365012800  9423544130  9482075460\n",
      "  9540606790  9599138120  9657669450  9716200780  9774732110  9833263440\n",
      "  9891794770  9950326100 10008857430 10067388760 10125920090 10184451420\n",
      " 10242982750 10301514080 10360045410 10418576740 10477108070 10535639400\n",
      " 10594170730 10652702060 10711233390 10769764720 10828296050 10886827380\n",
      " 10945358710 11003890040 11062421370 11120952700 11179484030 11238015360\n",
      " 11296546690 11355078020 11413609350 11472140680 11530672010 11589203340\n",
      " 11647734670 11706266000]\n",
      "train time:  [   5.6030729   12.6646809   19.7800884   25.7235658   31.5494387\n",
      "   37.2801664   44.1007713   51.3996715   59.3305106   67.1220806\n",
      "   74.0250544   81.148638    88.7001547   95.9150302  103.0321695\n",
      "  110.5972658  118.2949661  125.5981688  132.9003041  140.2865393\n",
      "  147.5061226  154.7267852  162.0902962  169.6197758  177.0293945\n",
      "  184.3064095  191.4965995  198.6167769  206.0767413  213.9136225\n",
      "  221.6285797  229.0665498  236.5056319  244.0329091  251.3104286\n",
      "  258.7148696  266.3353675  274.1481321  282.4951459  290.5339709\n",
      "  298.0246439  305.3978752  312.4804611  319.5934881  327.011847\n",
      "  334.2367631  341.5066166  348.7446226  356.0264982  363.3991944\n",
      "  370.8148825  378.5361027  386.3868263  393.7447786  401.2031344\n",
      "  408.8821437  416.2886078  424.0154872  431.9310875  439.6234393\n",
      "  447.3245892  454.8848171  462.5813373  470.389371   477.4177784\n",
      "  484.4882924  491.6098292  498.0758214  505.0926816  512.0621661\n",
      "  519.2827567  525.8868447  532.5806911  539.7742799  546.7412343\n",
      "  553.6959454  560.5427179  567.1785585  573.8248498  580.609629\n",
      "  587.1862521  595.3522183  603.1683391  609.819823   616.8868988\n",
      "  624.1740391  631.696156   639.2893782  646.6437501  653.7886594\n",
      "  661.1066902  668.381805   675.2343045  681.8060775  688.7172881\n",
      "  695.580848   702.9106703  710.1909896  717.1510075  723.9479833\n",
      "  730.5632419  737.1322248  743.5136047  749.9537807  756.2969348\n",
      "  762.8552917  769.2057617  775.7876674  782.1167578  788.5876583\n",
      "  795.0235772  801.6989638  808.2365068  814.8637676  821.7127129\n",
      "  828.9697393  836.2217341  843.45742    850.832914   858.0340616\n",
      "  865.3109042  872.2445482  879.2516202  886.3591762  894.1624486\n",
      "  902.3096482  910.8182119  917.735883   924.4860067  931.4075934\n",
      "  938.3808412  945.2218852  952.3363564  959.6880649  967.0918474\n",
      "  974.3100807  981.6805714  989.0741482  996.2466758 1003.775555\n",
      " 1011.0949407 1018.5530463 1025.3896066 1032.4710561 1039.6760779\n",
      " 1046.8791595 1054.8264833 1062.4532837 1069.7740484 1077.4977904\n",
      " 1085.0313853 1092.7320204 1100.5835259 1108.2924662 1115.7913975\n",
      " 1123.2413637 1130.3604782 1137.9986575 1145.0408629 1152.1694775\n",
      " 1160.1899629 1167.9867442 1175.6030357 1183.245827  1190.682582\n",
      " 1198.4950345 1206.258361  1214.535881  1223.3844539 1231.25303\n",
      " 1239.4043325 1245.8063719 1252.2562834 1258.9529603 1265.7698473\n",
      " 1272.5410516 1279.936295  1289.0383347 1296.0918228 1302.5007052\n",
      " 1308.7148879 1315.331262  1322.0468356 1329.6000974 1337.9277009\n",
      " 1344.6593803 1351.554345  1358.596451  1365.5441639 1372.4340987\n",
      " 1379.6105973 1386.7326738 1393.1789221 1399.7488307 1406.0151181\n",
      " 1412.4821227 1418.671448  1424.927079  1431.2021964 1437.508194 ]\n",
      "=======TEST RESULT=======\n",
      "test loss:  [0.00062612 0.0006213  0.00061654 0.00061185 0.00060722 0.00060267\n",
      " 0.00059817 0.00059374 0.00058937 0.00058506 0.00058081 0.00057661\n",
      " 0.00057247 0.00056839 0.00056436 0.00056039 0.00055647 0.0005526\n",
      " 0.00054877 0.00054501 0.00054128 0.0005376  0.00053398 0.0005304\n",
      " 0.00052686 0.00052337 0.00051992 0.00051651 0.00051315 0.00050982\n",
      " 0.00050654 0.00050329 0.0005001  0.00049693 0.0004938  0.00049071\n",
      " 0.00048765 0.00048463 0.00048165 0.00047869 0.00047578 0.00047289\n",
      " 0.00047004 0.00046722 0.00046443 0.00046168 0.00045896 0.00045626\n",
      " 0.0004536  0.00045096 0.00044835 0.00044577 0.00044322 0.00044069\n",
      " 0.00043819 0.00043573 0.00043328 0.00043086 0.00042847 0.00042609\n",
      " 0.00042375 0.00042143 0.00041913 0.00041686 0.00041461 0.00041238\n",
      " 0.00041017 0.000408   0.00040583 0.00040369 0.00040157 0.00039948\n",
      " 0.0003974  0.00039534 0.00039331 0.00039129 0.00038929 0.00038731\n",
      " 0.00038535 0.00038341 0.00038149 0.00037959 0.0003777  0.00037583\n",
      " 0.00037398 0.00037215 0.00037033 0.00036853 0.00036674 0.00036497\n",
      " 0.00036322 0.00036149 0.00035976 0.00035806 0.00035637 0.0003547\n",
      " 0.00035304 0.00035139 0.00034976 0.00034815 0.00034654 0.00034495\n",
      " 0.00034337 0.00034181 0.00034026 0.00033873 0.0003372  0.0003357\n",
      " 0.0003342  0.00033271 0.00033124 0.00032978 0.00032834 0.0003269\n",
      " 0.00032547 0.00032406 0.00032266 0.00032127 0.0003199  0.00031852\n",
      " 0.00031717 0.00031583 0.00031449 0.00031317 0.00031185 0.00031055\n",
      " 0.00030926 0.00030797 0.0003067  0.00030544 0.00030418 0.00030294\n",
      " 0.00030171 0.00030049 0.00029927 0.00029807 0.00029687 0.00029568\n",
      " 0.0002945  0.00029334 0.00029217 0.00029102 0.00028988 0.00028874\n",
      " 0.00028761 0.0002865  0.00028538 0.00028428 0.00028318 0.0002821\n",
      " 0.00028102 0.00027995 0.00027889 0.00027782 0.00027678 0.00027574\n",
      " 0.0002747  0.00027368 0.00027265 0.00027164 0.00027064 0.00026964\n",
      " 0.00026865 0.00026767 0.00026669 0.00026571 0.00026475 0.00026379\n",
      " 0.00026285 0.0002619  0.00026097 0.00026004 0.00025911 0.00025819\n",
      " 0.00025728 0.00025637 0.00025546 0.00025457 0.00025367 0.0002528\n",
      " 0.00025192 0.00025105 0.00025018 0.00024931 0.00024846 0.00024761\n",
      " 0.00024677 0.00024593 0.00024509 0.00024427 0.00024344 0.00024262\n",
      " 0.00024181 0.000241   0.0002402  0.00023941 0.00023861 0.00023783\n",
      " 0.00023704 0.00023627]\n",
      "test error:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test send cost:  [   58531330   117062660   175593990   234125320   292656650   351187980\n",
      "   409719310   468250640   526781970   585313300   643844630   702375960\n",
      "   760907290   819438620   877969950   936501280   995032610  1053563940\n",
      "  1112095270  1170626600  1229157930  1287689260  1346220590  1404751920\n",
      "  1463283250  1521814580  1580345910  1638877240  1697408570  1755939900\n",
      "  1814471230  1873002560  1931533890  1990065220  2048596550  2107127880\n",
      "  2165659210  2224190540  2282721870  2341253200  2399784530  2458315860\n",
      "  2516847190  2575378520  2633909850  2692441180  2750972510  2809503840\n",
      "  2868035170  2926566500  2985097830  3043629160  3102160490  3160691820\n",
      "  3219223150  3277754480  3336285810  3394817140  3453348470  3511879800\n",
      "  3570411130  3628942460  3687473790  3746005120  3804536450  3863067780\n",
      "  3921599110  3980130440  4038661770  4097193100  4155724430  4214255760\n",
      "  4272787090  4331318420  4389849750  4448381080  4506912410  4565443740\n",
      "  4623975070  4682506400  4741037730  4799569060  4858100390  4916631720\n",
      "  4975163050  5033694380  5092225710  5150757040  5209288370  5267819700\n",
      "  5326351030  5384882360  5443413690  5501945020  5560476350  5619007680\n",
      "  5677539010  5736070340  5794601670  5853133000  5911664330  5970195660\n",
      "  6028726990  6087258320  6145789650  6204320980  6262852310  6321383640\n",
      "  6379914970  6438446300  6496977630  6555508960  6614040290  6672571620\n",
      "  6731102950  6789634280  6848165610  6906696940  6965228270  7023759600\n",
      "  7082290930  7140822260  7199353590  7257884920  7316416250  7374947580\n",
      "  7433478910  7492010240  7550541570  7609072900  7667604230  7726135560\n",
      "  7784666890  7843198220  7901729550  7960260880  8018792210  8077323540\n",
      "  8135854870  8194386200  8252917530  8311448860  8369980190  8428511520\n",
      "  8487042850  8545574180  8604105510  8662636840  8721168170  8779699500\n",
      "  8838230830  8896762160  8955293490  9013824820  9072356150  9130887480\n",
      "  9189418810  9247950140  9306481470  9365012800  9423544130  9482075460\n",
      "  9540606790  9599138120  9657669450  9716200780  9774732110  9833263440\n",
      "  9891794770  9950326100 10008857430 10067388760 10125920090 10184451420\n",
      " 10242982750 10301514080 10360045410 10418576740 10477108070 10535639400\n",
      " 10594170730 10652702060 10711233390 10769764720 10828296050 10886827380\n",
      " 10945358710 11003890040 11062421370 11120952700 11179484030 11238015360\n",
      " 11296546690 11355078020 11413609350 11472140680 11530672010 11589203340\n",
      " 11647734670 11706266000]\n",
      "test time:  [   6.3432107   12.7859634   19.4112856   26.5201185   34.3080472\n",
      "   42.8601581   50.7950803   57.1912271   63.7597455   70.0694182\n",
      "   76.660291    83.3044341   91.1966346   98.2101406  105.7676523\n",
      "  112.770946   119.4747882  125.9928277  132.6102518  139.5580756\n",
      "  146.2706219  152.9515603  160.049273   167.0424753  173.486066\n",
      "  180.7000052  187.1433621  194.4396722  201.5450401  208.4092848\n",
      "  215.4752143  222.1599117  229.0623061  236.4263339  244.5522315\n",
      "  252.0148695  259.2748467  265.8280388  272.4272999  279.0760669\n",
      "  285.9825423  293.0974257  300.835129   308.0560344  315.3233959\n",
      "  321.9507505  328.9509993  335.617975   342.2333673  348.8040274\n",
      "  355.2604045  361.8053486  368.5178056  375.1378562  382.5282713\n",
      "  389.7301851  397.7407481  407.0067038  414.9251018  421.805898\n",
      "  428.8447537  436.07315    444.2164627  452.7543368  460.9999022\n",
      "  469.2080984  477.3688665  485.4355526  493.4934635  501.5168303\n",
      "  509.6019683  518.4436876  526.9916029  534.7940311  542.8286762\n",
      "  550.8378243  559.0945926  566.9569724  575.2008396  583.1551975\n",
      "  591.2936288  599.4163256  607.3852916  615.139443   623.5200056\n",
      "  632.3392403  640.6285401  648.4649046  656.3153619  664.1680107\n",
      "  672.2400012  680.234739   687.858412   696.4042371  704.792371\n",
      "  713.045471   721.1312153  728.8283391  736.6487419  744.4827765\n",
      "  752.4178804  760.0502232  768.0174476  775.8274326  783.526356\n",
      "  791.0390417  798.7900088  806.8765012  815.1332568  823.2612161\n",
      "  831.540333   839.4565056  847.1120832  854.5488498  862.0116062\n",
      "  869.579134   877.622931   885.8094868  893.8130161  902.0947425\n",
      "  910.8273464  919.4198828  927.6882905  935.8892902  944.5418263\n",
      "  952.6045485  960.4451547  968.3771552  976.0404357  983.9502512\n",
      "  991.9294132  999.8961033 1007.8740545 1015.5492451 1023.7359331\n",
      " 1031.6376656 1039.2767908 1046.9487139 1055.9772835 1064.0027891\n",
      " 1072.3062977 1079.5435598 1086.419786  1093.690846  1101.0950966\n",
      " 1108.4328163 1115.5600662 1122.7925469 1130.186099  1137.2260105\n",
      " 1144.9784052 1152.3323178 1159.2516165 1166.442157  1173.9294668\n",
      " 1181.3995259 1189.376985  1196.9812333 1204.2352075 1211.8267841\n",
      " 1219.2417912 1226.6650132 1234.2205847 1241.6923206 1249.0950191\n",
      " 1256.4652266 1263.5367192 1270.3533689 1276.9190649 1283.9085312\n",
      " 1291.2394365 1298.5259859 1305.7941767 1313.1575958 1321.0476577\n",
      " 1329.3068323 1336.9717334 1343.9287873 1350.6699235 1357.2884179\n",
      " 1363.8319712 1370.2446036 1376.4185964 1382.8533255 1389.2901877\n",
      " 1395.5408176 1402.1854175 1408.5803496 1415.1912287 1421.9642717\n",
      " 1428.601458  1434.8719368 1441.6788715 1447.7975542 1454.2788213\n",
      " 1461.0929464 1467.9063453 1474.8461297 1481.6707749 1489.2162002]\n",
      "=======TRAIN RESULT=======\n",
      "train loss:  [2.30633025e+00 2.18515327e+00 2.10994499e+00 2.02539656e+00\n",
      " 2.00944207e+00 2.31130626e+00 2.25889239e+00 2.04337673e+00\n",
      " 1.93592349e+00 1.84738572e+00 1.86360134e+00 1.95429167e+00\n",
      " 1.91801770e+00 1.81722385e+00 1.80860925e+00 1.84210768e+00\n",
      " 1.94224988e+00 1.87599733e+00 1.85987318e+00 1.71152407e+00\n",
      " 1.66772224e+00 1.74506243e+00 1.79832205e+00 1.65885350e+00\n",
      " 1.63194010e+00 1.64449055e+00 1.78052111e+00 1.72173250e+00\n",
      " 1.54203142e+00 1.34081538e+00 1.42191496e+00 1.57178305e+00\n",
      " 1.66744405e+00 1.78839356e+00 1.56385937e+00 1.32333845e+00\n",
      " 1.20420241e+00 1.19979596e+00 1.34437180e+00 1.66518962e+00\n",
      " 1.67999924e+00 1.36923982e+00 1.00306628e+00 8.78963369e-01\n",
      " 1.16957204e+00 1.16322409e+00 1.27424103e+00 9.60981280e-01\n",
      " 6.61365098e-01 4.71895972e-01 4.47681463e-01 6.80914634e-01\n",
      " 7.42373961e-01 4.87510577e-01 3.98135361e-01 3.69944975e-01\n",
      " 3.80267078e-01 1.89107521e-01 7.58797489e-02 3.95120313e-02\n",
      " 2.77954929e-02 2.19704743e-02 1.82491234e-02 1.56191302e-02\n",
      " 1.36610230e-02 1.21350997e-02 1.09111055e-02 9.90838306e-03\n",
      " 9.07142423e-03 8.36178139e-03 7.75242387e-03 7.22325044e-03\n",
      " 6.75940737e-03 6.34980053e-03 5.98509307e-03 5.65884607e-03\n",
      " 5.36536016e-03 5.09970072e-03 4.85787583e-03 4.63683140e-03\n",
      " 4.43416510e-03 4.24773816e-03 4.07567567e-03 3.91635743e-03\n",
      " 3.76826893e-03 3.63031744e-03 3.50159118e-03 3.38121520e-03\n",
      " 3.26848524e-03 3.16274005e-03 3.06326961e-03 2.96953523e-03\n",
      " 2.88107134e-03 2.79745383e-03 2.71833423e-03 2.64331303e-03\n",
      " 2.57205830e-03 2.50433115e-03 2.43987495e-03 2.37844961e-03\n",
      " 2.31986057e-03 2.26393698e-03 2.21045931e-03 2.15934244e-03\n",
      " 2.11039925e-03 2.06350962e-03 2.01855990e-03 1.97542406e-03\n",
      " 1.93397668e-03 1.89413652e-03 1.85582920e-03 1.81896981e-03\n",
      " 1.78346016e-03 1.74922788e-03 1.71620650e-03 1.68436809e-03\n",
      " 1.65361351e-03 1.62390250e-03 1.59518347e-03 1.56739312e-03\n",
      " 1.54049256e-03 1.51445940e-03 1.48922403e-03 1.46478424e-03\n",
      " 1.44109168e-03 1.41811089e-03 1.39580042e-03 1.37414580e-03\n",
      " 1.35309467e-03 1.33265560e-03 1.31279409e-03 1.29346681e-03\n",
      " 1.27468319e-03 1.25639179e-03 1.23859158e-03 1.22127294e-03\n",
      " 1.20440383e-03 1.18796540e-03 1.17195841e-03 1.15633591e-03\n",
      " 1.14110792e-03 1.12625892e-03 1.11175086e-03 1.09759775e-03\n",
      " 1.08377446e-03 1.07028289e-03 1.05709873e-03 1.04421378e-03\n",
      " 1.03162625e-03 1.01933237e-03 1.00729583e-03 9.95528506e-04\n",
      " 9.84023098e-04 9.72756732e-04 9.61725338e-04 9.50933102e-04\n",
      " 9.40364861e-04 9.30018583e-04 9.19881236e-04 9.09955485e-04\n",
      " 9.00216674e-04 8.90688907e-04 8.81342910e-04 8.72175669e-04\n",
      " 8.63192003e-04 8.54382012e-04 8.45732616e-04 8.37244611e-04\n",
      " 8.28925997e-04 8.20746447e-04 8.12731718e-04 8.04853335e-04\n",
      " 7.97120592e-04 7.89530057e-04 7.82072061e-04 7.74746248e-04\n",
      " 7.67546945e-04 7.60478730e-04 7.53520255e-04 7.46689388e-04\n",
      " 7.39975320e-04 7.33367383e-04 7.26873591e-04 7.20486918e-04\n",
      " 7.14204327e-04 7.08026130e-04 7.01945554e-04 6.95966935e-04\n",
      " 6.90078788e-04 6.84286770e-04 6.78579509e-04 6.72968995e-04\n",
      " 6.67446939e-04 6.62002346e-04 6.56638358e-04 6.51366473e-04\n",
      " 6.46168255e-04 6.41043024e-04 6.36002555e-04 6.31027977e-04]\n",
      "train error:  [0.90699995 0.691      0.696      0.664      0.684      0.838\n",
      " 0.83900005 0.693      0.648      0.619      0.633      0.697\n",
      " 0.688      0.618      0.614      0.643      0.673      0.639\n",
      " 0.679      0.584      0.602      0.61499995 0.621      0.538\n",
      " 0.566      0.563      0.617      0.5730001  0.54700005 0.42999998\n",
      " 0.49700004 0.554      0.53       0.57       0.468      0.41200003\n",
      " 0.39       0.40399998 0.467      0.574      0.5400001  0.464\n",
      " 0.29599997 0.264      0.323      0.37899998 0.39800003 0.282\n",
      " 0.16699998 0.113      0.14099999 0.21300001 0.192      0.12\n",
      " 0.11400001 0.096      0.108      0.029      0.008      0.001\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "train send cost:  [   58531330   117062660   175593990   234125320   292656650   351187980\n",
      "   409719310   468250640   526781970   585313300   643844630   702375960\n",
      "   760907290   819438620   877969950   936501280   995032610  1053563940\n",
      "  1112095270  1170626600  1229157930  1287689260  1346220590  1404751920\n",
      "  1463283250  1521814580  1580345910  1638877240  1697408570  1755939900\n",
      "  1814471230  1873002560  1931533890  1990065220  2048596550  2107127880\n",
      "  2165659210  2224190540  2282721870  2341253200  2399784530  2458315860\n",
      "  2516847190  2575378520  2633909850  2692441180  2750972510  2809503840\n",
      "  2868035170  2926566500  2985097830  3043629160  3102160490  3160691820\n",
      "  3219223150  3277754480  3336285810  3394817140  3453348470  3511879800\n",
      "  3570411130  3628942460  3687473790  3746005120  3804536450  3863067780\n",
      "  3921599110  3980130440  4038661770  4097193100  4155724430  4214255760\n",
      "  4272787090  4331318420  4389849750  4448381080  4506912410  4565443740\n",
      "  4623975070  4682506400  4741037730  4799569060  4858100390  4916631720\n",
      "  4975163050  5033694380  5092225710  5150757040  5209288370  5267819700\n",
      "  5326351030  5384882360  5443413690  5501945020  5560476350  5619007680\n",
      "  5677539010  5736070340  5794601670  5853133000  5911664330  5970195660\n",
      "  6028726990  6087258320  6145789650  6204320980  6262852310  6321383640\n",
      "  6379914970  6438446300  6496977630  6555508960  6614040290  6672571620\n",
      "  6731102950  6789634280  6848165610  6906696940  6965228270  7023759600\n",
      "  7082290930  7140822260  7199353590  7257884920  7316416250  7374947580\n",
      "  7433478910  7492010240  7550541570  7609072900  7667604230  7726135560\n",
      "  7784666890  7843198220  7901729550  7960260880  8018792210  8077323540\n",
      "  8135854870  8194386200  8252917530  8311448860  8369980190  8428511520\n",
      "  8487042850  8545574180  8604105510  8662636840  8721168170  8779699500\n",
      "  8838230830  8896762160  8955293490  9013824820  9072356150  9130887480\n",
      "  9189418810  9247950140  9306481470  9365012800  9423544130  9482075460\n",
      "  9540606790  9599138120  9657669450  9716200780  9774732110  9833263440\n",
      "  9891794770  9950326100 10008857430 10067388760 10125920090 10184451420\n",
      " 10242982750 10301514080 10360045410 10418576740 10477108070 10535639400\n",
      " 10594170730 10652702060 10711233390 10769764720 10828296050 10886827380\n",
      " 10945358710 11003890040 11062421370 11120952700 11179484030 11238015360\n",
      " 11296546690 11355078020 11413609350 11472140680 11530672010 11589203340\n",
      " 11647734670 11706266000]\n",
      "train time:  [   5.6030729   12.6646809   19.7800884   25.7235658   31.5494387\n",
      "   37.2801664   44.1007713   51.3996715   59.3305106   67.1220806\n",
      "   74.0250544   81.148638    88.7001547   95.9150302  103.0321695\n",
      "  110.5972658  118.2949661  125.5981688  132.9003041  140.2865393\n",
      "  147.5061226  154.7267852  162.0902962  169.6197758  177.0293945\n",
      "  184.3064095  191.4965995  198.6167769  206.0767413  213.9136225\n",
      "  221.6285797  229.0665498  236.5056319  244.0329091  251.3104286\n",
      "  258.7148696  266.3353675  274.1481321  282.4951459  290.5339709\n",
      "  298.0246439  305.3978752  312.4804611  319.5934881  327.011847\n",
      "  334.2367631  341.5066166  348.7446226  356.0264982  363.3991944\n",
      "  370.8148825  378.5361027  386.3868263  393.7447786  401.2031344\n",
      "  408.8821437  416.2886078  424.0154872  431.9310875  439.6234393\n",
      "  447.3245892  454.8848171  462.5813373  470.389371   477.4177784\n",
      "  484.4882924  491.6098292  498.0758214  505.0926816  512.0621661\n",
      "  519.2827567  525.8868447  532.5806911  539.7742799  546.7412343\n",
      "  553.6959454  560.5427179  567.1785585  573.8248498  580.609629\n",
      "  587.1862521  595.3522183  603.1683391  609.819823   616.8868988\n",
      "  624.1740391  631.696156   639.2893782  646.6437501  653.7886594\n",
      "  661.1066902  668.381805   675.2343045  681.8060775  688.7172881\n",
      "  695.580848   702.9106703  710.1909896  717.1510075  723.9479833\n",
      "  730.5632419  737.1322248  743.5136047  749.9537807  756.2969348\n",
      "  762.8552917  769.2057617  775.7876674  782.1167578  788.5876583\n",
      "  795.0235772  801.6989638  808.2365068  814.8637676  821.7127129\n",
      "  828.9697393  836.2217341  843.45742    850.832914   858.0340616\n",
      "  865.3109042  872.2445482  879.2516202  886.3591762  894.1624486\n",
      "  902.3096482  910.8182119  917.735883   924.4860067  931.4075934\n",
      "  938.3808412  945.2218852  952.3363564  959.6880649  967.0918474\n",
      "  974.3100807  981.6805714  989.0741482  996.2466758 1003.775555\n",
      " 1011.0949407 1018.5530463 1025.3896066 1032.4710561 1039.6760779\n",
      " 1046.8791595 1054.8264833 1062.4532837 1069.7740484 1077.4977904\n",
      " 1085.0313853 1092.7320204 1100.5835259 1108.2924662 1115.7913975\n",
      " 1123.2413637 1130.3604782 1137.9986575 1145.0408629 1152.1694775\n",
      " 1160.1899629 1167.9867442 1175.6030357 1183.245827  1190.682582\n",
      " 1198.4950345 1206.258361  1214.535881  1223.3844539 1231.25303\n",
      " 1239.4043325 1245.8063719 1252.2562834 1258.9529603 1265.7698473\n",
      " 1272.5410516 1279.936295  1289.0383347 1296.0918228 1302.5007052\n",
      " 1308.7148879 1315.331262  1322.0468356 1329.6000974 1337.9277009\n",
      " 1344.6593803 1351.554345  1358.596451  1365.5441639 1372.4340987\n",
      " 1379.6105973 1386.7326738 1393.1789221 1399.7488307 1406.0151181\n",
      " 1412.4821227 1418.671448  1424.927079  1431.2021964 1437.508194 ]\n",
      "=======TEST RESULT=======\n",
      "test loss:  [0.00062612 0.0006213  0.00061654 0.00061185 0.00060722 0.00060267\n",
      " 0.00059817 0.00059374 0.00058937 0.00058506 0.00058081 0.00057661\n",
      " 0.00057247 0.00056839 0.00056436 0.00056039 0.00055647 0.0005526\n",
      " 0.00054877 0.00054501 0.00054128 0.0005376  0.00053398 0.0005304\n",
      " 0.00052686 0.00052337 0.00051992 0.00051651 0.00051315 0.00050982\n",
      " 0.00050654 0.00050329 0.0005001  0.00049693 0.0004938  0.00049071\n",
      " 0.00048765 0.00048463 0.00048165 0.00047869 0.00047578 0.00047289\n",
      " 0.00047004 0.00046722 0.00046443 0.00046168 0.00045896 0.00045626\n",
      " 0.0004536  0.00045096 0.00044835 0.00044577 0.00044322 0.00044069\n",
      " 0.00043819 0.00043573 0.00043328 0.00043086 0.00042847 0.00042609\n",
      " 0.00042375 0.00042143 0.00041913 0.00041686 0.00041461 0.00041238\n",
      " 0.00041017 0.000408   0.00040583 0.00040369 0.00040157 0.00039948\n",
      " 0.0003974  0.00039534 0.00039331 0.00039129 0.00038929 0.00038731\n",
      " 0.00038535 0.00038341 0.00038149 0.00037959 0.0003777  0.00037583\n",
      " 0.00037398 0.00037215 0.00037033 0.00036853 0.00036674 0.00036497\n",
      " 0.00036322 0.00036149 0.00035976 0.00035806 0.00035637 0.0003547\n",
      " 0.00035304 0.00035139 0.00034976 0.00034815 0.00034654 0.00034495\n",
      " 0.00034337 0.00034181 0.00034026 0.00033873 0.0003372  0.0003357\n",
      " 0.0003342  0.00033271 0.00033124 0.00032978 0.00032834 0.0003269\n",
      " 0.00032547 0.00032406 0.00032266 0.00032127 0.0003199  0.00031852\n",
      " 0.00031717 0.00031583 0.00031449 0.00031317 0.00031185 0.00031055\n",
      " 0.00030926 0.00030797 0.0003067  0.00030544 0.00030418 0.00030294\n",
      " 0.00030171 0.00030049 0.00029927 0.00029807 0.00029687 0.00029568\n",
      " 0.0002945  0.00029334 0.00029217 0.00029102 0.00028988 0.00028874\n",
      " 0.00028761 0.0002865  0.00028538 0.00028428 0.00028318 0.0002821\n",
      " 0.00028102 0.00027995 0.00027889 0.00027782 0.00027678 0.00027574\n",
      " 0.0002747  0.00027368 0.00027265 0.00027164 0.00027064 0.00026964\n",
      " 0.00026865 0.00026767 0.00026669 0.00026571 0.00026475 0.00026379\n",
      " 0.00026285 0.0002619  0.00026097 0.00026004 0.00025911 0.00025819\n",
      " 0.00025728 0.00025637 0.00025546 0.00025457 0.00025367 0.0002528\n",
      " 0.00025192 0.00025105 0.00025018 0.00024931 0.00024846 0.00024761\n",
      " 0.00024677 0.00024593 0.00024509 0.00024427 0.00024344 0.00024262\n",
      " 0.00024181 0.000241   0.0002402  0.00023941 0.00023861 0.00023783\n",
      " 0.00023704 0.00023627]\n",
      "test error:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test send cost:  [   58531330   117062660   175593990   234125320   292656650   351187980\n",
      "   409719310   468250640   526781970   585313300   643844630   702375960\n",
      "   760907290   819438620   877969950   936501280   995032610  1053563940\n",
      "  1112095270  1170626600  1229157930  1287689260  1346220590  1404751920\n",
      "  1463283250  1521814580  1580345910  1638877240  1697408570  1755939900\n",
      "  1814471230  1873002560  1931533890  1990065220  2048596550  2107127880\n",
      "  2165659210  2224190540  2282721870  2341253200  2399784530  2458315860\n",
      "  2516847190  2575378520  2633909850  2692441180  2750972510  2809503840\n",
      "  2868035170  2926566500  2985097830  3043629160  3102160490  3160691820\n",
      "  3219223150  3277754480  3336285810  3394817140  3453348470  3511879800\n",
      "  3570411130  3628942460  3687473790  3746005120  3804536450  3863067780\n",
      "  3921599110  3980130440  4038661770  4097193100  4155724430  4214255760\n",
      "  4272787090  4331318420  4389849750  4448381080  4506912410  4565443740\n",
      "  4623975070  4682506400  4741037730  4799569060  4858100390  4916631720\n",
      "  4975163050  5033694380  5092225710  5150757040  5209288370  5267819700\n",
      "  5326351030  5384882360  5443413690  5501945020  5560476350  5619007680\n",
      "  5677539010  5736070340  5794601670  5853133000  5911664330  5970195660\n",
      "  6028726990  6087258320  6145789650  6204320980  6262852310  6321383640\n",
      "  6379914970  6438446300  6496977630  6555508960  6614040290  6672571620\n",
      "  6731102950  6789634280  6848165610  6906696940  6965228270  7023759600\n",
      "  7082290930  7140822260  7199353590  7257884920  7316416250  7374947580\n",
      "  7433478910  7492010240  7550541570  7609072900  7667604230  7726135560\n",
      "  7784666890  7843198220  7901729550  7960260880  8018792210  8077323540\n",
      "  8135854870  8194386200  8252917530  8311448860  8369980190  8428511520\n",
      "  8487042850  8545574180  8604105510  8662636840  8721168170  8779699500\n",
      "  8838230830  8896762160  8955293490  9013824820  9072356150  9130887480\n",
      "  9189418810  9247950140  9306481470  9365012800  9423544130  9482075460\n",
      "  9540606790  9599138120  9657669450  9716200780  9774732110  9833263440\n",
      "  9891794770  9950326100 10008857430 10067388760 10125920090 10184451420\n",
      " 10242982750 10301514080 10360045410 10418576740 10477108070 10535639400\n",
      " 10594170730 10652702060 10711233390 10769764720 10828296050 10886827380\n",
      " 10945358710 11003890040 11062421370 11120952700 11179484030 11238015360\n",
      " 11296546690 11355078020 11413609350 11472140680 11530672010 11589203340\n",
      " 11647734670 11706266000]\n",
      "test time:  [   6.3432107   12.7859634   19.4112856   26.5201185   34.3080472\n",
      "   42.8601581   50.7950803   57.1912271   63.7597455   70.0694182\n",
      "   76.660291    83.3044341   91.1966346   98.2101406  105.7676523\n",
      "  112.770946   119.4747882  125.9928277  132.6102518  139.5580756\n",
      "  146.2706219  152.9515603  160.049273   167.0424753  173.486066\n",
      "  180.7000052  187.1433621  194.4396722  201.5450401  208.4092848\n",
      "  215.4752143  222.1599117  229.0623061  236.4263339  244.5522315\n",
      "  252.0148695  259.2748467  265.8280388  272.4272999  279.0760669\n",
      "  285.9825423  293.0974257  300.835129   308.0560344  315.3233959\n",
      "  321.9507505  328.9509993  335.617975   342.2333673  348.8040274\n",
      "  355.2604045  361.8053486  368.5178056  375.1378562  382.5282713\n",
      "  389.7301851  397.7407481  407.0067038  414.9251018  421.805898\n",
      "  428.8447537  436.07315    444.2164627  452.7543368  460.9999022\n",
      "  469.2080984  477.3688665  485.4355526  493.4934635  501.5168303\n",
      "  509.6019683  518.4436876  526.9916029  534.7940311  542.8286762\n",
      "  550.8378243  559.0945926  566.9569724  575.2008396  583.1551975\n",
      "  591.2936288  599.4163256  607.3852916  615.139443   623.5200056\n",
      "  632.3392403  640.6285401  648.4649046  656.3153619  664.1680107\n",
      "  672.2400012  680.234739   687.858412   696.4042371  704.792371\n",
      "  713.045471   721.1312153  728.8283391  736.6487419  744.4827765\n",
      "  752.4178804  760.0502232  768.0174476  775.8274326  783.526356\n",
      "  791.0390417  798.7900088  806.8765012  815.1332568  823.2612161\n",
      "  831.540333   839.4565056  847.1120832  854.5488498  862.0116062\n",
      "  869.579134   877.622931   885.8094868  893.8130161  902.0947425\n",
      "  910.8273464  919.4198828  927.6882905  935.8892902  944.5418263\n",
      "  952.6045485  960.4451547  968.3771552  976.0404357  983.9502512\n",
      "  991.9294132  999.8961033 1007.8740545 1015.5492451 1023.7359331\n",
      " 1031.6376656 1039.2767908 1046.9487139 1055.9772835 1064.0027891\n",
      " 1072.3062977 1079.5435598 1086.419786  1093.690846  1101.0950966\n",
      " 1108.4328163 1115.5600662 1122.7925469 1130.186099  1137.2260105\n",
      " 1144.9784052 1152.3323178 1159.2516165 1166.442157  1173.9294668\n",
      " 1181.3995259 1189.376985  1196.9812333 1204.2352075 1211.8267841\n",
      " 1219.2417912 1226.6650132 1234.2205847 1241.6923206 1249.0950191\n",
      " 1256.4652266 1263.5367192 1270.3533689 1276.9190649 1283.9085312\n",
      " 1291.2394365 1298.5259859 1305.7941767 1313.1575958 1321.0476577\n",
      " 1329.3068323 1336.9717334 1343.9287873 1350.6699235 1357.2884179\n",
      " 1363.8319712 1370.2446036 1376.4185964 1382.8533255 1389.2901877\n",
      " 1395.5408176 1402.1854175 1408.5803496 1415.1912287 1421.9642717\n",
      " 1428.601458  1434.8719368 1441.6788715 1447.7975542 1454.2788213\n",
      " 1461.0929464 1467.9063453 1474.8461297 1481.6707749 1489.2162002]\n",
      "filename:  homogeneous_CIFAR-10 Datset10local_update_epochs40epoch_result\n",
      "['train_loss', 'train_error', 'train_send_cost', 'train_time', 'test_loss', 'test_error', 'test_send_cost', 'test_time']\n",
      "=======TRAIN RESULT=======\n",
      "train loss:  [1.95174193e+00 1.70167189e+00 1.11625063e+00 4.63036511e-01\n",
      " 3.57587787e-01 1.05892487e-01 5.17183588e-02 1.87644526e-02\n",
      " 8.42088786e-03 5.60566255e-03 4.33247796e-03 3.53786191e-03\n",
      " 2.97861655e-03 2.56027608e-03 2.23512145e-03 1.97404202e-03\n",
      " 1.76111318e-03 1.58394901e-03 1.43440564e-03 1.30703145e-03\n",
      " 1.19723808e-03 1.10206696e-03 1.01867051e-03 9.45276287e-04\n",
      " 8.80203911e-04 8.22174273e-04 7.70241846e-04 7.23541171e-04\n",
      " 6.81388389e-04 6.43130423e-04 6.08333147e-04 5.76563278e-04\n",
      " 5.47469527e-04 5.20761012e-04 4.96156411e-04 4.73472499e-04\n",
      " 4.52463686e-04 4.32993512e-04 4.14933939e-04 3.98096235e-04]\n",
      "train error:  [6.1740005e-01 5.4100001e-01 3.4070006e-01 1.3329999e-01 9.6999988e-02\n",
      " 2.2499999e-02 9.8000001e-03 1.5999998e-03 9.9999990e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "train send cost:  [  58531330  117062660  175593990  234125320  292656650  351187980\n",
      "  409719310  468250640  526781970  585313300  643844630  702375960\n",
      "  760907290  819438620  877969950  936501280  995032610 1053563940\n",
      " 1112095270 1170626600 1229157930 1287689260 1346220590 1404751920\n",
      " 1463283250 1521814580 1580345910 1638877240 1697408570 1755939900\n",
      " 1814471230 1873002560 1931533890 1990065220 2048596550 2107127880\n",
      " 2165659210 2224190540 2282721870 2341253200]\n",
      "train time:  [  67.5152324  137.6233915  210.2782056  284.6200937  357.2536575\n",
      "  428.1262068  499.5194407  570.5356523  643.7998039  716.8538393\n",
      "  790.040309   865.7168599  943.3911319 1019.6949924 1099.3241767\n",
      " 1178.7043339 1256.8101247 1334.1990798 1415.1180451 1494.8494573\n",
      " 1573.2248025 1651.0256438 1730.1261544 1810.7125919 1888.5269811\n",
      " 1965.0321257 2042.6241431 2109.6387123 2178.6629503 2250.8321555\n",
      " 2326.3230804 2404.797577  2480.8279504 2552.0724389 2620.4423575\n",
      " 2695.1695429 2760.6329742 2823.5858999 2887.6134063 2951.0938386]\n",
      "=======TEST RESULT=======\n",
      "test loss:  [0.00038239 0.00036771 0.00035397 0.00034109 0.00032899 0.00031761\n",
      " 0.0003069  0.00029679 0.00028725 0.00027823 0.00026969 0.00026159\n",
      " 0.00025391 0.00024662 0.00023968 0.00023308 0.00022678 0.00022079\n",
      " 0.00021506 0.00020959 0.00020436 0.00019936 0.00019457 0.00018998\n",
      " 0.00018557 0.00018135 0.00017729 0.00017338 0.00016963 0.00016602\n",
      " 0.00016255 0.00015921 0.00015598 0.00015287 0.00014987 0.00014697\n",
      " 0.00014418 0.00014147 0.00013886 0.00013633]\n",
      "test error:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test send cost:  [  58531330  117062660  175593990  234125320  292656650  351187980\n",
      "  409719310  468250640  526781970  585313300  643844630  702375960\n",
      "  760907290  819438620  877969950  936501280  995032610 1053563940\n",
      " 1112095270 1170626600 1229157930 1287689260 1346220590 1404751920\n",
      " 1463283250 1521814580 1580345910 1638877240 1697408570 1755939900\n",
      " 1814471230 1873002560 1931533890 1990065220 2048596550 2107127880\n",
      " 2165659210 2224190540 2282721870 2341253200]\n",
      "test time:  [  63.2507921  125.3527145  186.8330805  249.4306678  558.4021274\n",
      "  811.7099674 1064.201226  1352.6029719 1707.2500227 1783.604386\n",
      " 1863.5326165 1944.5182872 2025.3096033 2108.1402425 2176.399212\n",
      " 2237.6593332 2299.863637  2362.2798447 2426.1781745 2488.1323764\n",
      " 2551.8303353 2616.1388762 2687.1371549 2753.2083663 2818.7832783\n",
      " 2885.1188481 2949.3728496 3016.1307014 3077.0327542 3150.1872859\n",
      " 3227.1463912 3292.4851017 3355.7958308 3417.7649334 3498.0290629\n",
      " 3588.4743668 3653.0520495 3713.647254  3774.7343846 3835.7274562]\n",
      "=======TRAIN RESULT=======\n",
      "train loss:  [1.95174193e+00 1.70167189e+00 1.11625063e+00 4.63036511e-01\n",
      " 3.57587787e-01 1.05892487e-01 5.17183588e-02 1.87644526e-02\n",
      " 8.42088786e-03 5.60566255e-03 4.33247796e-03 3.53786191e-03\n",
      " 2.97861655e-03 2.56027608e-03 2.23512145e-03 1.97404202e-03\n",
      " 1.76111318e-03 1.58394901e-03 1.43440564e-03 1.30703145e-03\n",
      " 1.19723808e-03 1.10206696e-03 1.01867051e-03 9.45276287e-04\n",
      " 8.80203911e-04 8.22174273e-04 7.70241846e-04 7.23541171e-04\n",
      " 6.81388389e-04 6.43130423e-04 6.08333147e-04 5.76563278e-04\n",
      " 5.47469527e-04 5.20761012e-04 4.96156411e-04 4.73472499e-04\n",
      " 4.52463686e-04 4.32993512e-04 4.14933939e-04 3.98096235e-04]\n",
      "train error:  [6.1740005e-01 5.4100001e-01 3.4070006e-01 1.3329999e-01 9.6999988e-02\n",
      " 2.2499999e-02 9.8000001e-03 1.5999998e-03 9.9999990e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "train send cost:  [  58531330  117062660  175593990  234125320  292656650  351187980\n",
      "  409719310  468250640  526781970  585313300  643844630  702375960\n",
      "  760907290  819438620  877969950  936501280  995032610 1053563940\n",
      " 1112095270 1170626600 1229157930 1287689260 1346220590 1404751920\n",
      " 1463283250 1521814580 1580345910 1638877240 1697408570 1755939900\n",
      " 1814471230 1873002560 1931533890 1990065220 2048596550 2107127880\n",
      " 2165659210 2224190540 2282721870 2341253200]\n",
      "train time:  [  67.5152324  137.6233915  210.2782056  284.6200937  357.2536575\n",
      "  428.1262068  499.5194407  570.5356523  643.7998039  716.8538393\n",
      "  790.040309   865.7168599  943.3911319 1019.6949924 1099.3241767\n",
      " 1178.7043339 1256.8101247 1334.1990798 1415.1180451 1494.8494573\n",
      " 1573.2248025 1651.0256438 1730.1261544 1810.7125919 1888.5269811\n",
      " 1965.0321257 2042.6241431 2109.6387123 2178.6629503 2250.8321555\n",
      " 2326.3230804 2404.797577  2480.8279504 2552.0724389 2620.4423575\n",
      " 2695.1695429 2760.6329742 2823.5858999 2887.6134063 2951.0938386]\n",
      "=======TEST RESULT=======\n",
      "test loss:  [0.00038239 0.00036771 0.00035397 0.00034109 0.00032899 0.00031761\n",
      " 0.0003069  0.00029679 0.00028725 0.00027823 0.00026969 0.00026159\n",
      " 0.00025391 0.00024662 0.00023968 0.00023308 0.00022678 0.00022079\n",
      " 0.00021506 0.00020959 0.00020436 0.00019936 0.00019457 0.00018998\n",
      " 0.00018557 0.00018135 0.00017729 0.00017338 0.00016963 0.00016602\n",
      " 0.00016255 0.00015921 0.00015598 0.00015287 0.00014987 0.00014697\n",
      " 0.00014418 0.00014147 0.00013886 0.00013633]\n",
      "test error:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test send cost:  [  58531330  117062660  175593990  234125320  292656650  351187980\n",
      "  409719310  468250640  526781970  585313300  643844630  702375960\n",
      "  760907290  819438620  877969950  936501280  995032610 1053563940\n",
      " 1112095270 1170626600 1229157930 1287689260 1346220590 1404751920\n",
      " 1463283250 1521814580 1580345910 1638877240 1697408570 1755939900\n",
      " 1814471230 1873002560 1931533890 1990065220 2048596550 2107127880\n",
      " 2165659210 2224190540 2282721870 2341253200]\n",
      "test time:  [  63.2507921  125.3527145  186.8330805  249.4306678  558.4021274\n",
      "  811.7099674 1064.201226  1352.6029719 1707.2500227 1783.604386\n",
      " 1863.5326165 1944.5182872 2025.3096033 2108.1402425 2176.399212\n",
      " 2237.6593332 2299.863637  2362.2798447 2426.1781745 2488.1323764\n",
      " 2551.8303353 2616.1388762 2687.1371549 2753.2083663 2818.7832783\n",
      " 2885.1188481 2949.3728496 3016.1307014 3077.0327542 3150.1872859\n",
      " 3227.1463912 3292.4851017 3355.7958308 3417.7649334 3498.0290629\n",
      " 3588.4743668 3653.0520495 3713.647254  3774.7343846 3835.7274562]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!-- x-axis as global epochs --!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs_list = [200, 40]\n",
    "num_clients_list = [10]\n",
    "local_update_epochs_list = [1, 10]\n",
    "num_epochs = num_epochs_list[0]\n",
    "\n",
    "num_clients_list_size = len(num_clients_list)\n",
    "local_update_epochs_list_size = len(local_update_epochs_list)\n",
    "data_train_loss_history_total = []\n",
    "data_train_error_history_total = []\n",
    "data_train_send_cost_history_total = []\n",
    "data_train_time_history_total = []\n",
    "data_test_loss_history_total = []\n",
    "data_test_error_history_total = []\n",
    "data_test_send_cost_history_total = []\n",
    "data_test_time_history_total = []\n",
    "experiment_type = \"test\"\n",
    "\n",
    "num_epochs_list = [200, 40]\n",
    "open_list = [1, 10]\n",
    "experiment_type = 'local_update_epochs'\n",
    "\n",
    "for n in range(len(open_list)):\n",
    "    num_epochs = num_epochs_list[n]\n",
    "    total_filename = \"homogeneous_{}{}{}{}epoch_result\".format(dataset_name, open_list[n], experiment_type, num_epochs) #update name of result .npz file\n",
    "    result = np.load(total_filename) #load data into 'result'\n",
    "    print('filename: ', total_filename)\n",
    "    print(result.files) #show attributes inside 'result'\n",
    "    data_train_loss = result['train_loss']    #np.load(total_filename['train_loss'])\n",
    "    data_train_error = result['train_error']    #np.load(total_filename['train_error'])\n",
    "    data_train_send_cost = result['train_send_cost']    #np.load(total_filename['train_send_cost'])\n",
    "    data_train_time = result['train_time']    #np.load(total_filename['train_time'])\n",
    "    data_test_loss = result['test_loss']    #np.load(total_filename['test_loss'])\n",
    "    data_test_error = result['test_error']    #np.load(total_filename['test_error'])\n",
    "    data_test_send_cost = result['test_send_cost']    #np.load(total_filename['test_send_cost'])\n",
    "    data_test_time = result['test_time']    #np.load(total_filename['test_time'])\n",
    "\n",
    "    print(\"=======TRAIN RESULT=======\")\n",
    "    print(\"train loss: \", data_train_loss)\n",
    "    print(\"train error: \", data_train_error)\n",
    "    print(\"train send cost: \", data_train_send_cost)\n",
    "    print(\"train time: \", data_train_time)\n",
    "    print(\"=======TEST RESULT=======\")\n",
    "    print(\"test loss: \", data_test_loss)\n",
    "    print(\"test error: \", data_test_error)\n",
    "    print(\"test send cost: \", data_test_send_cost)\n",
    "    print(\"test time: \", data_test_time)\n",
    "\n",
    "    print(\"=======TRAIN RESULT=======\")\n",
    "    print(\"train loss: \", data_train_loss)\n",
    "    print(\"train error: \", data_train_error)\n",
    "    print(\"train send cost: \", data_train_send_cost)\n",
    "    print(\"train time: \", data_train_time)\n",
    "    print(\"=======TEST RESULT=======\")\n",
    "    print(\"test loss: \", data_test_loss)\n",
    "    print(\"test error: \", data_test_error)\n",
    "    print(\"test send cost: \", data_test_send_cost)\n",
    "    print(\"test time: \", data_test_time)\n",
    "\n",
    "    compareClients = False\n",
    "    if compareClients is True:\n",
    "        iteration_list = num_clients_list\n",
    "        experiment_type = \"num_clients\"\n",
    "    else:\n",
    "        iteration_list = local_update_epochs_list\n",
    "        experiment_type = \"local_update_epochs\"\n",
    "\n",
    "        data_train_loss_history_total.append(data_train_loss)\n",
    "        data_train_error_history_total.append(data_train_error)\n",
    "        data_train_send_cost_history_total.append(data_train_send_cost)\n",
    "        data_train_time_history_total.append(data_train_time)\n",
    "        data_test_loss_history_total.append(data_test_loss)\n",
    "        data_test_error_history_total.append(data_test_error)\n",
    "        data_test_send_cost_history_total.append(data_test_send_cost)\n",
    "        data_test_time_history_total.append(data_test_time)\n",
    "\n",
    "print(f'=== The Experiment Result ===')\n",
    "# Show Dataset Name\n",
    "print(f'Current Dataset: {dataset_name}')\n",
    "\n",
    "# Training Result\n",
    "print(f'!-- Training Result --!')\n",
    "if compareClients is True:\n",
    "    # Plot the training loss rate between cost history with num_clients\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_train_send_cost_history_total[i], data_train_loss_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss Rate vs Send Cost (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_train_send_cost_history_total[i], data_train_error_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate vs Send Cost (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the training loss rate between cost history with num_clients per clients\n",
    "    min_cost_list = data_train_send_cost_history_total[0]\n",
    "    for sublist in data_train_send_cost_history_total:\n",
    "        if len(sublist) < len(min_cost_list):\n",
    "            min_cost_list = sublist\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(min_cost_list, data_train_loss_history_total[i])\n",
    "    plt.xlabel(\"Send Cost per clients\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss Rate vs Send Cost per clients (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_per_clients_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the training loss rate between cost history with num_clients per clients\n",
    "    min_cost_list = data_train_send_cost_history_total[0]\n",
    "    for sublist in data_train_send_cost_history_total:\n",
    "        if len(sublist) < len(min_cost_list):\n",
    "            min_cost_list = sublist\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(min_cost_list, data_train_error_history_total[i])\n",
    "    plt.xlabel(\"Send Cost per clients\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate vs Send Cost per clients (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_per_clients_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'!-- x-axis as global epochs --!')\n",
    "    # Plot the training loss rate between cost history with num_clients\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_train_loss_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss Rate (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'Loss_{dataset_name}_num_clients_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_train_error_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'ErrorRate_{dataset_name}_num_clients_training.png')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # Plot the training loss rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_train_send_cost_history_total[i], data_train_loss_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss Rate vs Send Cost (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_local_update_epochs_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_train_send_cost_history_total[i], data_train_error_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate vs Send Cost (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_local_update_epochs_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'!-- x-axis as global epochs --!')\n",
    "    # Plot the training loss rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_train_loss_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss Rate (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'Loss_epochs_{dataset_name}_local_update_epochs_training.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_train_error_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'ErrorRate_epochs_{dataset_name}_local_update_epochs_training.png')\n",
    "    plt.show()\n",
    "\n",
    "# Testing Result\n",
    "print(f'!-- Testing Result --!')\n",
    "if compareClients is True:\n",
    "    # Plot the training loss rate between cost history with num_clients\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_test_send_cost_history_total[i], data_test_loss_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Testing Loss Rate\")\n",
    "    plt.title(\"Testing Loss Rate vs Send Cost (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_test_send_cost_history_total[i], data_test_error_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate vs Send Cost (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the training loss rate between cost history with num_clients per clients\n",
    "    min_cost_list = data_test_send_cost_history_total[0]\n",
    "    for sublist in data_test_send_cost_history_total:\n",
    "        if len(sublist) < len(min_cost_list):\n",
    "            min_cost_list = sublist\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(min_cost_list, data_test_loss_history_total[i])\n",
    "    plt.xlabel(\"Send Cost per clients\")\n",
    "    plt.ylabel(\"Testing Loss Rate\")\n",
    "    plt.title(\"Testing Loss Rate vs Send Cost per clients (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_num_clients_per_clients_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the training loss rate between cost history with num_clients per clients\n",
    "    min_cost_list = data_test_send_cost_history_total[0]\n",
    "    for sublist in data_test_send_cost_history_total:\n",
    "        if len(sublist) < len(min_cost_list):\n",
    "            min_cost_list = sublist\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(min_cost_list, data_test_error_history_total[i])\n",
    "    plt.xlabel(\"Send Cost per clients\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate vs Send Cost per clients (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_num_clients_per_clients_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'!-- x-axis as global epochs --!')\n",
    "    # Plot the training loss rate between cost history with num_clients\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_test_loss_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Testing Loss Rate\")\n",
    "    plt.title(\"Testing Loss Rate (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'Loss_{dataset_name}_num_clients_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(num_clients_list_size):\n",
    "        plt.plot(data_test_error_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate (with different number of clients)\")\n",
    "    plt.legend(num_clients_list)\n",
    "    plt.savefig(f'ErrorRate_{dataset_name}_num_clients_testing.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    # Plot the training loss rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_test_send_cost_history_total[i], data_test_loss_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Testing Loss Rate\")\n",
    "    plt.title(\"Testing Loss Rate vs Send Cost (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'Loss_vs_Send_Cost_{dataset_name}_local_update_epochs_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_test_send_cost_history_total[i], data_test_error_history_total[i])\n",
    "    plt.xlabel(\"Send Cost\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate vs Send Cost (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'ErrorRate_vs_Send_Cost_{dataset_name}_local_update_epochs_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'!-- x-axis as global epochs --!')\n",
    "    # Plot the training loss rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_test_loss_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Training Loss Rate\")\n",
    "    plt.title(\"Training Loss Rate (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'Loss_epochs_{dataset_name}_local_update_epochs_testing.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the error rate between cost history with local_update_epochs\n",
    "    for i in range(local_update_epochs_list_size):\n",
    "        plt.plot(data_test_error_history_total[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(\"Error Rate (with different local update epochs)\")\n",
    "    plt.legend(local_update_epochs_list)\n",
    "    plt.savefig(f'ErrorRate_epochs_{dataset_name}_local_update_epochs_testing.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
