{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a8e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages #\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install torch\n",
    "# !pip install xlrd\n",
    "# !pip install pandas\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b59c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eb81ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading training data\n",
    "dataset = pd.read_csv(\"bmi_train.csv\")\n",
    "dataset.replace({'Gender': {'Female': 0, 'Male': 1}}, inplace=True) #Gender -> boolean\n",
    "dataset = dataset.to_numpy()\n",
    "\n",
    "# Splitting off 80% of data for training, 20% for validation\n",
    "train_split = int(0.8 * len(dataset))\n",
    "X_train = dataset[:train_split, [0,1,2]]\n",
    "y_train = dataset[:train_split, 3]\n",
    "X_test = dataset[train_split:, [0,1,2]]\n",
    "y_test = dataset[train_split:, 3]\n",
    "\n",
    "# Loading prediction data\n",
    "prediction_dataset = pd.read_csv(\"bmi_validation.csv\")\n",
    "prediction_dataset.replace({'Gender': {'Female': 0, 'Male': 1}}, inplace=True) #Gender -> boolean\n",
    "X_prediction = prediction_dataset.to_numpy()\n",
    "\n",
    "# Normalize data set\n",
    "X_train_normalized = (X_train - X_train.min(0)) / (X_train.max(0) - X_train.min(0))\n",
    "X_test_normalized = (X_test - X_test.min(0)) / (X_test.max(0) - X_test.min(0))\n",
    "X_prediction_normalized = (X_prediction - X_prediction.min(0)) / (X_prediction.max(0) - X_prediction.min(0))\n",
    "\n",
    "# Turn data to tensor\n",
    "X_train_tensor = torch.from_numpy(X_train_normalized)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test_normalized)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "X_prediction_tensor = torch.from_numpy(X_prediction_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd85410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test error rate analysis function\n",
    "def calculate_error_rate(X, y, w, b):\n",
    "    num_samples = X.shape[0]\n",
    "    y_pred = np.dot(X, w) + b\n",
    "    y_pred = torch.round(torch.from_numpy(y_pred))\n",
    "    error_count = torch.count_nonzero(y_pred - y)\n",
    "    error_rate = error_count / num_samples\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9bae8",
   "metadata": {},
   "source": [
    "Custom SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1017f7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned parameters:\n",
      "w0 = 0.060808857709234714\n",
      "w1 = -2.1334616790571426\n",
      "w2 = 3.847422443386162\n",
      "b = 2.8643211189596514\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error rate: tensor(0.3812)\n",
      "Test error rate: tensor(0.3625)\n"
     ]
    }
   ],
   "source": [
    "# Vanilia Gradient Descent Algorithms\n",
    "def gradient_descent(X, y, learning_rate, num_iterations):\n",
    "    num_samples, num_features = X.shape\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = np.zeros(num_features)\n",
    "    b = 0\n",
    "    cost_history = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Calculate predictions\n",
    "        y_pred = np.dot(X, w) + b\n",
    "        \n",
    "        # Calculate the difference between predictions and actual values\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # Calculate the gradient\n",
    "        w_gradient = (1/num_samples) * np.dot(X.T, error)\n",
    "        b_gradient = (1/num_samples) * np.sum(error)\n",
    "        \n",
    "        # Update theta using the learning rate and gradient\n",
    "        w -= learning_rate * w_gradient\n",
    "        b -= learning_rate * b_gradient\n",
    "        \n",
    "        # Calculate the cost (mean squared error)\n",
    "        cost = np.mean(np.square(error))\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return w, b, cost_history\n",
    "\n",
    "# Train the model using gradient descent\n",
    "learning_rate = 0.01\n",
    "num_iterations = 10000\n",
    "w, b, cost_history = gradient_descent(X_train_normalized, y_train, learning_rate, num_iterations)\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "\n",
    "for i, w_i in enumerate(w):\n",
    "    print(f\"w{i} =\", w_i)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w, b)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w, b)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf7d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned parameters:\n",
      "w0 = 0.059983496550581133\n",
      "w1 = -2.1378298844535375\n",
      "w2 = 3.8459536565170858\n",
      "b = 2.8665206461276247\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error rate: tensor(0.3781)\n",
      "Test error rate: tensor(0.3625)\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradien Descent Algorithms\n",
    "def stochastic_gradient_descent(X, y, learning_rate, num_epochs, batch_size):\n",
    "    num_samples, num_features = X.shape\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    # Initialize weights and bias\n",
    "    w = np.zeros(num_features)\n",
    "    b = 0\n",
    "    cost_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data for each epoch\n",
    "        permutation = np.random.permutation(num_samples)\n",
    "        X_shuffled = X[permutation]\n",
    "        y_shuffled = y[permutation]\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            # Select the current batch\n",
    "            start = batch * batch_size\n",
    "            end = (batch + 1) * batch_size\n",
    "            X_batch = X_shuffled[start:end]\n",
    "            y_batch = y_shuffled[start:end]\n",
    "\n",
    "            # Calculate predictions\n",
    "            y_pred = np.dot(X_batch, w) + b\n",
    "\n",
    "            # Calculate the difference between predictions and actual values\n",
    "            error = y_pred - y_batch\n",
    "\n",
    "            # Calculate the gradients\n",
    "            w_gradient = (1 / batch_size) * np.dot(X_batch.T, error)\n",
    "            b_gradient = (1 / batch_size) * np.sum(error)\n",
    "\n",
    "            # Update weights and bias\n",
    "            w -= learning_rate * w_gradient\n",
    "            b -= learning_rate * b_gradient\n",
    "\n",
    "            # Calculate the cost (mean squared error)\n",
    "            cost = np.mean(np.square(error))\n",
    "            cost_history.append(cost)\n",
    "            \n",
    "    return w, b, cost_history\n",
    "\n",
    "# Train the model using stochastic gradient descent\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10000\n",
    "batch_size = 10\n",
    "w, b, cost_history = stochastic_gradient_descent(X_train_normalized, y_train, learning_rate, num_epochs, batch_size)\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for i, w_i in enumerate(w):\n",
    "    print(f\"w{i} =\", w_i)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w, b)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w, b)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38cfbbe",
   "metadata": {},
   "source": [
    "Pytorch SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707afbc",
   "metadata": {},
   "source": [
    "Pytorch SGD Test (This is done by Chris for testing purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc595f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000], Loss: 15.80624962\n",
      "Epoch [10/5000], Loss: 8.95719337\n",
      "Epoch [20/5000], Loss: 5.18171310\n",
      "Epoch [30/5000], Loss: 3.37053919\n",
      "Epoch [40/5000], Loss: 2.48795056\n",
      "Epoch [50/5000], Loss: 2.04493523\n",
      "Epoch [60/5000], Loss: 1.81057477\n",
      "Epoch [70/5000], Loss: 1.67579579\n",
      "Epoch [80/5000], Loss: 1.58904791\n",
      "Epoch [90/5000], Loss: 1.52594018\n",
      "Epoch [100/5000], Loss: 1.47490764\n",
      "Epoch [110/5000], Loss: 1.43044233\n",
      "Epoch [120/5000], Loss: 1.38989937\n",
      "Epoch [130/5000], Loss: 1.35198796\n",
      "Epoch [140/5000], Loss: 1.31605935\n",
      "Epoch [150/5000], Loss: 1.28177118\n",
      "Epoch [160/5000], Loss: 1.24892676\n",
      "Epoch [170/5000], Loss: 1.21740115\n",
      "Epoch [180/5000], Loss: 1.18710470\n",
      "Epoch [190/5000], Loss: 1.15796685\n",
      "Epoch [200/5000], Loss: 1.12992716\n",
      "Epoch [210/5000], Loss: 1.10293210\n",
      "Epoch [220/5000], Loss: 1.07693267\n",
      "Epoch [230/5000], Loss: 1.05188298\n",
      "Epoch [240/5000], Loss: 1.02774048\n",
      "Epoch [250/5000], Loss: 1.00446510\n",
      "Epoch [260/5000], Loss: 0.98201925\n",
      "Epoch [270/5000], Loss: 0.96036673\n",
      "Epoch [280/5000], Loss: 0.93947446\n",
      "Epoch [290/5000], Loss: 0.91931021\n",
      "Epoch [300/5000], Loss: 0.89984387\n",
      "Epoch [310/5000], Loss: 0.88104689\n",
      "Epoch [320/5000], Loss: 0.86289203\n",
      "Epoch [330/5000], Loss: 0.84535408\n",
      "Epoch [340/5000], Loss: 0.82840812\n",
      "Epoch [350/5000], Loss: 0.81203139\n",
      "Epoch [360/5000], Loss: 0.79620153\n",
      "Epoch [370/5000], Loss: 0.78089750\n",
      "Epoch [380/5000], Loss: 0.76609957\n",
      "Epoch [390/5000], Loss: 0.75178838\n",
      "Epoch [400/5000], Loss: 0.73794621\n",
      "Epoch [410/5000], Loss: 0.72455537\n",
      "Epoch [420/5000], Loss: 0.71159959\n",
      "Epoch [430/5000], Loss: 0.69906294\n",
      "Epoch [440/5000], Loss: 0.68693036\n",
      "Epoch [450/5000], Loss: 0.67518729\n",
      "Epoch [460/5000], Loss: 0.66382009\n",
      "Epoch [470/5000], Loss: 0.65281516\n",
      "Epoch [480/5000], Loss: 0.64216036\n",
      "Epoch [490/5000], Loss: 0.63184321\n",
      "Epoch [500/5000], Loss: 0.62185228\n",
      "Epoch [510/5000], Loss: 0.61217618\n",
      "Epoch [520/5000], Loss: 0.60280424\n",
      "Epoch [530/5000], Loss: 0.59372616\n",
      "Epoch [540/5000], Loss: 0.58493221\n",
      "Epoch [550/5000], Loss: 0.57641256\n",
      "Epoch [560/5000], Loss: 0.56815821\n",
      "Epoch [570/5000], Loss: 0.56016034\n",
      "Epoch [580/5000], Loss: 0.55241072\n",
      "Epoch [590/5000], Loss: 0.54490095\n",
      "Epoch [600/5000], Loss: 0.53762317\n",
      "Epoch [610/5000], Loss: 0.53056991\n",
      "Epoch [620/5000], Loss: 0.52373397\n",
      "Epoch [630/5000], Loss: 0.51710808\n",
      "Epoch [640/5000], Loss: 0.51068562\n",
      "Epoch [650/5000], Loss: 0.50446016\n",
      "Epoch [660/5000], Loss: 0.49842516\n",
      "Epoch [670/5000], Loss: 0.49257460\n",
      "Epoch [680/5000], Loss: 0.48690286\n",
      "Epoch [690/5000], Loss: 0.48140401\n",
      "Epoch [700/5000], Loss: 0.47607270\n",
      "Epoch [710/5000], Loss: 0.47090358\n",
      "Epoch [720/5000], Loss: 0.46589169\n",
      "Epoch [730/5000], Loss: 0.46103191\n",
      "Epoch [740/5000], Loss: 0.45631957\n",
      "Epoch [750/5000], Loss: 0.45175010\n",
      "Epoch [760/5000], Loss: 0.44731897\n",
      "Epoch [770/5000], Loss: 0.44302186\n",
      "Epoch [780/5000], Loss: 0.43885475\n",
      "Epoch [790/5000], Loss: 0.43481344\n",
      "Epoch [800/5000], Loss: 0.43089414\n",
      "Epoch [810/5000], Loss: 0.42709309\n",
      "Epoch [820/5000], Loss: 0.42340651\n",
      "Epoch [830/5000], Loss: 0.41983098\n",
      "Epoch [840/5000], Loss: 0.41636318\n",
      "Epoch [850/5000], Loss: 0.41299963\n",
      "Epoch [860/5000], Loss: 0.40973711\n",
      "Epoch [870/5000], Loss: 0.40657273\n",
      "Epoch [880/5000], Loss: 0.40350333\n",
      "Epoch [890/5000], Loss: 0.40052599\n",
      "Epoch [900/5000], Loss: 0.39763802\n",
      "Epoch [910/5000], Loss: 0.39483657\n",
      "Epoch [920/5000], Loss: 0.39211911\n",
      "Epoch [930/5000], Loss: 0.38948306\n",
      "Epoch [940/5000], Loss: 0.38692588\n",
      "Epoch [950/5000], Loss: 0.38444519\n",
      "Epoch [960/5000], Loss: 0.38203877\n",
      "Epoch [970/5000], Loss: 0.37970418\n",
      "Epoch [980/5000], Loss: 0.37743941\n",
      "Epoch [990/5000], Loss: 0.37524226\n",
      "Epoch [1000/5000], Loss: 0.37311071\n",
      "Epoch [1010/5000], Loss: 0.37104276\n",
      "Epoch [1020/5000], Loss: 0.36903650\n",
      "Epoch [1030/5000], Loss: 0.36709011\n",
      "Epoch [1040/5000], Loss: 0.36520165\n",
      "Epoch [1050/5000], Loss: 0.36336952\n",
      "Epoch [1060/5000], Loss: 0.36159191\n",
      "Epoch [1070/5000], Loss: 0.35986724\n",
      "Epoch [1080/5000], Loss: 0.35819393\n",
      "Epoch [1090/5000], Loss: 0.35657042\n",
      "Epoch [1100/5000], Loss: 0.35499519\n",
      "Epoch [1110/5000], Loss: 0.35346684\n",
      "Epoch [1120/5000], Loss: 0.35198388\n",
      "Epoch [1130/5000], Loss: 0.35054496\n",
      "Epoch [1140/5000], Loss: 0.34914875\n",
      "Epoch [1150/5000], Loss: 0.34779400\n",
      "Epoch [1160/5000], Loss: 0.34647948\n",
      "Epoch [1170/5000], Loss: 0.34520397\n",
      "Epoch [1180/5000], Loss: 0.34396631\n",
      "Epoch [1190/5000], Loss: 0.34276533\n",
      "Epoch [1200/5000], Loss: 0.34159997\n",
      "Epoch [1210/5000], Loss: 0.34046912\n",
      "Epoch [1220/5000], Loss: 0.33937177\n",
      "Epoch [1230/5000], Loss: 0.33830693\n",
      "Epoch [1240/5000], Loss: 0.33727354\n",
      "Epoch [1250/5000], Loss: 0.33627084\n",
      "Epoch [1260/5000], Loss: 0.33529779\n",
      "Epoch [1270/5000], Loss: 0.33435348\n",
      "Epoch [1280/5000], Loss: 0.33343714\n",
      "Epoch [1290/5000], Loss: 0.33254784\n",
      "Epoch [1300/5000], Loss: 0.33168483\n",
      "Epoch [1310/5000], Loss: 0.33084732\n",
      "Epoch [1320/5000], Loss: 0.33003452\n",
      "Epoch [1330/5000], Loss: 0.32924575\n",
      "Epoch [1340/5000], Loss: 0.32848024\n",
      "Epoch [1350/5000], Loss: 0.32773730\n",
      "Epoch [1360/5000], Loss: 0.32701626\n",
      "Epoch [1370/5000], Loss: 0.32631651\n",
      "Epoch [1380/5000], Loss: 0.32563740\n",
      "Epoch [1390/5000], Loss: 0.32497823\n",
      "Epoch [1400/5000], Loss: 0.32433853\n",
      "Epoch [1410/5000], Loss: 0.32371765\n",
      "Epoch [1420/5000], Loss: 0.32311505\n",
      "Epoch [1430/5000], Loss: 0.32253018\n",
      "Epoch [1440/5000], Loss: 0.32196248\n",
      "Epoch [1450/5000], Loss: 0.32141155\n",
      "Epoch [1460/5000], Loss: 0.32087675\n",
      "Epoch [1470/5000], Loss: 0.32035765\n",
      "Epoch [1480/5000], Loss: 0.31985384\n",
      "Epoch [1490/5000], Loss: 0.31936482\n",
      "Epoch [1500/5000], Loss: 0.31889015\n",
      "Epoch [1510/5000], Loss: 0.31842941\n",
      "Epoch [1520/5000], Loss: 0.31798220\n",
      "Epoch [1530/5000], Loss: 0.31754810\n",
      "Epoch [1540/5000], Loss: 0.31712672\n",
      "Epoch [1550/5000], Loss: 0.31671768\n",
      "Epoch [1560/5000], Loss: 0.31632060\n",
      "Epoch [1570/5000], Loss: 0.31593522\n",
      "Epoch [1580/5000], Loss: 0.31556109\n",
      "Epoch [1590/5000], Loss: 0.31519791\n",
      "Epoch [1600/5000], Loss: 0.31484535\n",
      "Epoch [1610/5000], Loss: 0.31450313\n",
      "Epoch [1620/5000], Loss: 0.31417084\n",
      "Epoch [1630/5000], Loss: 0.31384832\n",
      "Epoch [1640/5000], Loss: 0.31353521\n",
      "Epoch [1650/5000], Loss: 0.31323129\n",
      "Epoch [1660/5000], Loss: 0.31293616\n",
      "Epoch [1670/5000], Loss: 0.31264970\n",
      "Epoch [1680/5000], Loss: 0.31237158\n",
      "Epoch [1690/5000], Loss: 0.31210154\n",
      "Epoch [1700/5000], Loss: 0.31183943\n",
      "Epoch [1710/5000], Loss: 0.31158489\n",
      "Epoch [1720/5000], Loss: 0.31133780\n",
      "Epoch [1730/5000], Loss: 0.31109789\n",
      "Epoch [1740/5000], Loss: 0.31086498\n",
      "Epoch [1750/5000], Loss: 0.31063882\n",
      "Epoch [1760/5000], Loss: 0.31041923\n",
      "Epoch [1770/5000], Loss: 0.31020609\n",
      "Epoch [1780/5000], Loss: 0.30999908\n",
      "Epoch [1790/5000], Loss: 0.30979809\n",
      "Epoch [1800/5000], Loss: 0.30960298\n",
      "Epoch [1810/5000], Loss: 0.30941349\n",
      "Epoch [1820/5000], Loss: 0.30922952\n",
      "Epoch [1830/5000], Loss: 0.30905089\n",
      "Epoch [1840/5000], Loss: 0.30887741\n",
      "Epoch [1850/5000], Loss: 0.30870897\n",
      "Epoch [1860/5000], Loss: 0.30854541\n",
      "Epoch [1870/5000], Loss: 0.30838662\n",
      "Epoch [1880/5000], Loss: 0.30823237\n",
      "Epoch [1890/5000], Loss: 0.30808264\n",
      "Epoch [1900/5000], Loss: 0.30793720\n",
      "Epoch [1910/5000], Loss: 0.30779597\n",
      "Epoch [1920/5000], Loss: 0.30765885\n",
      "Epoch [1930/5000], Loss: 0.30752563\n",
      "Epoch [1940/5000], Loss: 0.30739632\n",
      "Epoch [1950/5000], Loss: 0.30727068\n",
      "Epoch [1960/5000], Loss: 0.30714872\n",
      "Epoch [1970/5000], Loss: 0.30703020\n",
      "Epoch [1980/5000], Loss: 0.30691516\n",
      "Epoch [1990/5000], Loss: 0.30680341\n",
      "Epoch [2000/5000], Loss: 0.30669490\n",
      "Epoch [2010/5000], Loss: 0.30658951\n",
      "Epoch [2020/5000], Loss: 0.30648711\n",
      "Epoch [2030/5000], Loss: 0.30638766\n",
      "Epoch [2040/5000], Loss: 0.30629110\n",
      "Epoch [2050/5000], Loss: 0.30619732\n",
      "Epoch [2060/5000], Loss: 0.30610624\n",
      "Epoch [2070/5000], Loss: 0.30601773\n",
      "Epoch [2080/5000], Loss: 0.30593175\n",
      "Epoch [2090/5000], Loss: 0.30584830\n",
      "Epoch [2100/5000], Loss: 0.30576715\n",
      "Epoch [2110/5000], Loss: 0.30568841\n",
      "Epoch [2120/5000], Loss: 0.30561191\n",
      "Epoch [2130/5000], Loss: 0.30553758\n",
      "Epoch [2140/5000], Loss: 0.30546537\n",
      "Epoch [2150/5000], Loss: 0.30539525\n",
      "Epoch [2160/5000], Loss: 0.30532709\n",
      "Epoch [2170/5000], Loss: 0.30526093\n",
      "Epoch [2180/5000], Loss: 0.30519661\n",
      "Epoch [2190/5000], Loss: 0.30513415\n",
      "Epoch [2200/5000], Loss: 0.30507347\n",
      "Epoch [2210/5000], Loss: 0.30501452\n",
      "Epoch [2220/5000], Loss: 0.30495727\n",
      "Epoch [2230/5000], Loss: 0.30490163\n",
      "Epoch [2240/5000], Loss: 0.30484754\n",
      "Epoch [2250/5000], Loss: 0.30479506\n",
      "Epoch [2260/5000], Loss: 0.30474404\n",
      "Epoch [2270/5000], Loss: 0.30469444\n",
      "Epoch [2280/5000], Loss: 0.30464631\n",
      "Epoch [2290/5000], Loss: 0.30459946\n",
      "Epoch [2300/5000], Loss: 0.30455399\n",
      "Epoch [2310/5000], Loss: 0.30450985\n",
      "Epoch [2320/5000], Loss: 0.30446690\n",
      "Epoch [2330/5000], Loss: 0.30442521\n",
      "Epoch [2340/5000], Loss: 0.30438471\n",
      "Epoch [2350/5000], Loss: 0.30434531\n",
      "Epoch [2360/5000], Loss: 0.30430701\n",
      "Epoch [2370/5000], Loss: 0.30426985\n",
      "Epoch [2380/5000], Loss: 0.30423367\n",
      "Epoch [2390/5000], Loss: 0.30419856\n",
      "Epoch [2400/5000], Loss: 0.30416444\n",
      "Epoch [2410/5000], Loss: 0.30413130\n",
      "Epoch [2420/5000], Loss: 0.30409902\n",
      "Epoch [2430/5000], Loss: 0.30406773\n",
      "Epoch [2440/5000], Loss: 0.30403727\n",
      "Epoch [2450/5000], Loss: 0.30400771\n",
      "Epoch [2460/5000], Loss: 0.30397895\n",
      "Epoch [2470/5000], Loss: 0.30395100\n",
      "Epoch [2480/5000], Loss: 0.30392385\n",
      "Epoch [2490/5000], Loss: 0.30389744\n",
      "Epoch [2500/5000], Loss: 0.30387181\n",
      "Epoch [2510/5000], Loss: 0.30384684\n",
      "Epoch [2520/5000], Loss: 0.30382261\n",
      "Epoch [2530/5000], Loss: 0.30379903\n",
      "Epoch [2540/5000], Loss: 0.30377617\n",
      "Epoch [2550/5000], Loss: 0.30375388\n",
      "Epoch [2560/5000], Loss: 0.30373225\n",
      "Epoch [2570/5000], Loss: 0.30371124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2580/5000], Loss: 0.30369076\n",
      "Epoch [2590/5000], Loss: 0.30367091\n",
      "Epoch [2600/5000], Loss: 0.30365160\n",
      "Epoch [2610/5000], Loss: 0.30363280\n",
      "Epoch [2620/5000], Loss: 0.30361456\n",
      "Epoch [2630/5000], Loss: 0.30359682\n",
      "Epoch [2640/5000], Loss: 0.30357957\n",
      "Epoch [2650/5000], Loss: 0.30356276\n",
      "Epoch [2660/5000], Loss: 0.30354643\n",
      "Epoch [2670/5000], Loss: 0.30353060\n",
      "Epoch [2680/5000], Loss: 0.30351517\n",
      "Epoch [2690/5000], Loss: 0.30350021\n",
      "Epoch [2700/5000], Loss: 0.30348563\n",
      "Epoch [2710/5000], Loss: 0.30347148\n",
      "Epoch [2720/5000], Loss: 0.30345768\n",
      "Epoch [2730/5000], Loss: 0.30344430\n",
      "Epoch [2740/5000], Loss: 0.30343124\n",
      "Epoch [2750/5000], Loss: 0.30341858\n",
      "Epoch [2760/5000], Loss: 0.30340627\n",
      "Epoch [2770/5000], Loss: 0.30339429\n",
      "Epoch [2780/5000], Loss: 0.30338269\n",
      "Epoch [2790/5000], Loss: 0.30337134\n",
      "Epoch [2800/5000], Loss: 0.30336031\n",
      "Epoch [2810/5000], Loss: 0.30334961\n",
      "Epoch [2820/5000], Loss: 0.30333918\n",
      "Epoch [2830/5000], Loss: 0.30332905\n",
      "Epoch [2840/5000], Loss: 0.30331919\n",
      "Epoch [2850/5000], Loss: 0.30330962\n",
      "Epoch [2860/5000], Loss: 0.30330029\n",
      "Epoch [2870/5000], Loss: 0.30329126\n",
      "Epoch [2880/5000], Loss: 0.30328241\n",
      "Epoch [2890/5000], Loss: 0.30327386\n",
      "Epoch [2900/5000], Loss: 0.30326551\n",
      "Epoch [2910/5000], Loss: 0.30325741\n",
      "Epoch [2920/5000], Loss: 0.30324954\n",
      "Epoch [2930/5000], Loss: 0.30324188\n",
      "Epoch [2940/5000], Loss: 0.30323440\n",
      "Epoch [2950/5000], Loss: 0.30322713\n",
      "Epoch [2960/5000], Loss: 0.30322006\n",
      "Epoch [2970/5000], Loss: 0.30321321\n",
      "Epoch [2980/5000], Loss: 0.30320650\n",
      "Epoch [2990/5000], Loss: 0.30320004\n",
      "Epoch [3000/5000], Loss: 0.30319372\n",
      "Epoch [3010/5000], Loss: 0.30318755\n",
      "Epoch [3020/5000], Loss: 0.30318156\n",
      "Epoch [3030/5000], Loss: 0.30317575\n",
      "Epoch [3040/5000], Loss: 0.30317008\n",
      "Epoch [3050/5000], Loss: 0.30316457\n",
      "Epoch [3060/5000], Loss: 0.30315924\n",
      "Epoch [3070/5000], Loss: 0.30315399\n",
      "Epoch [3080/5000], Loss: 0.30314890\n",
      "Epoch [3090/5000], Loss: 0.30314398\n",
      "Epoch [3100/5000], Loss: 0.30313915\n",
      "Epoch [3110/5000], Loss: 0.30313447\n",
      "Epoch [3120/5000], Loss: 0.30312991\n",
      "Epoch [3130/5000], Loss: 0.30312547\n",
      "Epoch [3140/5000], Loss: 0.30312118\n",
      "Epoch [3150/5000], Loss: 0.30311698\n",
      "Epoch [3160/5000], Loss: 0.30311292\n",
      "Epoch [3170/5000], Loss: 0.30310893\n",
      "Epoch [3180/5000], Loss: 0.30310506\n",
      "Epoch [3190/5000], Loss: 0.30310136\n",
      "Epoch [3200/5000], Loss: 0.30309770\n",
      "Epoch [3210/5000], Loss: 0.30309409\n",
      "Epoch [3220/5000], Loss: 0.30309066\n",
      "Epoch [3230/5000], Loss: 0.30308726\n",
      "Epoch [3240/5000], Loss: 0.30308396\n",
      "Epoch [3250/5000], Loss: 0.30308074\n",
      "Epoch [3260/5000], Loss: 0.30307767\n",
      "Epoch [3270/5000], Loss: 0.30307466\n",
      "Epoch [3280/5000], Loss: 0.30307168\n",
      "Epoch [3290/5000], Loss: 0.30306882\n",
      "Epoch [3300/5000], Loss: 0.30306602\n",
      "Epoch [3310/5000], Loss: 0.30306330\n",
      "Epoch [3320/5000], Loss: 0.30306068\n",
      "Epoch [3330/5000], Loss: 0.30305809\n",
      "Epoch [3340/5000], Loss: 0.30305558\n",
      "Epoch [3350/5000], Loss: 0.30305317\n",
      "Epoch [3360/5000], Loss: 0.30305073\n",
      "Epoch [3370/5000], Loss: 0.30304843\n",
      "Epoch [3380/5000], Loss: 0.30304617\n",
      "Epoch [3390/5000], Loss: 0.30304402\n",
      "Epoch [3400/5000], Loss: 0.30304188\n",
      "Epoch [3410/5000], Loss: 0.30303976\n",
      "Epoch [3420/5000], Loss: 0.30303779\n",
      "Epoch [3430/5000], Loss: 0.30303580\n",
      "Epoch [3440/5000], Loss: 0.30303389\n",
      "Epoch [3450/5000], Loss: 0.30303201\n",
      "Epoch [3460/5000], Loss: 0.30303019\n",
      "Epoch [3470/5000], Loss: 0.30302840\n",
      "Epoch [3480/5000], Loss: 0.30302674\n",
      "Epoch [3490/5000], Loss: 0.30302501\n",
      "Epoch [3500/5000], Loss: 0.30302340\n",
      "Epoch [3510/5000], Loss: 0.30302173\n",
      "Epoch [3520/5000], Loss: 0.30302021\n",
      "Epoch [3530/5000], Loss: 0.30301872\n",
      "Epoch [3540/5000], Loss: 0.30301726\n",
      "Epoch [3550/5000], Loss: 0.30301580\n",
      "Epoch [3560/5000], Loss: 0.30301443\n",
      "Epoch [3570/5000], Loss: 0.30301303\n",
      "Epoch [3580/5000], Loss: 0.30301172\n",
      "Epoch [3590/5000], Loss: 0.30301043\n",
      "Epoch [3600/5000], Loss: 0.30300921\n",
      "Epoch [3610/5000], Loss: 0.30300793\n",
      "Epoch [3620/5000], Loss: 0.30300674\n",
      "Epoch [3630/5000], Loss: 0.30300561\n",
      "Epoch [3640/5000], Loss: 0.30300444\n",
      "Epoch [3650/5000], Loss: 0.30300337\n",
      "Epoch [3660/5000], Loss: 0.30300230\n",
      "Epoch [3670/5000], Loss: 0.30300125\n",
      "Epoch [3680/5000], Loss: 0.30300021\n",
      "Epoch [3690/5000], Loss: 0.30299923\n",
      "Epoch [3700/5000], Loss: 0.30299827\n",
      "Epoch [3710/5000], Loss: 0.30299735\n",
      "Epoch [3720/5000], Loss: 0.30299643\n",
      "Epoch [3730/5000], Loss: 0.30299550\n",
      "Epoch [3740/5000], Loss: 0.30299467\n",
      "Epoch [3750/5000], Loss: 0.30299377\n",
      "Epoch [3760/5000], Loss: 0.30299297\n",
      "Epoch [3770/5000], Loss: 0.30299217\n",
      "Epoch [3780/5000], Loss: 0.30299136\n",
      "Epoch [3790/5000], Loss: 0.30299062\n",
      "Epoch [3800/5000], Loss: 0.30298990\n",
      "Epoch [3810/5000], Loss: 0.30298918\n",
      "Epoch [3820/5000], Loss: 0.30298844\n",
      "Epoch [3830/5000], Loss: 0.30298775\n",
      "Epoch [3840/5000], Loss: 0.30298704\n",
      "Epoch [3850/5000], Loss: 0.30298644\n",
      "Epoch [3860/5000], Loss: 0.30298582\n",
      "Epoch [3870/5000], Loss: 0.30298516\n",
      "Epoch [3880/5000], Loss: 0.30298457\n",
      "Epoch [3890/5000], Loss: 0.30298397\n",
      "Epoch [3900/5000], Loss: 0.30298337\n",
      "Epoch [3910/5000], Loss: 0.30298287\n",
      "Epoch [3920/5000], Loss: 0.30298227\n",
      "Epoch [3930/5000], Loss: 0.30298176\n",
      "Epoch [3940/5000], Loss: 0.30298123\n",
      "Epoch [3950/5000], Loss: 0.30298072\n",
      "Epoch [3960/5000], Loss: 0.30298024\n",
      "Epoch [3970/5000], Loss: 0.30297977\n",
      "Epoch [3980/5000], Loss: 0.30297929\n",
      "Epoch [3990/5000], Loss: 0.30297881\n",
      "Epoch [4000/5000], Loss: 0.30297837\n",
      "Epoch [4010/5000], Loss: 0.30297795\n",
      "Epoch [4020/5000], Loss: 0.30297750\n",
      "Epoch [4030/5000], Loss: 0.30297711\n",
      "Epoch [4040/5000], Loss: 0.30297673\n",
      "Epoch [4050/5000], Loss: 0.30297631\n",
      "Epoch [4060/5000], Loss: 0.30297595\n",
      "Epoch [4070/5000], Loss: 0.30297559\n",
      "Epoch [4080/5000], Loss: 0.30297524\n",
      "Epoch [4090/5000], Loss: 0.30297485\n",
      "Epoch [4100/5000], Loss: 0.30297449\n",
      "Epoch [4110/5000], Loss: 0.30297416\n",
      "Epoch [4120/5000], Loss: 0.30297384\n",
      "Epoch [4130/5000], Loss: 0.30297354\n",
      "Epoch [4140/5000], Loss: 0.30297318\n",
      "Epoch [4150/5000], Loss: 0.30297288\n",
      "Epoch [4160/5000], Loss: 0.30297261\n",
      "Epoch [4170/5000], Loss: 0.30297232\n",
      "Epoch [4180/5000], Loss: 0.30297202\n",
      "Epoch [4190/5000], Loss: 0.30297175\n",
      "Epoch [4200/5000], Loss: 0.30297151\n",
      "Epoch [4210/5000], Loss: 0.30297121\n",
      "Epoch [4220/5000], Loss: 0.30297095\n",
      "Epoch [4230/5000], Loss: 0.30297071\n",
      "Epoch [4240/5000], Loss: 0.30297050\n",
      "Epoch [4250/5000], Loss: 0.30297023\n",
      "Epoch [4260/5000], Loss: 0.30297002\n",
      "Epoch [4270/5000], Loss: 0.30296975\n",
      "Epoch [4280/5000], Loss: 0.30296957\n",
      "Epoch [4290/5000], Loss: 0.30296937\n",
      "Epoch [4300/5000], Loss: 0.30296913\n",
      "Epoch [4310/5000], Loss: 0.30296892\n",
      "Epoch [4320/5000], Loss: 0.30296877\n",
      "Epoch [4330/5000], Loss: 0.30296853\n",
      "Epoch [4340/5000], Loss: 0.30296838\n",
      "Epoch [4350/5000], Loss: 0.30296814\n",
      "Epoch [4360/5000], Loss: 0.30296800\n",
      "Epoch [4370/5000], Loss: 0.30296782\n",
      "Epoch [4380/5000], Loss: 0.30296764\n",
      "Epoch [4390/5000], Loss: 0.30296749\n",
      "Epoch [4400/5000], Loss: 0.30296734\n",
      "Epoch [4410/5000], Loss: 0.30296713\n",
      "Epoch [4420/5000], Loss: 0.30296701\n",
      "Epoch [4430/5000], Loss: 0.30296689\n",
      "Epoch [4440/5000], Loss: 0.30296668\n",
      "Epoch [4450/5000], Loss: 0.30296654\n",
      "Epoch [4460/5000], Loss: 0.30296642\n",
      "Epoch [4470/5000], Loss: 0.30296627\n",
      "Epoch [4480/5000], Loss: 0.30296612\n",
      "Epoch [4490/5000], Loss: 0.30296603\n",
      "Epoch [4500/5000], Loss: 0.30296588\n",
      "Epoch [4510/5000], Loss: 0.30296576\n",
      "Epoch [4520/5000], Loss: 0.30296564\n",
      "Epoch [4530/5000], Loss: 0.30296558\n",
      "Epoch [4540/5000], Loss: 0.30296540\n",
      "Epoch [4550/5000], Loss: 0.30296528\n",
      "Epoch [4560/5000], Loss: 0.30296516\n",
      "Epoch [4570/5000], Loss: 0.30296510\n",
      "Epoch [4580/5000], Loss: 0.30296499\n",
      "Epoch [4590/5000], Loss: 0.30296487\n",
      "Epoch [4600/5000], Loss: 0.30296478\n",
      "Epoch [4610/5000], Loss: 0.30296469\n",
      "Epoch [4620/5000], Loss: 0.30296460\n",
      "Epoch [4630/5000], Loss: 0.30296451\n",
      "Epoch [4640/5000], Loss: 0.30296439\n",
      "Epoch [4650/5000], Loss: 0.30296427\n",
      "Epoch [4660/5000], Loss: 0.30296424\n",
      "Epoch [4670/5000], Loss: 0.30296415\n",
      "Epoch [4680/5000], Loss: 0.30296403\n",
      "Epoch [4690/5000], Loss: 0.30296394\n",
      "Epoch [4700/5000], Loss: 0.30296391\n",
      "Epoch [4710/5000], Loss: 0.30296382\n",
      "Epoch [4720/5000], Loss: 0.30296376\n",
      "Epoch [4730/5000], Loss: 0.30296367\n",
      "Epoch [4740/5000], Loss: 0.30296361\n",
      "Epoch [4750/5000], Loss: 0.30296355\n",
      "Epoch [4760/5000], Loss: 0.30296347\n",
      "Epoch [4770/5000], Loss: 0.30296341\n",
      "Epoch [4780/5000], Loss: 0.30296332\n",
      "Epoch [4790/5000], Loss: 0.30296329\n",
      "Epoch [4800/5000], Loss: 0.30296320\n",
      "Epoch [4810/5000], Loss: 0.30296317\n",
      "Epoch [4820/5000], Loss: 0.30296311\n",
      "Epoch [4830/5000], Loss: 0.30296305\n",
      "Epoch [4840/5000], Loss: 0.30296296\n",
      "Epoch [4850/5000], Loss: 0.30296296\n",
      "Epoch [4860/5000], Loss: 0.30296290\n",
      "Epoch [4870/5000], Loss: 0.30296284\n",
      "Epoch [4880/5000], Loss: 0.30296278\n",
      "Epoch [4890/5000], Loss: 0.30296272\n",
      "Epoch [4900/5000], Loss: 0.30296269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4910/5000], Loss: 0.30296263\n",
      "Epoch [4920/5000], Loss: 0.30296260\n",
      "Epoch [4930/5000], Loss: 0.30296254\n",
      "Epoch [4940/5000], Loss: 0.30296251\n",
      "Epoch [4950/5000], Loss: 0.30296245\n",
      "Epoch [4960/5000], Loss: 0.30296239\n",
      "Epoch [4970/5000], Loss: 0.30296236\n",
      "Epoch [4980/5000], Loss: 0.30296236\n",
      "Epoch [4990/5000], Loss: 0.30296227\n",
      "Epoch [5000/5000], Loss: 0.30296227\n",
      "Trained weights: tensor([ 0.0608, -2.1335,  3.8474], requires_grad=True)\n",
      "Trained bias: tensor([2.8643], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error rate: tensor(0.3812)\n",
      "Test error rate: tensor(0.3625)\n"
     ]
    }
   ],
   "source": [
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define the number of features\n",
    "num_features = X_train_tensor.size()[1]\n",
    "\n",
    "# Define the model parameters (weights and bias)\n",
    "w = torch.zeros(num_features, dtype=torch.float, requires_grad=True)\n",
    "# w = torch.tensor([1., 1., 1.], requires_grad=True)\n",
    "b = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "# b = torch.tensor([1.], requires_grad=True)\n",
    "cost_history = []\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Vanilla Gradient Descent)\n",
    "optimizer = torch.optim.SGD([w, b], lr=learning_rate, weight_decay=0)\n",
    "\n",
    "# Perform gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = torch.matmul(X_train_tensor.float(), w) + b\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record the loss\n",
    "    cost_history.append(loss.detach().numpy())\n",
    "    \n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}')\n",
    "        \n",
    "\n",
    "# Print learned parameters\n",
    "print('Trained weights:', w)\n",
    "print('Trained bias:', b)\n",
    "\n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w.detach().numpy(), b.detach().numpy())\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w.detach().numpy(), b.detach().numpy())\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa3f70",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e79914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3285b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (activation_stack): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/5000], Loss: 17.65631294\n",
      "Epoch [10/5000], Loss: 9.74049568\n",
      "Epoch [20/5000], Loss: 5.38651800\n",
      "Epoch [30/5000], Loss: 3.30731153\n",
      "Epoch [40/5000], Loss: 2.30308795\n",
      "Epoch [50/5000], Loss: 1.80739093\n",
      "Epoch [60/5000], Loss: 1.55274749\n",
      "Epoch [70/5000], Loss: 1.41283226\n",
      "Epoch [80/5000], Loss: 1.32795680\n",
      "Epoch [90/5000], Loss: 1.26989341\n",
      "Epoch [100/5000], Loss: 1.22527003\n",
      "Epoch [110/5000], Loss: 1.18773103\n",
      "Epoch [120/5000], Loss: 1.15423524\n",
      "Epoch [130/5000], Loss: 1.12330937\n",
      "Epoch [140/5000], Loss: 1.09422243\n",
      "Epoch [150/5000], Loss: 1.06659698\n",
      "Epoch [160/5000], Loss: 1.04022360\n",
      "Epoch [170/5000], Loss: 1.01497483\n",
      "Epoch [180/5000], Loss: 0.99076378\n",
      "Epoch [190/5000], Loss: 0.96752387\n",
      "Epoch [200/5000], Loss: 0.94520015\n",
      "Epoch [210/5000], Loss: 0.92374480\n",
      "Epoch [220/5000], Loss: 0.90311396\n",
      "Epoch [230/5000], Loss: 0.88326770\n",
      "Epoch [240/5000], Loss: 0.86416852\n",
      "Epoch [250/5000], Loss: 0.84578162\n",
      "Epoch [260/5000], Loss: 0.82807416\n",
      "Epoch [270/5000], Loss: 0.81101543\n",
      "Epoch [280/5000], Loss: 0.79457617\n",
      "Epoch [290/5000], Loss: 0.77872920\n",
      "Epoch [300/5000], Loss: 0.76344860\n",
      "Epoch [310/5000], Loss: 0.74871004\n",
      "Epoch [320/5000], Loss: 0.73449039\n",
      "Epoch [330/5000], Loss: 0.72076786\n",
      "Epoch [340/5000], Loss: 0.70752180\n",
      "Epoch [350/5000], Loss: 0.69473279\n",
      "Epoch [360/5000], Loss: 0.68238211\n",
      "Epoch [370/5000], Loss: 0.67045230\n",
      "Epoch [380/5000], Loss: 0.65892661\n",
      "Epoch [390/5000], Loss: 0.64778912\n",
      "Epoch [400/5000], Loss: 0.63702470\n",
      "Epoch [410/5000], Loss: 0.62661910\n",
      "Epoch [420/5000], Loss: 0.61655879\n",
      "Epoch [430/5000], Loss: 0.60683036\n",
      "Epoch [440/5000], Loss: 0.59742182\n",
      "Epoch [450/5000], Loss: 0.58832103\n",
      "Epoch [460/5000], Loss: 0.57951665\n",
      "Epoch [470/5000], Loss: 0.57099813\n",
      "Epoch [480/5000], Loss: 0.56275505\n",
      "Epoch [490/5000], Loss: 0.55477774\n",
      "Epoch [500/5000], Loss: 0.54705632\n",
      "Epoch [510/5000], Loss: 0.53958189\n",
      "Epoch [520/5000], Loss: 0.53234595\n",
      "Epoch [530/5000], Loss: 0.52534014\n",
      "Epoch [540/5000], Loss: 0.51855642\n",
      "Epoch [550/5000], Loss: 0.51198727\n",
      "Epoch [560/5000], Loss: 0.50562531\n",
      "Epoch [570/5000], Loss: 0.49946362\n",
      "Epoch [580/5000], Loss: 0.49349523\n",
      "Epoch [590/5000], Loss: 0.48771366\n",
      "Epoch [600/5000], Loss: 0.48211282\n",
      "Epoch [610/5000], Loss: 0.47668657\n",
      "Epoch [620/5000], Loss: 0.47142920\n",
      "Epoch [630/5000], Loss: 0.46633515\n",
      "Epoch [640/5000], Loss: 0.46139902\n",
      "Epoch [650/5000], Loss: 0.45661569\n",
      "Epoch [660/5000], Loss: 0.45198011\n",
      "Epoch [670/5000], Loss: 0.44748750\n",
      "Epoch [680/5000], Loss: 0.44313341\n",
      "Epoch [690/5000], Loss: 0.43891326\n",
      "Epoch [700/5000], Loss: 0.43482271\n",
      "Epoch [710/5000], Loss: 0.43085760\n",
      "Epoch [720/5000], Loss: 0.42701411\n",
      "Epoch [730/5000], Loss: 0.42328826\n",
      "Epoch [740/5000], Loss: 0.41967624\n",
      "Epoch [750/5000], Loss: 0.41617459\n",
      "Epoch [760/5000], Loss: 0.41277975\n",
      "Epoch [770/5000], Loss: 0.40948838\n",
      "Epoch [780/5000], Loss: 0.40629727\n",
      "Epoch [790/5000], Loss: 0.40320319\n",
      "Epoch [800/5000], Loss: 0.40020314\n",
      "Epoch [810/5000], Loss: 0.39729422\n",
      "Epoch [820/5000], Loss: 0.39447355\n",
      "Epoch [830/5000], Loss: 0.39173844\n",
      "Epoch [840/5000], Loss: 0.38908616\n",
      "Epoch [850/5000], Loss: 0.38651419\n",
      "Epoch [860/5000], Loss: 0.38402006\n",
      "Epoch [870/5000], Loss: 0.38160133\n",
      "Epoch [880/5000], Loss: 0.37925571\n",
      "Epoch [890/5000], Loss: 0.37698099\n",
      "Epoch [900/5000], Loss: 0.37477475\n",
      "Epoch [910/5000], Loss: 0.37263519\n",
      "Epoch [920/5000], Loss: 0.37056008\n",
      "Epoch [930/5000], Loss: 0.36854753\n",
      "Epoch [940/5000], Loss: 0.36659551\n",
      "Epoch [950/5000], Loss: 0.36470225\n",
      "Epoch [960/5000], Loss: 0.36286601\n",
      "Epoch [970/5000], Loss: 0.36108506\n",
      "Epoch [980/5000], Loss: 0.35935757\n",
      "Epoch [990/5000], Loss: 0.35768202\n",
      "Epoch [1000/5000], Loss: 0.35605675\n",
      "Epoch [1010/5000], Loss: 0.35448033\n",
      "Epoch [1020/5000], Loss: 0.35295120\n",
      "Epoch [1030/5000], Loss: 0.35146791\n",
      "Epoch [1040/5000], Loss: 0.35002908\n",
      "Epoch [1050/5000], Loss: 0.34863347\n",
      "Epoch [1060/5000], Loss: 0.34727958\n",
      "Epoch [1070/5000], Loss: 0.34596631\n",
      "Epoch [1080/5000], Loss: 0.34469229\n",
      "Epoch [1090/5000], Loss: 0.34345642\n",
      "Epoch [1100/5000], Loss: 0.34225759\n",
      "Epoch [1110/5000], Loss: 0.34109458\n",
      "Epoch [1120/5000], Loss: 0.33996639\n",
      "Epoch [1130/5000], Loss: 0.33887181\n",
      "Epoch [1140/5000], Loss: 0.33781007\n",
      "Epoch [1150/5000], Loss: 0.33677995\n",
      "Epoch [1160/5000], Loss: 0.33578062\n",
      "Epoch [1170/5000], Loss: 0.33481115\n",
      "Epoch [1180/5000], Loss: 0.33387059\n",
      "Epoch [1190/5000], Loss: 0.33295819\n",
      "Epoch [1200/5000], Loss: 0.33207291\n",
      "Epoch [1210/5000], Loss: 0.33121404\n",
      "Epoch [1220/5000], Loss: 0.33038077\n",
      "Epoch [1230/5000], Loss: 0.32957229\n",
      "Epoch [1240/5000], Loss: 0.32878795\n",
      "Epoch [1250/5000], Loss: 0.32802698\n",
      "Epoch [1260/5000], Loss: 0.32728860\n",
      "Epoch [1270/5000], Loss: 0.32657227\n",
      "Epoch [1280/5000], Loss: 0.32587728\n",
      "Epoch [1290/5000], Loss: 0.32520291\n",
      "Epoch [1300/5000], Loss: 0.32454866\n",
      "Epoch [1310/5000], Loss: 0.32391375\n",
      "Epoch [1320/5000], Loss: 0.32329780\n",
      "Epoch [1330/5000], Loss: 0.32270017\n",
      "Epoch [1340/5000], Loss: 0.32212025\n",
      "Epoch [1350/5000], Loss: 0.32155758\n",
      "Epoch [1360/5000], Loss: 0.32101160\n",
      "Epoch [1370/5000], Loss: 0.32048184\n",
      "Epoch [1380/5000], Loss: 0.31996781\n",
      "Epoch [1390/5000], Loss: 0.31946903\n",
      "Epoch [1400/5000], Loss: 0.31898502\n",
      "Epoch [1410/5000], Loss: 0.31851536\n",
      "Epoch [1420/5000], Loss: 0.31805965\n",
      "Epoch [1430/5000], Loss: 0.31761745\n",
      "Epoch [1440/5000], Loss: 0.31718832\n",
      "Epoch [1450/5000], Loss: 0.31677189\n",
      "Epoch [1460/5000], Loss: 0.31636781\n",
      "Epoch [1470/5000], Loss: 0.31597573\n",
      "Epoch [1480/5000], Loss: 0.31559521\n",
      "Epoch [1490/5000], Loss: 0.31522593\n",
      "Epoch [1500/5000], Loss: 0.31486759\n",
      "Epoch [1510/5000], Loss: 0.31451985\n",
      "Epoch [1520/5000], Loss: 0.31418243\n",
      "Epoch [1530/5000], Loss: 0.31385487\n",
      "Epoch [1540/5000], Loss: 0.31353706\n",
      "Epoch [1550/5000], Loss: 0.31322867\n",
      "Epoch [1560/5000], Loss: 0.31292933\n",
      "Epoch [1570/5000], Loss: 0.31263885\n",
      "Epoch [1580/5000], Loss: 0.31235695\n",
      "Epoch [1590/5000], Loss: 0.31208333\n",
      "Epoch [1600/5000], Loss: 0.31181777\n",
      "Epoch [1610/5000], Loss: 0.31156003\n",
      "Epoch [1620/5000], Loss: 0.31130993\n",
      "Epoch [1630/5000], Loss: 0.31106719\n",
      "Epoch [1640/5000], Loss: 0.31083161\n",
      "Epoch [1650/5000], Loss: 0.31060296\n",
      "Epoch [1660/5000], Loss: 0.31038103\n",
      "Epoch [1670/5000], Loss: 0.31016561\n",
      "Epoch [1680/5000], Loss: 0.30995658\n",
      "Epoch [1690/5000], Loss: 0.30975369\n",
      "Epoch [1700/5000], Loss: 0.30955672\n",
      "Epoch [1710/5000], Loss: 0.30936557\n",
      "Epoch [1720/5000], Loss: 0.30917999\n",
      "Epoch [1730/5000], Loss: 0.30899996\n",
      "Epoch [1740/5000], Loss: 0.30882517\n",
      "Epoch [1750/5000], Loss: 0.30865550\n",
      "Epoch [1760/5000], Loss: 0.30849081\n",
      "Epoch [1770/5000], Loss: 0.30833095\n",
      "Epoch [1780/5000], Loss: 0.30817577\n",
      "Epoch [1790/5000], Loss: 0.30802515\n",
      "Epoch [1800/5000], Loss: 0.30787891\n",
      "Epoch [1810/5000], Loss: 0.30773699\n",
      "Epoch [1820/5000], Loss: 0.30759922\n",
      "Epoch [1830/5000], Loss: 0.30746549\n",
      "Epoch [1840/5000], Loss: 0.30733567\n",
      "Epoch [1850/5000], Loss: 0.30720964\n",
      "Epoch [1860/5000], Loss: 0.30708724\n",
      "Epoch [1870/5000], Loss: 0.30696851\n",
      "Epoch [1880/5000], Loss: 0.30685323\n",
      "Epoch [1890/5000], Loss: 0.30674130\n",
      "Epoch [1900/5000], Loss: 0.30663264\n",
      "Epoch [1910/5000], Loss: 0.30652711\n",
      "Epoch [1920/5000], Loss: 0.30642468\n",
      "Epoch [1930/5000], Loss: 0.30632529\n",
      "Epoch [1940/5000], Loss: 0.30622879\n",
      "Epoch [1950/5000], Loss: 0.30613509\n",
      "Epoch [1960/5000], Loss: 0.30604407\n",
      "Epoch [1970/5000], Loss: 0.30595571\n",
      "Epoch [1980/5000], Loss: 0.30587000\n",
      "Epoch [1990/5000], Loss: 0.30578673\n",
      "Epoch [2000/5000], Loss: 0.30570588\n",
      "Epoch [2010/5000], Loss: 0.30562738\n",
      "Epoch [2020/5000], Loss: 0.30555120\n",
      "Epoch [2030/5000], Loss: 0.30547720\n",
      "Epoch [2040/5000], Loss: 0.30540532\n",
      "Epoch [2050/5000], Loss: 0.30533558\n",
      "Epoch [2060/5000], Loss: 0.30526784\n",
      "Epoch [2070/5000], Loss: 0.30520207\n",
      "Epoch [2080/5000], Loss: 0.30513820\n",
      "Epoch [2090/5000], Loss: 0.30507618\n",
      "Epoch [2100/5000], Loss: 0.30501598\n",
      "Epoch [2110/5000], Loss: 0.30495748\n",
      "Epoch [2120/5000], Loss: 0.30490071\n",
      "Epoch [2130/5000], Loss: 0.30484560\n",
      "Epoch [2140/5000], Loss: 0.30479202\n",
      "Epoch [2150/5000], Loss: 0.30474001\n",
      "Epoch [2160/5000], Loss: 0.30468950\n",
      "Epoch [2170/5000], Loss: 0.30464050\n",
      "Epoch [2180/5000], Loss: 0.30459291\n",
      "Epoch [2190/5000], Loss: 0.30454665\n",
      "Epoch [2200/5000], Loss: 0.30450174\n",
      "Epoch [2210/5000], Loss: 0.30445814\n",
      "Epoch [2220/5000], Loss: 0.30441579\n",
      "Epoch [2230/5000], Loss: 0.30437467\n",
      "Epoch [2240/5000], Loss: 0.30433470\n",
      "Epoch [2250/5000], Loss: 0.30429584\n",
      "Epoch [2260/5000], Loss: 0.30425820\n",
      "Epoch [2270/5000], Loss: 0.30422163\n",
      "Epoch [2280/5000], Loss: 0.30418602\n",
      "Epoch [2290/5000], Loss: 0.30415154\n",
      "Epoch [2300/5000], Loss: 0.30411798\n",
      "Epoch [2310/5000], Loss: 0.30408540\n",
      "Epoch [2320/5000], Loss: 0.30405378\n",
      "Epoch [2330/5000], Loss: 0.30402309\n",
      "Epoch [2340/5000], Loss: 0.30399320\n",
      "Epoch [2350/5000], Loss: 0.30396420\n",
      "Epoch [2360/5000], Loss: 0.30393606\n",
      "Epoch [2370/5000], Loss: 0.30390868\n",
      "Epoch [2380/5000], Loss: 0.30388209\n",
      "Epoch [2390/5000], Loss: 0.30385631\n",
      "Epoch [2400/5000], Loss: 0.30383122\n",
      "Epoch [2410/5000], Loss: 0.30380684\n",
      "Epoch [2420/5000], Loss: 0.30378321\n",
      "Epoch [2430/5000], Loss: 0.30376020\n",
      "Epoch [2440/5000], Loss: 0.30373785\n",
      "Epoch [2450/5000], Loss: 0.30371615\n",
      "Epoch [2460/5000], Loss: 0.30369511\n",
      "Epoch [2470/5000], Loss: 0.30367461\n",
      "Epoch [2480/5000], Loss: 0.30365476\n",
      "Epoch [2490/5000], Loss: 0.30363542\n",
      "Epoch [2500/5000], Loss: 0.30361664\n",
      "Epoch [2510/5000], Loss: 0.30359840\n",
      "Epoch [2520/5000], Loss: 0.30358070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2530/5000], Loss: 0.30356345\n",
      "Epoch [2540/5000], Loss: 0.30354673\n",
      "Epoch [2550/5000], Loss: 0.30353042\n",
      "Epoch [2560/5000], Loss: 0.30351466\n",
      "Epoch [2570/5000], Loss: 0.30349928\n",
      "Epoch [2580/5000], Loss: 0.30348444\n",
      "Epoch [2590/5000], Loss: 0.30346990\n",
      "Epoch [2600/5000], Loss: 0.30345577\n",
      "Epoch [2610/5000], Loss: 0.30344212\n",
      "Epoch [2620/5000], Loss: 0.30342883\n",
      "Epoch [2630/5000], Loss: 0.30341589\n",
      "Epoch [2640/5000], Loss: 0.30340335\n",
      "Epoch [2650/5000], Loss: 0.30339113\n",
      "Epoch [2660/5000], Loss: 0.30337930\n",
      "Epoch [2670/5000], Loss: 0.30336776\n",
      "Epoch [2680/5000], Loss: 0.30335659\n",
      "Epoch [2690/5000], Loss: 0.30334568\n",
      "Epoch [2700/5000], Loss: 0.30333510\n",
      "Epoch [2710/5000], Loss: 0.30332482\n",
      "Epoch [2720/5000], Loss: 0.30331486\n",
      "Epoch [2730/5000], Loss: 0.30330512\n",
      "Epoch [2740/5000], Loss: 0.30329567\n",
      "Epoch [2750/5000], Loss: 0.30328652\n",
      "Epoch [2760/5000], Loss: 0.30327755\n",
      "Epoch [2770/5000], Loss: 0.30326891\n",
      "Epoch [2780/5000], Loss: 0.30326048\n",
      "Epoch [2790/5000], Loss: 0.30325228\n",
      "Epoch [2800/5000], Loss: 0.30324432\n",
      "Epoch [2810/5000], Loss: 0.30323663\n",
      "Epoch [2820/5000], Loss: 0.30322909\n",
      "Epoch [2830/5000], Loss: 0.30322179\n",
      "Epoch [2840/5000], Loss: 0.30321467\n",
      "Epoch [2850/5000], Loss: 0.30320776\n",
      "Epoch [2860/5000], Loss: 0.30320105\n",
      "Epoch [2870/5000], Loss: 0.30319452\n",
      "Epoch [2880/5000], Loss: 0.30318815\n",
      "Epoch [2890/5000], Loss: 0.30318198\n",
      "Epoch [2900/5000], Loss: 0.30317599\n",
      "Epoch [2910/5000], Loss: 0.30317017\n",
      "Epoch [2920/5000], Loss: 0.30316451\n",
      "Epoch [2930/5000], Loss: 0.30315900\n",
      "Epoch [2940/5000], Loss: 0.30315363\n",
      "Epoch [2950/5000], Loss: 0.30314839\n",
      "Epoch [2960/5000], Loss: 0.30314338\n",
      "Epoch [2970/5000], Loss: 0.30313843\n",
      "Epoch [2980/5000], Loss: 0.30313364\n",
      "Epoch [2990/5000], Loss: 0.30312902\n",
      "Epoch [3000/5000], Loss: 0.30312443\n",
      "Epoch [3010/5000], Loss: 0.30312008\n",
      "Epoch [3020/5000], Loss: 0.30311576\n",
      "Epoch [3030/5000], Loss: 0.30311161\n",
      "Epoch [3040/5000], Loss: 0.30310756\n",
      "Epoch [3050/5000], Loss: 0.30310360\n",
      "Epoch [3060/5000], Loss: 0.30309978\n",
      "Epoch [3070/5000], Loss: 0.30309606\n",
      "Epoch [3080/5000], Loss: 0.30309242\n",
      "Epoch [3090/5000], Loss: 0.30308890\n",
      "Epoch [3100/5000], Loss: 0.30308548\n",
      "Epoch [3110/5000], Loss: 0.30308214\n",
      "Epoch [3120/5000], Loss: 0.30307889\n",
      "Epoch [3130/5000], Loss: 0.30307573\n",
      "Epoch [3140/5000], Loss: 0.30307269\n",
      "Epoch [3150/5000], Loss: 0.30306968\n",
      "Epoch [3160/5000], Loss: 0.30306682\n",
      "Epoch [3170/5000], Loss: 0.30306399\n",
      "Epoch [3180/5000], Loss: 0.30306125\n",
      "Epoch [3190/5000], Loss: 0.30305856\n",
      "Epoch [3200/5000], Loss: 0.30305597\n",
      "Epoch [3210/5000], Loss: 0.30305344\n",
      "Epoch [3220/5000], Loss: 0.30305099\n",
      "Epoch [3230/5000], Loss: 0.30304861\n",
      "Epoch [3240/5000], Loss: 0.30304629\n",
      "Epoch [3250/5000], Loss: 0.30304402\n",
      "Epoch [3260/5000], Loss: 0.30304185\n",
      "Epoch [3270/5000], Loss: 0.30303967\n",
      "Epoch [3280/5000], Loss: 0.30303758\n",
      "Epoch [3290/5000], Loss: 0.30303559\n",
      "Epoch [3300/5000], Loss: 0.30303356\n",
      "Epoch [3310/5000], Loss: 0.30303168\n",
      "Epoch [3320/5000], Loss: 0.30302984\n",
      "Epoch [3330/5000], Loss: 0.30302802\n",
      "Epoch [3340/5000], Loss: 0.30302623\n",
      "Epoch [3350/5000], Loss: 0.30302450\n",
      "Epoch [3360/5000], Loss: 0.30302283\n",
      "Epoch [3370/5000], Loss: 0.30302119\n",
      "Epoch [3380/5000], Loss: 0.30301964\n",
      "Epoch [3390/5000], Loss: 0.30301806\n",
      "Epoch [3400/5000], Loss: 0.30301660\n",
      "Epoch [3410/5000], Loss: 0.30301508\n",
      "Epoch [3420/5000], Loss: 0.30301371\n",
      "Epoch [3430/5000], Loss: 0.30301231\n",
      "Epoch [3440/5000], Loss: 0.30301100\n",
      "Epoch [3450/5000], Loss: 0.30300966\n",
      "Epoch [3460/5000], Loss: 0.30300838\n",
      "Epoch [3470/5000], Loss: 0.30300719\n",
      "Epoch [3480/5000], Loss: 0.30300593\n",
      "Epoch [3490/5000], Loss: 0.30300477\n",
      "Epoch [3500/5000], Loss: 0.30300361\n",
      "Epoch [3510/5000], Loss: 0.30300254\n",
      "Epoch [3520/5000], Loss: 0.30300140\n",
      "Epoch [3530/5000], Loss: 0.30300039\n",
      "Epoch [3540/5000], Loss: 0.30299938\n",
      "Epoch [3550/5000], Loss: 0.30299836\n",
      "Epoch [3560/5000], Loss: 0.30299738\n",
      "Epoch [3570/5000], Loss: 0.30299646\n",
      "Epoch [3580/5000], Loss: 0.30299553\n",
      "Epoch [3590/5000], Loss: 0.30299464\n",
      "Epoch [3600/5000], Loss: 0.30299377\n",
      "Epoch [3610/5000], Loss: 0.30299288\n",
      "Epoch [3620/5000], Loss: 0.30299208\n",
      "Epoch [3630/5000], Loss: 0.30299121\n",
      "Epoch [3640/5000], Loss: 0.30299050\n",
      "Epoch [3650/5000], Loss: 0.30298969\n",
      "Epoch [3660/5000], Loss: 0.30298895\n",
      "Epoch [3670/5000], Loss: 0.30298823\n",
      "Epoch [3680/5000], Loss: 0.30298752\n",
      "Epoch [3690/5000], Loss: 0.30298683\n",
      "Epoch [3700/5000], Loss: 0.30298617\n",
      "Epoch [3710/5000], Loss: 0.30298555\n",
      "Epoch [3720/5000], Loss: 0.30298489\n",
      "Epoch [3730/5000], Loss: 0.30298427\n",
      "Epoch [3740/5000], Loss: 0.30298367\n",
      "Epoch [3750/5000], Loss: 0.30298308\n",
      "Epoch [3760/5000], Loss: 0.30298251\n",
      "Epoch [3770/5000], Loss: 0.30298200\n",
      "Epoch [3780/5000], Loss: 0.30298144\n",
      "Epoch [3790/5000], Loss: 0.30298093\n",
      "Epoch [3800/5000], Loss: 0.30298036\n",
      "Epoch [3810/5000], Loss: 0.30297989\n",
      "Epoch [3820/5000], Loss: 0.30297941\n",
      "Epoch [3830/5000], Loss: 0.30297893\n",
      "Epoch [3840/5000], Loss: 0.30297846\n",
      "Epoch [3850/5000], Loss: 0.30297804\n",
      "Epoch [3860/5000], Loss: 0.30297756\n",
      "Epoch [3870/5000], Loss: 0.30297714\n",
      "Epoch [3880/5000], Loss: 0.30297676\n",
      "Epoch [3890/5000], Loss: 0.30297631\n",
      "Epoch [3900/5000], Loss: 0.30297592\n",
      "Epoch [3910/5000], Loss: 0.30297557\n",
      "Epoch [3920/5000], Loss: 0.30297515\n",
      "Epoch [3930/5000], Loss: 0.30297479\n",
      "Epoch [3940/5000], Loss: 0.30297449\n",
      "Epoch [3950/5000], Loss: 0.30297410\n",
      "Epoch [3960/5000], Loss: 0.30297375\n",
      "Epoch [3970/5000], Loss: 0.30297345\n",
      "Epoch [3980/5000], Loss: 0.30297312\n",
      "Epoch [3990/5000], Loss: 0.30297282\n",
      "Epoch [4000/5000], Loss: 0.30297253\n",
      "Epoch [4010/5000], Loss: 0.30297220\n",
      "Epoch [4020/5000], Loss: 0.30297196\n",
      "Epoch [4030/5000], Loss: 0.30297166\n",
      "Epoch [4040/5000], Loss: 0.30297136\n",
      "Epoch [4050/5000], Loss: 0.30297107\n",
      "Epoch [4060/5000], Loss: 0.30297086\n",
      "Epoch [4070/5000], Loss: 0.30297059\n",
      "Epoch [4080/5000], Loss: 0.30297035\n",
      "Epoch [4090/5000], Loss: 0.30297011\n",
      "Epoch [4100/5000], Loss: 0.30296987\n",
      "Epoch [4110/5000], Loss: 0.30296963\n",
      "Epoch [4120/5000], Loss: 0.30296943\n",
      "Epoch [4130/5000], Loss: 0.30296925\n",
      "Epoch [4140/5000], Loss: 0.30296901\n",
      "Epoch [4150/5000], Loss: 0.30296880\n",
      "Epoch [4160/5000], Loss: 0.30296856\n",
      "Epoch [4170/5000], Loss: 0.30296841\n",
      "Epoch [4180/5000], Loss: 0.30296820\n",
      "Epoch [4190/5000], Loss: 0.30296803\n",
      "Epoch [4200/5000], Loss: 0.30296785\n",
      "Epoch [4210/5000], Loss: 0.30296764\n",
      "Epoch [4220/5000], Loss: 0.30296749\n",
      "Epoch [4230/5000], Loss: 0.30296731\n",
      "Epoch [4240/5000], Loss: 0.30296713\n",
      "Epoch [4250/5000], Loss: 0.30296701\n",
      "Epoch [4260/5000], Loss: 0.30296686\n",
      "Epoch [4270/5000], Loss: 0.30296668\n",
      "Epoch [4280/5000], Loss: 0.30296654\n",
      "Epoch [4290/5000], Loss: 0.30296639\n",
      "Epoch [4300/5000], Loss: 0.30296627\n",
      "Epoch [4310/5000], Loss: 0.30296615\n",
      "Epoch [4320/5000], Loss: 0.30296600\n",
      "Epoch [4330/5000], Loss: 0.30296588\n",
      "Epoch [4340/5000], Loss: 0.30296573\n",
      "Epoch [4350/5000], Loss: 0.30296558\n",
      "Epoch [4360/5000], Loss: 0.30296546\n",
      "Epoch [4370/5000], Loss: 0.30296540\n",
      "Epoch [4380/5000], Loss: 0.30296525\n",
      "Epoch [4390/5000], Loss: 0.30296513\n",
      "Epoch [4400/5000], Loss: 0.30296502\n",
      "Epoch [4410/5000], Loss: 0.30296490\n",
      "Epoch [4420/5000], Loss: 0.30296484\n",
      "Epoch [4430/5000], Loss: 0.30296475\n",
      "Epoch [4440/5000], Loss: 0.30296463\n",
      "Epoch [4450/5000], Loss: 0.30296454\n",
      "Epoch [4460/5000], Loss: 0.30296445\n",
      "Epoch [4470/5000], Loss: 0.30296433\n",
      "Epoch [4480/5000], Loss: 0.30296424\n",
      "Epoch [4490/5000], Loss: 0.30296415\n",
      "Epoch [4500/5000], Loss: 0.30296409\n",
      "Epoch [4510/5000], Loss: 0.30296403\n",
      "Epoch [4520/5000], Loss: 0.30296391\n",
      "Epoch [4530/5000], Loss: 0.30296382\n",
      "Epoch [4540/5000], Loss: 0.30296376\n",
      "Epoch [4550/5000], Loss: 0.30296367\n",
      "Epoch [4560/5000], Loss: 0.30296361\n",
      "Epoch [4570/5000], Loss: 0.30296355\n",
      "Epoch [4580/5000], Loss: 0.30296350\n",
      "Epoch [4590/5000], Loss: 0.30296341\n",
      "Epoch [4600/5000], Loss: 0.30296335\n",
      "Epoch [4610/5000], Loss: 0.30296326\n",
      "Epoch [4620/5000], Loss: 0.30296323\n",
      "Epoch [4630/5000], Loss: 0.30296314\n",
      "Epoch [4640/5000], Loss: 0.30296308\n",
      "Epoch [4650/5000], Loss: 0.30296305\n",
      "Epoch [4660/5000], Loss: 0.30296296\n",
      "Epoch [4670/5000], Loss: 0.30296293\n",
      "Epoch [4680/5000], Loss: 0.30296287\n",
      "Epoch [4690/5000], Loss: 0.30296281\n",
      "Epoch [4700/5000], Loss: 0.30296275\n",
      "Epoch [4710/5000], Loss: 0.30296272\n",
      "Epoch [4720/5000], Loss: 0.30296263\n",
      "Epoch [4730/5000], Loss: 0.30296263\n",
      "Epoch [4740/5000], Loss: 0.30296257\n",
      "Epoch [4750/5000], Loss: 0.30296251\n",
      "Epoch [4760/5000], Loss: 0.30296248\n",
      "Epoch [4770/5000], Loss: 0.30296245\n",
      "Epoch [4780/5000], Loss: 0.30296236\n",
      "Epoch [4790/5000], Loss: 0.30296236\n",
      "Epoch [4800/5000], Loss: 0.30296230\n",
      "Epoch [4810/5000], Loss: 0.30296230\n",
      "Epoch [4820/5000], Loss: 0.30296224\n",
      "Epoch [4830/5000], Loss: 0.30296218\n",
      "Epoch [4840/5000], Loss: 0.30296218\n",
      "Epoch [4850/5000], Loss: 0.30296212\n",
      "Epoch [4860/5000], Loss: 0.30296206\n",
      "Epoch [4870/5000], Loss: 0.30296203\n",
      "Epoch [4880/5000], Loss: 0.30296206\n",
      "Epoch [4890/5000], Loss: 0.30296201\n",
      "Epoch [4900/5000], Loss: 0.30296198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4910/5000], Loss: 0.30296192\n",
      "Epoch [4920/5000], Loss: 0.30296189\n",
      "Epoch [4930/5000], Loss: 0.30296189\n",
      "Epoch [4940/5000], Loss: 0.30296183\n",
      "Epoch [4950/5000], Loss: 0.30296183\n",
      "Epoch [4960/5000], Loss: 0.30296177\n",
      "Epoch [4970/5000], Loss: 0.30296177\n",
      "Epoch [4980/5000], Loss: 0.30296174\n",
      "Epoch [4990/5000], Loss: 0.30296174\n",
      "Epoch [5000/5000], Loss: 0.30296168\n",
      "activation_stack.0.weight: tensor([[ 0.0607, -2.1342,  3.8471]])\n",
      "activation_stack.0.bias: tensor([2.8650])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a custom neural network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.activation_stack = nn.Sequential(\n",
    "            nn.Linear(3, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.activation_stack(x)\n",
    "        return torch.squeeze(logits)\n",
    "    \n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define the model parameters\n",
    "cost_history = []\n",
    "\n",
    "# Create an instance of the neural network\n",
    "criterion = torch.nn.MSELoss()\n",
    "NeuralNetwork_model = NeuralNetwork()\n",
    "print(NeuralNetwork_model)\n",
    "optimizer = torch.optim.SGD(NeuralNetwork_model.parameters(), lr=learning_rate, weight_decay = 0)\n",
    "\n",
    "#for name, param in NeuralNetwork_model.named_parameters():\n",
    "#    print( name )\n",
    "#    values = torch.ones( param.shape )\n",
    "#    param.data = values\n",
    "    \n",
    "# Perform training\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward propagation to obtain the predicted output\n",
    "    outputs = NeuralNetwork_model(X_train_tensor.float())\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "    \n",
    "    # Backward propagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record the loss\n",
    "    cost_history.append(loss.item())\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}')\n",
    "        \n",
    "# Print learned parameters\n",
    "for name, param in NeuralNetwork_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'{name}: {param.data}')\n",
    "        \n",
    "        \n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "# train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w.T.detach().numpy(), b.detach().numpy())\n",
    "# print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "# if X_test is not None and y_test is not None:\n",
    "#    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w.T.detach().numpy(), b.detach().numpy())\n",
    "#    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d747c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d591a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7fb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
