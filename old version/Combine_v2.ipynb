{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a8e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages #\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install torch\n",
    "# !pip install xlrd\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b59c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eb81ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading training data\n",
    "dataset = pd.read_csv(\"bmi_train.csv\")\n",
    "dataset.replace({'Gender': {'Female': 0, 'Male': 1}}, inplace=True) #Gender -> boolean\n",
    "dataset = dataset.to_numpy()\n",
    "\n",
    "# Splitting off 80% of data for training, 20% for validation\n",
    "train_split = int(0.8 * len(dataset))\n",
    "X_train = dataset[:train_split, [0,1,2]]\n",
    "y_train = dataset[:train_split, 3]\n",
    "X_test = dataset[train_split:, [0,1,2]]\n",
    "y_test = dataset[train_split:, 3]\n",
    "\n",
    "# Loading prediction data\n",
    "prediction_dataset = pd.read_csv(\"bmi_validation.csv\")\n",
    "prediction_dataset.replace({'Gender': {'Female': 0, 'Male': 1}}, inplace=True) #Gender -> boolean\n",
    "X_prediction = prediction_dataset.to_numpy()\n",
    "\n",
    "# Normalize data set\n",
    "X_train_normalized = (X_train - X_train.min(0)) / (X_train.max(0) - X_train.min(0))\n",
    "X_test_normalized = (X_test - X_test.min(0)) / (X_test.max(0) - X_test.min(0))\n",
    "X_prediction_normalized = (X_prediction - X_prediction.min(0)) / (X_prediction.max(0) - X_prediction.min(0))\n",
    "\n",
    "# Turn data to tensor\n",
    "X_train_tensor = torch.from_numpy(X_train_normalized)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test_normalized)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "X_prediction_tensor = torch.from_numpy(X_prediction_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd85410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test error rate analysis function\n",
    "def calculate_error_rate(X, y, w, b):\n",
    "    num_samples = X.shape[0]\n",
    "    y_pred = np.dot(X, w) + b\n",
    "    error = y_pred - y\n",
    "    squared_error = np.square(error)\n",
    "    mean_squared_error = np.mean(squared_error)\n",
    "    error_rate = np.sqrt(mean_squared_error)\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9bae8",
   "metadata": {},
   "source": [
    "Custom SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1017f7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned parameters:\n",
      "w0 = 0.060808857709234714\n",
      "w1 = -2.1334616790571426\n",
      "w2 = 3.847422443386162\n",
      "b = 2.8643211189596514\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error rate: 0.5504200664658345\n",
      "Test error rate: 0.6053660924842965\n"
     ]
    }
   ],
   "source": [
    "# Vanilia Gradient Descent Algorithms\n",
    "def gradient_descent(X, y, learning_rate, num_iterations):\n",
    "    num_samples, num_features = X.shape\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = np.zeros(num_features)\n",
    "    b = 0\n",
    "    cost_history = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Calculate predictions\n",
    "        y_pred = np.dot(X, w) + b\n",
    "        \n",
    "        # Calculate the difference between predictions and actual values\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # Calculate the gradient\n",
    "        w_gradient = (1/num_samples) * np.dot(X.T, error)\n",
    "        b_gradient = (1/num_samples) * np.sum(error)\n",
    "        \n",
    "        # Update theta using the learning rate and gradient\n",
    "        w -= learning_rate * w_gradient\n",
    "        b -= learning_rate * b_gradient\n",
    "        \n",
    "        # Calculate the cost (mean squared error)\n",
    "        cost = np.mean(np.square(error))\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return w, b, cost_history\n",
    "\n",
    "# Train the model using gradient descent\n",
    "learning_rate = 0.01\n",
    "num_iterations = 10000\n",
    "w, b, cost_history = gradient_descent(X_train_normalized, y_train, learning_rate, num_iterations)\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "\n",
    "for i, w_i in enumerate(w):\n",
    "    print(f\"w{i} =\", w_i)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w, b)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w, b)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf7d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned parameters:\n",
      "w0 = 0.05991745486833127\n",
      "w1 = -2.138096009922388\n",
      "w2 = 3.845528762767929\n",
      "b = 2.8660198487388913\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error rate: 0.5504233513770832\n",
      "Test error rate: 0.6050116909077828\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradien Descent Algorithms\n",
    "def stochastic_gradient_descent(X, y, learning_rate, num_epochs, batch_size):\n",
    "    num_samples, num_features = X.shape\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    # Initialize weights and bias\n",
    "    w = np.zeros(num_features)\n",
    "    b = 0\n",
    "    cost_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data for each epoch\n",
    "        permutation = np.random.permutation(num_samples)\n",
    "        X_shuffled = X[permutation]\n",
    "        y_shuffled = y[permutation]\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            # Select the current batch\n",
    "            start = batch * batch_size\n",
    "            end = (batch + 1) * batch_size\n",
    "            X_batch = X_shuffled[start:end]\n",
    "            y_batch = y_shuffled[start:end]\n",
    "\n",
    "            # Calculate predictions\n",
    "            y_pred = np.dot(X_batch, w) + b\n",
    "\n",
    "            # Calculate the difference between predictions and actual values\n",
    "            error = y_pred - y_batch\n",
    "\n",
    "            # Calculate the gradients\n",
    "            w_gradient = (1 / batch_size) * np.dot(X_batch.T, error)\n",
    "            b_gradient = (1 / batch_size) * np.sum(error)\n",
    "\n",
    "            # Update weights and bias\n",
    "            w -= learning_rate * w_gradient\n",
    "            b -= learning_rate * b_gradient\n",
    "\n",
    "            # Calculate the cost (mean squared error)\n",
    "            cost = np.mean(np.square(error))\n",
    "            cost_history.append(cost)\n",
    "            \n",
    "    return w, b, cost_history\n",
    "\n",
    "# Train the model using stochastic gradient descent\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10000\n",
    "batch_size = 10\n",
    "w, b, cost_history = stochastic_gradient_descent(X_train_normalized, y_train, learning_rate, num_epochs, batch_size)\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for i, w_i in enumerate(w):\n",
    "    print(f\"w{i} =\", w_i)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w, b)\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w, b)\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38cfbbe",
   "metadata": {},
   "source": [
    "Pytorch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0f31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.zeros(3, 1, # tensor size (3,1) for 3 variables and 1 output\n",
    "                                               dtype=torch.float),\n",
    "                                  requires_grad=True)  #we can update this value with gradient descent\n",
    "        self.bias = nn.Parameter(torch.zeros(1,\n",
    "                                            dtype=torch.float),\n",
    "                                requires_grad=True)\n",
    "    # Define one computation step as forward\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.transpose(self.weights, 0, 1) * x + self.bias #regression formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3743f7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.], requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create instance of model\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check nn.Parameters in the nn.Module subclass created\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c05051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function (Mean absolute error)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), #parameters of target model to optimize\n",
    "                           lr=0.01) #learning rate, how much optimizer should change the parameters each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee736aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 15.80625 | MAE Test Loss: 12.244346394535613 \n",
      "Epoch: 1 | MAE Train Loss: 12.097977166527667 | MAE Test Loss: 9.519757819975723 \n",
      "Epoch: 2 | MAE Train Loss: 9.406777537929964 | MAE Test Loss: 7.5351409392734325 \n",
      "Epoch: 3 | MAE Train Loss: 7.453224524927168 | MAE Test Loss: 6.088252695956648 \n",
      "Epoch: 4 | MAE Train Loss: 6.034662509015179 | MAE Test Loss: 5.0322527097664445 \n",
      "Epoch: 5 | MAE Train Loss: 5.0041140945370195 | MAE Test Loss: 4.2605070524628905 \n",
      "Epoch: 6 | MAE Train Loss: 4.254983164151073 | MAE Test Loss: 3.695562027486068 \n",
      "Epoch: 7 | MAE Train Loss: 3.7099594883252918 | MAE Test Loss: 3.2811466322701177 \n",
      "Epoch: 8 | MAE Train Loss: 3.312974216251581 | MAE Test Loss: 2.976366017623884 \n",
      "Epoch: 9 | MAE Train Loss: 3.0233621345906996 | MAE Test Loss: 2.7514914684639757 \n",
      "Epoch: 10 | MAE Train Loss: 2.8116312264876924 | MAE Test Loss: 2.5849020034068486 \n",
      "Epoch: 11 | MAE Train Loss: 2.656391563427617 | MAE Test Loss: 2.4608667622588927 \n",
      "Epoch: 12 | MAE Train Loss: 2.542130049293377 | MAE Test Loss: 2.3679348755715517 \n",
      "Epoch: 13 | MAE Train Loss: 2.4575961523002703 | MAE Test Loss: 2.2977650533629017 \n",
      "Epoch: 14 | MAE Train Loss: 2.3946298076285664 | MAE Test Loss: 2.2442774959452136 \n",
      "Epoch: 15 | MAE Train Loss: 2.3473129882391413 | MAE Test Loss: 2.2030370074585512 \n",
      "Epoch: 16 | MAE Train Loss: 2.311353494492593 | MAE Test Loss: 2.1708053803239933 \n",
      "Epoch: 17 | MAE Train Loss: 2.283638501680553 | MAE Test Loss: 2.1452155579649927 \n",
      "Epoch: 18 | MAE Train Loss: 2.261910249975287 | MAE Test Loss: 2.12453534988125 \n",
      "Epoch: 19 | MAE Train Loss: 2.244531311746917 | MAE Test Loss: 2.1074952273483065 \n",
      "Epoch: 20 | MAE Train Loss: 2.230314013388556 | MAE Test Loss: 2.0931633558401597 \n",
      "Epoch: 21 | MAE Train Loss: 2.2183969729033586 | MAE Test Loss: 2.0808545853831535 \n",
      "Epoch: 22 | MAE Train Loss: 2.208155485552093 | MAE Test Loss: 2.070063941288727 \n",
      "Epoch: 23 | MAE Train Loss: 2.1991363618546473 | MAE Test Loss: 2.060418520984638 \n",
      "Epoch: 24 | MAE Train Loss: 2.19101093595203 | MAE Test Loss: 2.051642091345056 \n",
      "Epoch: 25 | MAE Train Loss: 2.183540744420433 | MAE Test Loss: 2.043529650612915 \n",
      "Epoch: 26 | MAE Train Loss: 2.1765529114246456 | MAE Test Loss: 2.035928232261643 \n",
      "Epoch: 27 | MAE Train Loss: 2.169921881289813 | MAE Test Loss: 2.0287235193709585 \n",
      "Epoch: 28 | MAE Train Loss: 2.163556612491497 | MAE Test Loss: 2.0218297508879566 \n",
      "Epoch: 29 | MAE Train Loss: 2.157391084915607 | MAE Test Loss: 2.015182170316969 \n",
      "Epoch: 30 | MAE Train Loss: 2.151377332867764 | MAE Test Loss: 2.008731708732603 \n",
      "Epoch: 31 | MAE Train Loss: 2.1454805246310156 | MAE Test Loss: 2.002440974622836 \n",
      "Epoch: 32 | MAE Train Loss: 2.1396753558391564 | MAE Test Loss: 1.9962814100064463 \n",
      "Epoch: 33 | MAE Train Loss: 2.1339434764926692 | MAE Test Loss: 1.9902310098691445 \n",
      "Epoch: 34 | MAE Train Loss: 2.12827153508325 | MAE Test Loss: 1.9842726492726623 \n",
      "Epoch: 35 | MAE Train Loss: 2.1226497681501075 | MAE Test Loss: 1.9783930460541188 \n",
      "Epoch: 36 | MAE Train Loss: 2.117071095210354 | MAE Test Loss: 1.972581776497402 \n",
      "Epoch: 37 | MAE Train Loss: 2.1115303426610295 | MAE Test Loss: 1.9668305942422222 \n",
      "Epoch: 38 | MAE Train Loss: 2.1060237151105823 | MAE Test Loss: 1.9611328953169902 \n",
      "Epoch: 39 | MAE Train Loss: 2.1005484014882114 | MAE Test Loss: 1.9554834798215706 \n",
      "Epoch: 40 | MAE Train Loss: 2.0951023657855825 | MAE Test Loss: 1.949878123382679 \n",
      "Epoch: 41 | MAE Train Loss: 2.0896840780074064 | MAE Test Loss: 1.9443133818400828 \n",
      "Epoch: 42 | MAE Train Loss: 2.084292390297321 | MAE Test Loss: 1.9387864701129414 \n",
      "Epoch: 43 | MAE Train Loss: 2.078926437806868 | MAE Test Loss: 1.93329508993913 \n",
      "Epoch: 44 | MAE Train Loss: 2.073585557806555 | MAE Test Loss: 1.927837333351349 \n",
      "Epoch: 45 | MAE Train Loss: 2.068269232536434 | MAE Test Loss: 1.9224116475255335 \n",
      "Epoch: 46 | MAE Train Loss: 2.062977064477446 | MAE Test Loss: 1.9170167006812977 \n",
      "Epoch: 47 | MAE Train Loss: 2.0577087088329016 | MAE Test Loss: 1.9116513909540707 \n",
      "Epoch: 48 | MAE Train Loss: 2.052463904372238 | MAE Test Loss: 1.9063147766878477 \n",
      "Epoch: 49 | MAE Train Loss: 2.047242419574098 | MAE Test Loss: 1.9010060691007697 \n",
      "Epoch: 50 | MAE Train Loss: 2.042044051911 | MAE Test Loss: 1.8957245371313995 \n",
      "Epoch: 51 | MAE Train Loss: 2.0368686036445447 | MAE Test Loss: 1.8904696252501352 \n",
      "Epoch: 52 | MAE Train Loss: 2.03171593357487 | MAE Test Loss: 1.8852407778836038 \n",
      "Epoch: 53 | MAE Train Loss: 2.0265858651745963 | MAE Test Loss: 1.8800375893420007 \n",
      "Epoch: 54 | MAE Train Loss: 2.0214782801991724 | MAE Test Loss: 1.874859635755822 \n",
      "Epoch: 55 | MAE Train Loss: 2.0163930325123607 | MAE Test Loss: 1.8697065625610492 \n",
      "Epoch: 56 | MAE Train Loss: 2.011329987488967 | MAE Test Loss: 1.8645780607775104 \n",
      "Epoch: 57 | MAE Train Loss: 2.0062890235877036 | MAE Test Loss: 1.8594738471327332 \n",
      "Epoch: 58 | MAE Train Loss: 2.001270015488646 | MAE Test Loss: 1.8543936487756465 \n",
      "Epoch: 59 | MAE Train Loss: 1.9962728396355829 | MAE Test Loss: 1.8493372522703873 \n",
      "Epoch: 60 | MAE Train Loss: 1.9912973840788495 | MAE Test Loss: 1.8443044075075072 \n",
      "Epoch: 61 | MAE Train Loss: 1.986343516174322 | MAE Test Loss: 1.8392949093515019 \n",
      "Epoch: 62 | MAE Train Loss: 1.9814111209767424 | MAE Test Loss: 1.8343085676236512 \n",
      "Epoch: 63 | MAE Train Loss: 1.9765000769734666 | MAE Test Loss: 1.8293452481054544 \n",
      "Epoch: 64 | MAE Train Loss: 1.9716102917995904 | MAE Test Loss: 1.824404740727824 \n",
      "Epoch: 65 | MAE Train Loss: 1.9667416367265127 | MAE Test Loss: 1.8194868920000324 \n",
      "Epoch: 66 | MAE Train Loss: 1.961893997593587 | MAE Test Loss: 1.814591520680858 \n",
      "Epoch: 67 | MAE Train Loss: 1.957067250032209 | MAE Test Loss: 1.8097185145087238 \n",
      "Epoch: 68 | MAE Train Loss: 1.952261296532813 | MAE Test Loss: 1.804867706665592 \n",
      "Epoch: 69 | MAE Train Loss: 1.9474760219000469 | MAE Test Loss: 1.8000389820995886 \n",
      "Epoch: 70 | MAE Train Loss: 1.9427113237030766 | MAE Test Loss: 1.7952321884589129 \n",
      "Epoch: 71 | MAE Train Loss: 1.9379670823125317 | MAE Test Loss: 1.7904472133485654 \n",
      "Epoch: 72 | MAE Train Loss: 1.9332431972756627 | MAE Test Loss: 1.7856839158140894 \n",
      "Epoch: 73 | MAE Train Loss: 1.9285395565630785 | MAE Test Loss: 1.78094215518935 \n",
      "Epoch: 74 | MAE Train Loss: 1.9238560472364867 | MAE Test Loss: 1.7762218197211883 \n",
      "Epoch: 75 | MAE Train Loss: 1.9191925674760788 | MAE Test Loss: 1.771522795708055 \n",
      "Epoch: 76 | MAE Train Loss: 1.9145490129250688 | MAE Test Loss: 1.7668449741512358 \n",
      "Epoch: 77 | MAE Train Loss: 1.909925284245069 | MAE Test Loss: 1.7621882155188495 \n",
      "Epoch: 78 | MAE Train Loss: 1.905321267894794 | MAE Test Loss: 1.7575524081954703 \n",
      "Epoch: 79 | MAE Train Loss: 1.900736861332592 | MAE Test Loss: 1.7529374418618127 \n",
      "Epoch: 80 | MAE Train Loss: 1.896171962341582 | MAE Test Loss: 1.7483432174114264 \n",
      "Epoch: 81 | MAE Train Loss: 1.891626478517329 | MAE Test Loss: 1.7437695686571892 \n",
      "Epoch: 82 | MAE Train Loss: 1.8871002715634417 | MAE Test Loss: 1.7392164436774038 \n",
      "Epoch: 83 | MAE Train Loss: 1.8825932782987658 | MAE Test Loss: 1.7346836962576835 \n",
      "Epoch: 84 | MAE Train Loss: 1.8781053779941967 | MAE Test Loss: 1.7301712300835024 \n",
      "Epoch: 85 | MAE Train Loss: 1.8736364803553076 | MAE Test Loss: 1.7256789219686433 \n",
      "Epoch: 86 | MAE Train Loss: 1.869186471689617 | MAE Test Loss: 1.72120667662703 \n",
      "Epoch: 87 | MAE Train Loss: 1.8647552627197073 | MAE Test Loss: 1.7167543765261055 \n",
      "Epoch: 88 | MAE Train Loss: 1.8603427558706502 | MAE Test Loss: 1.7123219240862508 \n",
      "Epoch: 89 | MAE Train Loss: 1.8559488477526507 | MAE Test Loss: 1.7079092278669865 \n",
      "Epoch: 90 | MAE Train Loss: 1.8515734534741384 | MAE Test Loss: 1.7035161480466432 \n",
      "Epoch: 91 | MAE Train Loss: 1.8472164563985576 | MAE Test Loss: 1.6991426149924038 \n",
      "Epoch: 92 | MAE Train Loss: 1.8428777782895793 | MAE Test Loss: 1.6947884848333044 \n",
      "Epoch: 93 | MAE Train Loss: 1.8385572978784075 | MAE Test Loss: 1.690453690897814 \n",
      "Epoch: 94 | MAE Train Loss: 1.8342549408107893 | MAE Test Loss: 1.6861381230859156 \n",
      "Epoch: 95 | MAE Train Loss: 1.8299706159902995 | MAE Test Loss: 1.6818416645566447 \n",
      "Epoch: 96 | MAE Train Loss: 1.8257042152247625 | MAE Test Loss: 1.6775642469104841 \n",
      "Epoch: 97 | MAE Train Loss: 1.8214556625729172 | MAE Test Loss: 1.6733057597006227 \n",
      "Epoch: 98 | MAE Train Loss: 1.8172248654980065 | MAE Test Loss: 1.6690660924362342 \n",
      "Epoch: 99 | MAE Train Loss: 1.8130117230968144 | MAE Test Loss: 1.6648451305537446 \n"
     ]
    }
   ],
   "source": [
    "# ACTUAL TRAINING OF THE MODEL\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# no. of times the model will pass over the training data\n",
    "epochs = 100\n",
    "\n",
    "# Create empty loss list to track loss values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### TRAINING!!!\n",
    "    \n",
    "    # Put model in training mode\n",
    "    model_0.train()\n",
    "    \n",
    "    # 1. Forward pass on train data\n",
    "    y_pred = model_0(X_train_tensor) # weight prediction\n",
    "    # calculated index prediction\n",
    "    index_pred = torch.sum(torch.mul(X_train_tensor, y_pred), dim=1) + model_0.bias #sum product of weight and data\n",
    "        \n",
    "    # 2. Calculate loss from prediction\n",
    "    loss = loss_fn(index_pred.double(), y_train_tensor.double())\n",
    "    \n",
    "    # 3. Zero grad of optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Progress the optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    ### TESTING ACCURACY!!!\n",
    "    \n",
    "    # Put model in evaluation mode\n",
    "    model_0.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass on test data\n",
    "        test_pred = model_0(X_test_tensor)\n",
    "        \n",
    "        # 2. Calculate loss on test data\n",
    "        test_sum_prod = torch.sum(torch.mul(X_test_tensor, test_pred), dim=1) + model_0.bias\n",
    "        test_loss = loss_fn(test_sum_prod, y_test_tensor)\n",
    "        \n",
    "        # Print out what is happening (each 10 steps)\n",
    "        if epoch % 1 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c17bfd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2ece1c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('weights', tensor([[-0.1530],\n",
      "        [-0.2198],\n",
      "        [ 0.5658]])), ('bias', tensor([1.3950]))])\n"
     ]
    }
   ],
   "source": [
    "# Find our model's learned parameters\n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707afbc",
   "metadata": {},
   "source": [
    "Pytorch SGD Test (This is done by Chris for testing purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc595f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained weights: tensor([ 0.0608, -2.1335,  3.8474], requires_grad=True)\n",
      "Trained bias: tensor([2.8643], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error rate: 0.5504200649769682\n",
      "Test error rate: 0.6053662950911989\n"
     ]
    }
   ],
   "source": [
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define the number of features\n",
    "num_features = X_train_tensor.size()[1]\n",
    "\n",
    "# Define the model parameters (weights and bias)\n",
    "w = torch.zeros(num_features, dtype=torch.float, requires_grad=True)\n",
    "b = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "cost_history = []\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Vanilla Gradient Descent)\n",
    "optimizer = torch.optim.SGD([w, b], lr=learning_rate)\n",
    "\n",
    "# Perform gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = torch.matmul(X_train_tensor.float(), w) + b\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record the loss\n",
    "    cost_history.append(loss.detach().numpy())\n",
    "    \n",
    "#    # Print the loss every 10 epochs\n",
    "#    if (epoch + 1) % 10 == 0:\n",
    "#        print(f'Epoch [{epoch+1}], Loss: {loss.item():.8f}')\n",
    "        \n",
    "\n",
    "# Print learned parameters\n",
    "print('Trained weights:', w)\n",
    "print('Trained bias:', b)\n",
    "\n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate train error rate\n",
    "train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w.detach().numpy(), b.detach().numpy())\n",
    "print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "if X_test is not None and y_test is not None:\n",
    "    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w.detach().numpy(), b.detach().numpy())\n",
    "    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa3f70",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3285b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/5000], Loss: 20.31640816\n",
      "Epoch [20/5000], Loss: 20.31640816\n",
      "Epoch [30/5000], Loss: 20.31640816\n",
      "Epoch [40/5000], Loss: 20.31640816\n",
      "Epoch [50/5000], Loss: 20.31640816\n",
      "Epoch [60/5000], Loss: 20.31640816\n",
      "Epoch [70/5000], Loss: 20.31640816\n",
      "Epoch [80/5000], Loss: 20.31640816\n",
      "Epoch [90/5000], Loss: 20.31640816\n",
      "Epoch [100/5000], Loss: 20.31640816\n",
      "Epoch [110/5000], Loss: 20.31640816\n",
      "Epoch [120/5000], Loss: 20.31640816\n",
      "Epoch [130/5000], Loss: 20.31640816\n",
      "Epoch [140/5000], Loss: 20.31640816\n",
      "Epoch [150/5000], Loss: 20.31640816\n",
      "Epoch [160/5000], Loss: 20.31640816\n",
      "Epoch [170/5000], Loss: 20.31640816\n",
      "Epoch [180/5000], Loss: 20.31640816\n",
      "Epoch [190/5000], Loss: 20.31640816\n",
      "Epoch [200/5000], Loss: 20.31640816\n",
      "Epoch [210/5000], Loss: 20.31640816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\.julia\\conda\\3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([320])) that is different to the input size (torch.Size([320, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_19584\\2400493343.py:22: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:491.)\n",
      "  return loss.grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [220/5000], Loss: 20.31640816\n",
      "Epoch [230/5000], Loss: 20.31640816\n",
      "Epoch [240/5000], Loss: 20.31640816\n",
      "Epoch [250/5000], Loss: 20.31640816\n",
      "Epoch [260/5000], Loss: 20.31640816\n",
      "Epoch [270/5000], Loss: 20.31640816\n",
      "Epoch [280/5000], Loss: 20.31640816\n",
      "Epoch [290/5000], Loss: 20.31640816\n",
      "Epoch [300/5000], Loss: 20.31640816\n",
      "Epoch [310/5000], Loss: 20.31640816\n",
      "Epoch [320/5000], Loss: 20.31640816\n",
      "Epoch [330/5000], Loss: 20.31640816\n",
      "Epoch [340/5000], Loss: 20.31640816\n",
      "Epoch [350/5000], Loss: 20.31640816\n",
      "Epoch [360/5000], Loss: 20.31640816\n",
      "Epoch [370/5000], Loss: 20.31640816\n",
      "Epoch [380/5000], Loss: 20.31640816\n",
      "Epoch [390/5000], Loss: 20.31640816\n",
      "Epoch [400/5000], Loss: 20.31640816\n",
      "Epoch [410/5000], Loss: 20.31640816\n",
      "Epoch [420/5000], Loss: 20.31640816\n",
      "Epoch [430/5000], Loss: 20.31640816\n",
      "Epoch [440/5000], Loss: 20.31640816\n",
      "Epoch [450/5000], Loss: 20.31640816\n",
      "Epoch [460/5000], Loss: 20.31640816\n",
      "Epoch [470/5000], Loss: 20.31640816\n",
      "Epoch [480/5000], Loss: 20.31640816\n",
      "Epoch [490/5000], Loss: 20.31640816\n",
      "Epoch [500/5000], Loss: 20.31640816\n",
      "Epoch [510/5000], Loss: 20.31640816\n",
      "Epoch [520/5000], Loss: 20.31640816\n",
      "Epoch [530/5000], Loss: 20.31640816\n",
      "Epoch [540/5000], Loss: 20.31640816\n",
      "Epoch [550/5000], Loss: 20.31640816\n",
      "Epoch [560/5000], Loss: 20.31640816\n",
      "Epoch [570/5000], Loss: 20.31640816\n",
      "Epoch [580/5000], Loss: 20.31640816\n",
      "Epoch [590/5000], Loss: 20.31640816\n",
      "Epoch [600/5000], Loss: 20.31640816\n",
      "Epoch [610/5000], Loss: 20.31640816\n",
      "Epoch [620/5000], Loss: 20.31640816\n",
      "Epoch [630/5000], Loss: 20.31640816\n",
      "Epoch [640/5000], Loss: 20.31640816\n",
      "Epoch [650/5000], Loss: 20.31640816\n",
      "Epoch [660/5000], Loss: 20.31640816\n",
      "Epoch [670/5000], Loss: 20.31640816\n",
      "Epoch [680/5000], Loss: 20.31640816\n",
      "Epoch [690/5000], Loss: 20.31640816\n",
      "Epoch [700/5000], Loss: 20.31640816\n",
      "Epoch [710/5000], Loss: 20.31640816\n",
      "Epoch [720/5000], Loss: 20.31640816\n",
      "Epoch [730/5000], Loss: 20.31640816\n",
      "Epoch [740/5000], Loss: 20.31640816\n",
      "Epoch [750/5000], Loss: 20.31640816\n",
      "Epoch [760/5000], Loss: 20.31640816\n",
      "Epoch [770/5000], Loss: 20.31640816\n",
      "Epoch [780/5000], Loss: 20.31640816\n",
      "Epoch [790/5000], Loss: 20.31640816\n",
      "Epoch [800/5000], Loss: 20.31640816\n",
      "Epoch [810/5000], Loss: 20.31640816\n",
      "Epoch [820/5000], Loss: 20.31640816\n",
      "Epoch [830/5000], Loss: 20.31640816\n",
      "Epoch [840/5000], Loss: 20.31640816\n",
      "Epoch [850/5000], Loss: 20.31640816\n",
      "Epoch [860/5000], Loss: 20.31640816\n",
      "Epoch [870/5000], Loss: 20.31640816\n",
      "Epoch [880/5000], Loss: 20.31640816\n",
      "Epoch [890/5000], Loss: 20.31640816\n",
      "Epoch [900/5000], Loss: 20.31640816\n",
      "Epoch [910/5000], Loss: 20.31640816\n",
      "Epoch [920/5000], Loss: 20.31640816\n",
      "Epoch [930/5000], Loss: 20.31640816\n",
      "Epoch [940/5000], Loss: 20.31640816\n",
      "Epoch [950/5000], Loss: 20.31640816\n",
      "Epoch [960/5000], Loss: 20.31640816\n",
      "Epoch [970/5000], Loss: 20.31640816\n",
      "Epoch [980/5000], Loss: 20.31640816\n",
      "Epoch [990/5000], Loss: 20.31640816\n",
      "Epoch [1000/5000], Loss: 20.31640816\n",
      "Epoch [1010/5000], Loss: 20.31640816\n",
      "Epoch [1020/5000], Loss: 20.31640816\n",
      "Epoch [1030/5000], Loss: 20.31640816\n",
      "Epoch [1040/5000], Loss: 20.31640816\n",
      "Epoch [1050/5000], Loss: 20.31640816\n",
      "Epoch [1060/5000], Loss: 20.31640816\n",
      "Epoch [1070/5000], Loss: 20.31640816\n",
      "Epoch [1080/5000], Loss: 20.31640816\n",
      "Epoch [1090/5000], Loss: 20.31640816\n",
      "Epoch [1100/5000], Loss: 20.31640816\n",
      "Epoch [1110/5000], Loss: 20.31640816\n",
      "Epoch [1120/5000], Loss: 20.31640816\n",
      "Epoch [1130/5000], Loss: 20.31640816\n",
      "Epoch [1140/5000], Loss: 20.31640816\n",
      "Epoch [1150/5000], Loss: 20.31640816\n",
      "Epoch [1160/5000], Loss: 20.31640816\n",
      "Epoch [1170/5000], Loss: 20.31640816\n",
      "Epoch [1180/5000], Loss: 20.31640816\n",
      "Epoch [1190/5000], Loss: 20.31640816\n",
      "Epoch [1200/5000], Loss: 20.31640816\n",
      "Epoch [1210/5000], Loss: 20.31640816\n",
      "Epoch [1220/5000], Loss: 20.31640816\n",
      "Epoch [1230/5000], Loss: 20.31640816\n",
      "Epoch [1240/5000], Loss: 20.31640816\n",
      "Epoch [1250/5000], Loss: 20.31640816\n",
      "Epoch [1260/5000], Loss: 20.31640816\n",
      "Epoch [1270/5000], Loss: 20.31640816\n",
      "Epoch [1280/5000], Loss: 20.31640816\n",
      "Epoch [1290/5000], Loss: 20.31640816\n",
      "Epoch [1300/5000], Loss: 20.31640816\n",
      "Epoch [1310/5000], Loss: 20.31640816\n",
      "Epoch [1320/5000], Loss: 20.31640816\n",
      "Epoch [1330/5000], Loss: 20.31640816\n",
      "Epoch [1340/5000], Loss: 20.31640816\n",
      "Epoch [1350/5000], Loss: 20.31640816\n",
      "Epoch [1360/5000], Loss: 20.31640816\n",
      "Epoch [1370/5000], Loss: 20.31640816\n",
      "Epoch [1380/5000], Loss: 20.31640816\n",
      "Epoch [1390/5000], Loss: 20.31640816\n",
      "Epoch [1400/5000], Loss: 20.31640816\n",
      "Epoch [1410/5000], Loss: 20.31640816\n",
      "Epoch [1420/5000], Loss: 20.31640816\n",
      "Epoch [1430/5000], Loss: 20.31640816\n",
      "Epoch [1440/5000], Loss: 20.31640816\n",
      "Epoch [1450/5000], Loss: 20.31640816\n",
      "Epoch [1460/5000], Loss: 20.31640816\n",
      "Epoch [1470/5000], Loss: 20.31640816\n",
      "Epoch [1480/5000], Loss: 20.31640816\n",
      "Epoch [1490/5000], Loss: 20.31640816\n",
      "Epoch [1500/5000], Loss: 20.31640816\n",
      "Epoch [1510/5000], Loss: 20.31640816\n",
      "Epoch [1520/5000], Loss: 20.31640816\n",
      "Epoch [1530/5000], Loss: 20.31640816\n",
      "Epoch [1540/5000], Loss: 20.31640816\n",
      "Epoch [1550/5000], Loss: 20.31640816\n",
      "Epoch [1560/5000], Loss: 20.31640816\n",
      "Epoch [1570/5000], Loss: 20.31640816\n",
      "Epoch [1580/5000], Loss: 20.31640816\n",
      "Epoch [1590/5000], Loss: 20.31640816\n",
      "Epoch [1600/5000], Loss: 20.31640816\n",
      "Epoch [1610/5000], Loss: 20.31640816\n",
      "Epoch [1620/5000], Loss: 20.31640816\n",
      "Epoch [1630/5000], Loss: 20.31640816\n",
      "Epoch [1640/5000], Loss: 20.31640816\n",
      "Epoch [1650/5000], Loss: 20.31640816\n",
      "Epoch [1660/5000], Loss: 20.31640816\n",
      "Epoch [1670/5000], Loss: 20.31640816\n",
      "Epoch [1680/5000], Loss: 20.31640816\n",
      "Epoch [1690/5000], Loss: 20.31640816\n",
      "Epoch [1700/5000], Loss: 20.31640816\n",
      "Epoch [1710/5000], Loss: 20.31640816\n",
      "Epoch [1720/5000], Loss: 20.31640816\n",
      "Epoch [1730/5000], Loss: 20.31640816\n",
      "Epoch [1740/5000], Loss: 20.31640816\n",
      "Epoch [1750/5000], Loss: 20.31640816\n",
      "Epoch [1760/5000], Loss: 20.31640816\n",
      "Epoch [1770/5000], Loss: 20.31640816\n",
      "Epoch [1780/5000], Loss: 20.31640816\n",
      "Epoch [1790/5000], Loss: 20.31640816\n",
      "Epoch [1800/5000], Loss: 20.31640816\n",
      "Epoch [1810/5000], Loss: 20.31640816\n",
      "Epoch [1820/5000], Loss: 20.31640816\n",
      "Epoch [1830/5000], Loss: 20.31640816\n",
      "Epoch [1840/5000], Loss: 20.31640816\n",
      "Epoch [1850/5000], Loss: 20.31640816\n",
      "Epoch [1860/5000], Loss: 20.31640816\n",
      "Epoch [1870/5000], Loss: 20.31640816\n",
      "Epoch [1880/5000], Loss: 20.31640816\n",
      "Epoch [1890/5000], Loss: 20.31640816\n",
      "Epoch [1900/5000], Loss: 20.31640816\n",
      "Epoch [1910/5000], Loss: 20.31640816\n",
      "Epoch [1920/5000], Loss: 20.31640816\n",
      "Epoch [1930/5000], Loss: 20.31640816\n",
      "Epoch [1940/5000], Loss: 20.31640816\n",
      "Epoch [1950/5000], Loss: 20.31640816\n",
      "Epoch [1960/5000], Loss: 20.31640816\n",
      "Epoch [1970/5000], Loss: 20.31640816\n",
      "Epoch [1980/5000], Loss: 20.31640816\n",
      "Epoch [1990/5000], Loss: 20.31640816\n",
      "Epoch [2000/5000], Loss: 20.31640816\n",
      "Epoch [2010/5000], Loss: 20.31640816\n",
      "Epoch [2020/5000], Loss: 20.31640816\n",
      "Epoch [2030/5000], Loss: 20.31640816\n",
      "Epoch [2040/5000], Loss: 20.31640816\n",
      "Epoch [2050/5000], Loss: 20.31640816\n",
      "Epoch [2060/5000], Loss: 20.31640816\n",
      "Epoch [2070/5000], Loss: 20.31640816\n",
      "Epoch [2080/5000], Loss: 20.31640816\n",
      "Epoch [2090/5000], Loss: 20.31640816\n",
      "Epoch [2100/5000], Loss: 20.31640816\n",
      "Epoch [2110/5000], Loss: 20.31640816\n",
      "Epoch [2120/5000], Loss: 20.31640816\n",
      "Epoch [2130/5000], Loss: 20.31640816\n",
      "Epoch [2140/5000], Loss: 20.31640816\n",
      "Epoch [2150/5000], Loss: 20.31640816\n",
      "Epoch [2160/5000], Loss: 20.31640816\n",
      "Epoch [2170/5000], Loss: 20.31640816\n",
      "Epoch [2180/5000], Loss: 20.31640816\n",
      "Epoch [2190/5000], Loss: 20.31640816\n",
      "Epoch [2200/5000], Loss: 20.31640816\n",
      "Epoch [2210/5000], Loss: 20.31640816\n",
      "Epoch [2220/5000], Loss: 20.31640816\n",
      "Epoch [2230/5000], Loss: 20.31640816\n",
      "Epoch [2240/5000], Loss: 20.31640816\n",
      "Epoch [2250/5000], Loss: 20.31640816\n",
      "Epoch [2260/5000], Loss: 20.31640816\n",
      "Epoch [2270/5000], Loss: 20.31640816\n",
      "Epoch [2280/5000], Loss: 20.31640816\n",
      "Epoch [2290/5000], Loss: 20.31640816\n",
      "Epoch [2300/5000], Loss: 20.31640816\n",
      "Epoch [2310/5000], Loss: 20.31640816\n",
      "Epoch [2320/5000], Loss: 20.31640816\n",
      "Epoch [2330/5000], Loss: 20.31640816\n",
      "Epoch [2340/5000], Loss: 20.31640816\n",
      "Epoch [2350/5000], Loss: 20.31640816\n",
      "Epoch [2360/5000], Loss: 20.31640816\n",
      "Epoch [2370/5000], Loss: 20.31640816\n",
      "Epoch [2380/5000], Loss: 20.31640816\n",
      "Epoch [2390/5000], Loss: 20.31640816\n",
      "Epoch [2400/5000], Loss: 20.31640816\n",
      "Epoch [2410/5000], Loss: 20.31640816\n",
      "Epoch [2420/5000], Loss: 20.31640816\n",
      "Epoch [2430/5000], Loss: 20.31640816\n",
      "Epoch [2440/5000], Loss: 20.31640816\n",
      "Epoch [2450/5000], Loss: 20.31640816\n",
      "Epoch [2460/5000], Loss: 20.31640816\n",
      "Epoch [2470/5000], Loss: 20.31640816\n",
      "Epoch [2480/5000], Loss: 20.31640816\n",
      "Epoch [2490/5000], Loss: 20.31640816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2500/5000], Loss: 20.31640816\n",
      "Epoch [2510/5000], Loss: 20.31640816\n",
      "Epoch [2520/5000], Loss: 20.31640816\n",
      "Epoch [2530/5000], Loss: 20.31640816\n",
      "Epoch [2540/5000], Loss: 20.31640816\n",
      "Epoch [2550/5000], Loss: 20.31640816\n",
      "Epoch [2560/5000], Loss: 20.31640816\n",
      "Epoch [2570/5000], Loss: 20.31640816\n",
      "Epoch [2580/5000], Loss: 20.31640816\n",
      "Epoch [2590/5000], Loss: 20.31640816\n",
      "Epoch [2600/5000], Loss: 20.31640816\n",
      "Epoch [2610/5000], Loss: 20.31640816\n",
      "Epoch [2620/5000], Loss: 20.31640816\n",
      "Epoch [2630/5000], Loss: 20.31640816\n",
      "Epoch [2640/5000], Loss: 20.31640816\n",
      "Epoch [2650/5000], Loss: 20.31640816\n",
      "Epoch [2660/5000], Loss: 20.31640816\n",
      "Epoch [2670/5000], Loss: 20.31640816\n",
      "Epoch [2680/5000], Loss: 20.31640816\n",
      "Epoch [2690/5000], Loss: 20.31640816\n",
      "Epoch [2700/5000], Loss: 20.31640816\n",
      "Epoch [2710/5000], Loss: 20.31640816\n",
      "Epoch [2720/5000], Loss: 20.31640816\n",
      "Epoch [2730/5000], Loss: 20.31640816\n",
      "Epoch [2740/5000], Loss: 20.31640816\n",
      "Epoch [2750/5000], Loss: 20.31640816\n",
      "Epoch [2760/5000], Loss: 20.31640816\n",
      "Epoch [2770/5000], Loss: 20.31640816\n",
      "Epoch [2780/5000], Loss: 20.31640816\n",
      "Epoch [2790/5000], Loss: 20.31640816\n",
      "Epoch [2800/5000], Loss: 20.31640816\n",
      "Epoch [2810/5000], Loss: 20.31640816\n",
      "Epoch [2820/5000], Loss: 20.31640816\n",
      "Epoch [2830/5000], Loss: 20.31640816\n",
      "Epoch [2840/5000], Loss: 20.31640816\n",
      "Epoch [2850/5000], Loss: 20.31640816\n",
      "Epoch [2860/5000], Loss: 20.31640816\n",
      "Epoch [2870/5000], Loss: 20.31640816\n",
      "Epoch [2880/5000], Loss: 20.31640816\n",
      "Epoch [2890/5000], Loss: 20.31640816\n",
      "Epoch [2900/5000], Loss: 20.31640816\n",
      "Epoch [2910/5000], Loss: 20.31640816\n",
      "Epoch [2920/5000], Loss: 20.31640816\n",
      "Epoch [2930/5000], Loss: 20.31640816\n",
      "Epoch [2940/5000], Loss: 20.31640816\n",
      "Epoch [2950/5000], Loss: 20.31640816\n",
      "Epoch [2960/5000], Loss: 20.31640816\n",
      "Epoch [2970/5000], Loss: 20.31640816\n",
      "Epoch [2980/5000], Loss: 20.31640816\n",
      "Epoch [2990/5000], Loss: 20.31640816\n",
      "Epoch [3000/5000], Loss: 20.31640816\n",
      "Epoch [3010/5000], Loss: 20.31640816\n",
      "Epoch [3020/5000], Loss: 20.31640816\n",
      "Epoch [3030/5000], Loss: 20.31640816\n",
      "Epoch [3040/5000], Loss: 20.31640816\n",
      "Epoch [3050/5000], Loss: 20.31640816\n",
      "Epoch [3060/5000], Loss: 20.31640816\n",
      "Epoch [3070/5000], Loss: 20.31640816\n",
      "Epoch [3080/5000], Loss: 20.31640816\n",
      "Epoch [3090/5000], Loss: 20.31640816\n",
      "Epoch [3100/5000], Loss: 20.31640816\n",
      "Epoch [3110/5000], Loss: 20.31640816\n",
      "Epoch [3120/5000], Loss: 20.31640816\n",
      "Epoch [3130/5000], Loss: 20.31640816\n",
      "Epoch [3140/5000], Loss: 20.31640816\n",
      "Epoch [3150/5000], Loss: 20.31640816\n",
      "Epoch [3160/5000], Loss: 20.31640816\n",
      "Epoch [3170/5000], Loss: 20.31640816\n",
      "Epoch [3180/5000], Loss: 20.31640816\n",
      "Epoch [3190/5000], Loss: 20.31640816\n",
      "Epoch [3200/5000], Loss: 20.31640816\n",
      "Epoch [3210/5000], Loss: 20.31640816\n",
      "Epoch [3220/5000], Loss: 20.31640816\n",
      "Epoch [3230/5000], Loss: 20.31640816\n",
      "Epoch [3240/5000], Loss: 20.31640816\n",
      "Epoch [3250/5000], Loss: 20.31640816\n",
      "Epoch [3260/5000], Loss: 20.31640816\n",
      "Epoch [3270/5000], Loss: 20.31640816\n",
      "Epoch [3280/5000], Loss: 20.31640816\n",
      "Epoch [3290/5000], Loss: 20.31640816\n",
      "Epoch [3300/5000], Loss: 20.31640816\n",
      "Epoch [3310/5000], Loss: 20.31640816\n",
      "Epoch [3320/5000], Loss: 20.31640816\n",
      "Epoch [3330/5000], Loss: 20.31640816\n",
      "Epoch [3340/5000], Loss: 20.31640816\n",
      "Epoch [3350/5000], Loss: 20.31640816\n",
      "Epoch [3360/5000], Loss: 20.31640816\n",
      "Epoch [3370/5000], Loss: 20.31640816\n",
      "Epoch [3380/5000], Loss: 20.31640816\n",
      "Epoch [3390/5000], Loss: 20.31640816\n",
      "Epoch [3400/5000], Loss: 20.31640816\n",
      "Epoch [3410/5000], Loss: 20.31640816\n",
      "Epoch [3420/5000], Loss: 20.31640816\n",
      "Epoch [3430/5000], Loss: 20.31640816\n",
      "Epoch [3440/5000], Loss: 20.31640816\n",
      "Epoch [3450/5000], Loss: 20.31640816\n",
      "Epoch [3460/5000], Loss: 20.31640816\n",
      "Epoch [3470/5000], Loss: 20.31640816\n",
      "Epoch [3480/5000], Loss: 20.31640816\n",
      "Epoch [3490/5000], Loss: 20.31640816\n",
      "Epoch [3500/5000], Loss: 20.31640816\n",
      "Epoch [3510/5000], Loss: 20.31640816\n",
      "Epoch [3520/5000], Loss: 20.31640816\n",
      "Epoch [3530/5000], Loss: 20.31640816\n",
      "Epoch [3540/5000], Loss: 20.31640816\n",
      "Epoch [3550/5000], Loss: 20.31640816\n",
      "Epoch [3560/5000], Loss: 20.31640816\n",
      "Epoch [3570/5000], Loss: 20.31640816\n",
      "Epoch [3580/5000], Loss: 20.31640816\n",
      "Epoch [3590/5000], Loss: 20.31640816\n",
      "Epoch [3600/5000], Loss: 20.31640816\n",
      "Epoch [3610/5000], Loss: 20.31640816\n",
      "Epoch [3620/5000], Loss: 20.31640816\n",
      "Epoch [3630/5000], Loss: 20.31640816\n",
      "Epoch [3640/5000], Loss: 20.31640816\n",
      "Epoch [3650/5000], Loss: 20.31640816\n",
      "Epoch [3660/5000], Loss: 20.31640816\n",
      "Epoch [3670/5000], Loss: 20.31640816\n",
      "Epoch [3680/5000], Loss: 20.31640816\n",
      "Epoch [3690/5000], Loss: 20.31640816\n",
      "Epoch [3700/5000], Loss: 20.31640816\n",
      "Epoch [3710/5000], Loss: 20.31640816\n",
      "Epoch [3720/5000], Loss: 20.31640816\n",
      "Epoch [3730/5000], Loss: 20.31640816\n",
      "Epoch [3740/5000], Loss: 20.31640816\n",
      "Epoch [3750/5000], Loss: 20.31640816\n",
      "Epoch [3760/5000], Loss: 20.31640816\n",
      "Epoch [3770/5000], Loss: 20.31640816\n",
      "Epoch [3780/5000], Loss: 20.31640816\n",
      "Epoch [3790/5000], Loss: 20.31640816\n",
      "Epoch [3800/5000], Loss: 20.31640816\n",
      "Epoch [3810/5000], Loss: 20.31640816\n",
      "Epoch [3820/5000], Loss: 20.31640816\n",
      "Epoch [3830/5000], Loss: 20.31640816\n",
      "Epoch [3840/5000], Loss: 20.31640816\n",
      "Epoch [3850/5000], Loss: 20.31640816\n",
      "Epoch [3860/5000], Loss: 20.31640816\n",
      "Epoch [3870/5000], Loss: 20.31640816\n",
      "Epoch [3880/5000], Loss: 20.31640816\n",
      "Epoch [3890/5000], Loss: 20.31640816\n",
      "Epoch [3900/5000], Loss: 20.31640816\n",
      "Epoch [3910/5000], Loss: 20.31640816\n",
      "Epoch [3920/5000], Loss: 20.31640816\n",
      "Epoch [3930/5000], Loss: 20.31640816\n",
      "Epoch [3940/5000], Loss: 20.31640816\n",
      "Epoch [3950/5000], Loss: 20.31640816\n",
      "Epoch [3960/5000], Loss: 20.31640816\n",
      "Epoch [3970/5000], Loss: 20.31640816\n",
      "Epoch [3980/5000], Loss: 20.31640816\n",
      "Epoch [3990/5000], Loss: 20.31640816\n",
      "Epoch [4000/5000], Loss: 20.31640816\n",
      "Epoch [4010/5000], Loss: 20.31640816\n",
      "Epoch [4020/5000], Loss: 20.31640816\n",
      "Epoch [4030/5000], Loss: 20.31640816\n",
      "Epoch [4040/5000], Loss: 20.31640816\n",
      "Epoch [4050/5000], Loss: 20.31640816\n",
      "Epoch [4060/5000], Loss: 20.31640816\n",
      "Epoch [4070/5000], Loss: 20.31640816\n",
      "Epoch [4080/5000], Loss: 20.31640816\n",
      "Epoch [4090/5000], Loss: 20.31640816\n",
      "Epoch [4100/5000], Loss: 20.31640816\n",
      "Epoch [4110/5000], Loss: 20.31640816\n",
      "Epoch [4120/5000], Loss: 20.31640816\n",
      "Epoch [4130/5000], Loss: 20.31640816\n",
      "Epoch [4140/5000], Loss: 20.31640816\n",
      "Epoch [4150/5000], Loss: 20.31640816\n",
      "Epoch [4160/5000], Loss: 20.31640816\n",
      "Epoch [4170/5000], Loss: 20.31640816\n",
      "Epoch [4180/5000], Loss: 20.31640816\n",
      "Epoch [4190/5000], Loss: 20.31640816\n",
      "Epoch [4200/5000], Loss: 20.31640816\n",
      "Epoch [4210/5000], Loss: 20.31640816\n",
      "Epoch [4220/5000], Loss: 20.31640816\n",
      "Epoch [4230/5000], Loss: 20.31640816\n",
      "Epoch [4240/5000], Loss: 20.31640816\n",
      "Epoch [4250/5000], Loss: 20.31640816\n",
      "Epoch [4260/5000], Loss: 20.31640816\n",
      "Epoch [4270/5000], Loss: 20.31640816\n",
      "Epoch [4280/5000], Loss: 20.31640816\n",
      "Epoch [4290/5000], Loss: 20.31640816\n",
      "Epoch [4300/5000], Loss: 20.31640816\n",
      "Epoch [4310/5000], Loss: 20.31640816\n",
      "Epoch [4320/5000], Loss: 20.31640816\n",
      "Epoch [4330/5000], Loss: 20.31640816\n",
      "Epoch [4340/5000], Loss: 20.31640816\n",
      "Epoch [4350/5000], Loss: 20.31640816\n",
      "Epoch [4360/5000], Loss: 20.31640816\n",
      "Epoch [4370/5000], Loss: 20.31640816\n",
      "Epoch [4380/5000], Loss: 20.31640816\n",
      "Epoch [4390/5000], Loss: 20.31640816\n",
      "Epoch [4400/5000], Loss: 20.31640816\n",
      "Epoch [4410/5000], Loss: 20.31640816\n",
      "Epoch [4420/5000], Loss: 20.31640816\n",
      "Epoch [4430/5000], Loss: 20.31640816\n",
      "Epoch [4440/5000], Loss: 20.31640816\n",
      "Epoch [4450/5000], Loss: 20.31640816\n",
      "Epoch [4460/5000], Loss: 20.31640816\n",
      "Epoch [4470/5000], Loss: 20.31640816\n",
      "Epoch [4480/5000], Loss: 20.31640816\n",
      "Epoch [4490/5000], Loss: 20.31640816\n",
      "Epoch [4500/5000], Loss: 20.31640816\n",
      "Epoch [4510/5000], Loss: 20.31640816\n",
      "Epoch [4520/5000], Loss: 20.31640816\n",
      "Epoch [4530/5000], Loss: 20.31640816\n",
      "Epoch [4540/5000], Loss: 20.31640816\n",
      "Epoch [4550/5000], Loss: 20.31640816\n",
      "Epoch [4560/5000], Loss: 20.31640816\n",
      "Epoch [4570/5000], Loss: 20.31640816\n",
      "Epoch [4580/5000], Loss: 20.31640816\n",
      "Epoch [4590/5000], Loss: 20.31640816\n",
      "Epoch [4600/5000], Loss: 20.31640816\n",
      "Epoch [4610/5000], Loss: 20.31640816\n",
      "Epoch [4620/5000], Loss: 20.31640816\n",
      "Epoch [4630/5000], Loss: 20.31640816\n",
      "Epoch [4640/5000], Loss: 20.31640816\n",
      "Epoch [4650/5000], Loss: 20.31640816\n",
      "Epoch [4660/5000], Loss: 20.31640816\n",
      "Epoch [4670/5000], Loss: 20.31640816\n",
      "Epoch [4680/5000], Loss: 20.31640816\n",
      "Epoch [4690/5000], Loss: 20.31640816\n",
      "Epoch [4700/5000], Loss: 20.31640816\n",
      "Epoch [4710/5000], Loss: 20.31640816\n",
      "Epoch [4720/5000], Loss: 20.31640816\n",
      "Epoch [4730/5000], Loss: 20.31640816\n",
      "Epoch [4740/5000], Loss: 20.31640816\n",
      "Epoch [4750/5000], Loss: 20.31640816\n",
      "Epoch [4760/5000], Loss: 20.31640816\n",
      "Epoch [4770/5000], Loss: 20.31640816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4780/5000], Loss: 20.31640816\n",
      "Epoch [4790/5000], Loss: 20.31640816\n",
      "Epoch [4800/5000], Loss: 20.31640816\n",
      "Epoch [4810/5000], Loss: 20.31640816\n",
      "Epoch [4820/5000], Loss: 20.31640816\n",
      "Epoch [4830/5000], Loss: 20.31640816\n",
      "Epoch [4840/5000], Loss: 20.31640816\n",
      "Epoch [4850/5000], Loss: 20.31640816\n",
      "Epoch [4860/5000], Loss: 20.31640816\n",
      "Epoch [4870/5000], Loss: 20.31640816\n",
      "Epoch [4880/5000], Loss: 20.31640816\n",
      "Epoch [4890/5000], Loss: 20.31640816\n",
      "Epoch [4900/5000], Loss: 20.31640816\n",
      "Epoch [4910/5000], Loss: 20.31640816\n",
      "Epoch [4920/5000], Loss: 20.31640816\n",
      "Epoch [4930/5000], Loss: 20.31640816\n",
      "Epoch [4940/5000], Loss: 20.31640816\n",
      "Epoch [4950/5000], Loss: 20.31640816\n",
      "Epoch [4960/5000], Loss: 20.31640816\n",
      "Epoch [4970/5000], Loss: 20.31640816\n",
      "Epoch [4980/5000], Loss: 20.31640816\n",
      "Epoch [4990/5000], Loss: 20.31640816\n",
      "Epoch [5000/5000], Loss: 20.31640816\n",
      "input_layer.weight: tensor([[ 0.4414,  0.4792, -0.1353],\n",
      "        [ 0.5304, -0.1265,  0.1165],\n",
      "        [-0.2811,  0.3391,  0.5090],\n",
      "        [-0.4236,  0.5018,  0.1081],\n",
      "        [ 0.4266,  0.0782,  0.2784]])\n",
      "input_layer.bias: tensor([-0.0815,  0.4451,  0.0853, -0.2695,  0.1472])\n",
      "output_layer.weight: tensor([[-0.2060, -0.0524, -0.1816,  0.2967, -0.3530]])\n",
      "output_layer.bias: tensor([-0.2062])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a custom neural network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        # Intialize the input, the hidden, and the output layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "    \n",
    "    def forward_propagation(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = torch.relu(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def backward_propagation(self, loss):\n",
    "        loss.sum().backward()\n",
    "        return loss.grad\n",
    "    \n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define the number of features\n",
    "num_features = X_train_tensor.size()[1]\n",
    "\n",
    "# Define the model parameters\n",
    "input_size = num_features\n",
    "hidden_size = [5]\n",
    "output_size = 1\n",
    "w = torch.zeros(torch.Size([input_size] + hidden_size + [output_size]), dtype=torch.float, requires_grad=True)\n",
    "b = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "cost_history = []\n",
    "\n",
    "# Create an instance of the neural network\n",
    "criterion = nn.MSELoss()\n",
    "NeuralNetwork_model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "optimizer = torch.optim.SGD([w, b], lr=learning_rate)\n",
    "\n",
    "# Perform training\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward propagation to obtain the predicted output\n",
    "    outputs = NeuralNetwork_model.forward_propagation(X_train_tensor.float())\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, y_train_tensor.float())\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss_derivative = NeuralNetwork_model.backward_propagation(loss)\n",
    "    \n",
    "    # Update the weights and biases\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record the loss\n",
    "    cost_history.append(loss.item())\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}')\n",
    "        \n",
    "# Print learned parameters\n",
    "for name, param in NeuralNetwork_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'{name}: {param.data}')\n",
    "        \n",
    "# Plot the cost history\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost History\")\n",
    "plt.show()\n",
    "\n",
    "# Error rate analysis function for neural network\n",
    "\n",
    "# Calculate train error rate\n",
    "#train_error_rate = calculate_error_rate(X_train_normalized,  y_train, w, b)\n",
    "#print(\"Train error rate:\", train_error_rate)\n",
    "    \n",
    "# Calculate test error rate if test data is provided\n",
    "#if X_test is not None and y_test is not None:\n",
    "#    test_error_rate = calculate_error_rate(X_test_normalized, y_test, w, b)\n",
    "#    print(\"Test error rate:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d747c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d591a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7fb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
